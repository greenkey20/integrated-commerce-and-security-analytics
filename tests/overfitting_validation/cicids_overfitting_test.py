#!/usr/bin/env python3
"""
CICIDS2017 Overfitting í•´ê²° ê²€ì¦ í…ŒìŠ¤íŠ¸

ëª©í‘œ: ì •í™•ë„ 1.0 â†’ 0.85~0.95ë¡œ ê°œì„  í™•ì¸
ë°©ë²•: ì‹¤ì œ CICIDS2017 ë°ì´í„° + êµì°¨ê²€ì¦ + ì„±ëŠ¥ ë¹„êµ
"""

import sys
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from data.loaders.cicids_working_files_loader import WorkingCICIDSLoader
from core.security.model_builder import SecurityModelBuilder, check_tensorflow_availability
from data.loaders.unified_security_loader import UnifiedSecurityLoader


class OverfittingValidator:
    """Overfitting í•´ê²° ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir="C:/keydev/customer-segmentation-analysis/data/cicids2017"):
        self.data_dir = data_dir
        self.results = {}
        
    def log_message(self, message):
        """íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ë©”ì‹œì§€ ì¶œë ¥"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {message}")
    
    def load_cicids_data(self, sample_size=50000):
        """ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ"""
        self.log_message("ğŸš€ ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        try:
            loader = WorkingCICIDSLoader(self.data_dir)
            dataset = loader.load_working_files(target_samples=sample_size)
            
            self.log_message(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(dataset):,}ê°œ")
            
            # ë¼ë²¨ ë¶„í¬ í™•ì¸
            label_counts = dataset['Label'].value_counts()
            attack_ratio = (len(dataset) - label_counts.get('BENIGN', 0)) / len(dataset) * 100
            
            self.log_message(f"ğŸ“Š ê³µê²© ë°ì´í„° ë¹„ìœ¨: {attack_ratio:.1f}%")
            
            if attack_ratio < 5:
                self.log_message("âš ï¸ ê³µê²© ë°ì´í„° ë¹„ìœ¨ì´ ë‚®ìŒ. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ë³´ì™„...")
                return self.load_simulation_data(sample_size)
            
            return dataset
            
        except Exception as e:
            self.log_message(f"âŒ ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self.log_message("ğŸ”§ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ëŒ€ì²´...")
            return self.load_simulation_data(sample_size)
    
    def load_simulation_data(self, sample_size=50000):
        """ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ (í´ë°±)"""
        try:
            sim_loader = UnifiedSecurityLoader()
            dataset = sim_loader.generate_sample_data(
                total_samples=sample_size, 
                attack_ratio=0.6,  # 60% ê³µê²© ë°ì´í„°
                realistic_mode=True
            )
            
            self.log_message(f"âœ… ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(dataset):,}ê°œ")
            return dataset
            
        except Exception as e:
            self.log_message(f"âŒ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±ë„ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def prepare_model_data(self, dataset):
        """ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬"""
        self.log_message("ğŸ”§ ëª¨ë¸ë§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        
        # íŠ¹ì„±ê³¼ ë¼ë²¨ ë¶„ë¦¬
        numeric_features = [col for col in dataset.columns 
                          if col != 'Label' and dataset[col].dtype in ['int64', 'float64']]
        
        X = dataset[numeric_features].values
        y = dataset['Label'].values
        
        self.log_message(f"ğŸ“ˆ íŠ¹ì„± ìˆ˜: {X.shape[1]}, ìƒ˜í”Œ ìˆ˜: {X.shape[0]}")
        
        return X, y, numeric_features
    
    def test_baseline_model(self, X, y):
        """ê¸°ì¡´ ë°©ì‹ (ë‹¨ìˆœ ëª¨ë¸) í…ŒìŠ¤íŠ¸"""
        self.log_message("ğŸ“Š ê¸°ì¡´ ë°©ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
        
        model_builder = SecurityModelBuilder()
        X_train, X_test, y_train, y_test = model_builder.prepare_data(X, y)
        
        # ë‹¨ìˆœ MLP ëª¨ë¸ (overfitting ìœ ë°œ ê°€ëŠ¥)
        model = model_builder.build_mlp_model(X_train.shape[1])
        
        # ê¸´ í›ˆë ¨ (overfitting ìœ ë°œ)
        history = model_builder.train_model(
            X_train, y_train, X_test, y_test, 
            epochs=200, verbose=0
        )
        
        # ì„±ëŠ¥ í‰ê°€
        metrics = model_builder.evaluate_binary_model(X_test, y_test)
        
        self.results['baseline'] = {
            'accuracy': metrics['accuracy'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1_score': metrics['f1_score'],
            'training_history': history.history
        }
        
        self.log_message(f"ğŸ“Š ê¸°ì¡´ ë°©ì‹ ì •í™•ë„: {metrics['accuracy']:.3f}")
        
        return metrics
    
    def test_improved_model(self, X, y):
        """ê°œì„ ëœ ë°©ì‹ (Overfitting ë°©ì§€) í…ŒìŠ¤íŠ¸"""
        self.log_message("ğŸš€ ê°œì„ ëœ ë°©ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
        
        model_builder = SecurityModelBuilder()
        X_train, X_test, y_train, y_test = model_builder.prepare_data(X, y)
        
        # ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸
        model = model_builder.build_hybrid_model(X_train.shape[1])
        
        # ì ì ˆí•œ í›ˆë ¨ (Early Stopping í¬í•¨)
        history = model_builder.train_model(
            X_train, y_train, X_test, y_test, 
            epochs=100, verbose=0
        )
        
        # ì„±ëŠ¥ í‰ê°€
        metrics = model_builder.evaluate_binary_model(X_test, y_test)
        
        self.results['improved'] = {
            'accuracy': metrics['accuracy'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1_score': metrics['f1_score'],
            'training_history': history.history
        }
        
        self.log_message(f"ğŸ¯ ê°œì„ ëœ ë°©ì‹ ì •í™•ë„: {metrics['accuracy']:.3f}")
        
        return metrics
    
    def test_cross_validation(self, X, y):
        """êµì°¨ê²€ì¦ìœ¼ë¡œ robustì„± í…ŒìŠ¤íŠ¸"""
        self.log_message("ğŸ”„ êµì°¨ê²€ì¦ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        
        model_builder = SecurityModelBuilder()
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        X_scaled = model_builder.scaler.fit_transform(X)
        y_binary = (y != 'BENIGN').astype(int) if isinstance(y[0], str) else y
        
        # MLP ëª¨ë¸ë¡œ êµì°¨ê²€ì¦
        model_builder.model_type = 'mlp'
        cv_results = model_builder.cross_validate(X_scaled, y_binary, cv_folds=5)
        
        self.results['cross_validation'] = cv_results
        
        self.log_message(f"ğŸ“Š êµì°¨ê²€ì¦ í‰ê·  ì •í™•ë„: {cv_results['mean']:.3f} Â± {cv_results['std']:.3f}")
        
        return cv_results
    
    def analyze_overfitting(self):
        """Overfitting ë¶„ì„"""
        self.log_message("ğŸ” Overfitting ë¶„ì„")
        
        analysis = {}
        
        # ê¸°ì¡´ ë°©ì‹ ë¶„ì„
        if 'baseline' in self.results:
            baseline_acc = self.results['baseline']['accuracy']
            if baseline_acc > 0.98:
                analysis['baseline_overfitting'] = "HIGH (ì˜ì‹¬ë¨)"
            elif baseline_acc > 0.95:
                analysis['baseline_overfitting'] = "MEDIUM"
            else:
                analysis['baseline_overfitting'] = "LOW (ì–‘í˜¸)"
        
        # ê°œì„ ëœ ë°©ì‹ ë¶„ì„
        if 'improved' in self.results:
            improved_acc = self.results['improved']['accuracy']
            if 0.85 <= improved_acc <= 0.95:
                analysis['improved_overfitting'] = "OPTIMAL (ëª©í‘œ ë‹¬ì„±)"
            elif improved_acc > 0.95:
                analysis['improved_overfitting'] = "ì—¬ì „íˆ ë†’ìŒ"
            else:
                analysis['improved_overfitting'] = "ë‚®ìŒ (underfitting ê°€ëŠ¥)"
        
        # êµì°¨ê²€ì¦ ì•ˆì •ì„±
        if 'cross_validation' in self.results:
            cv_std = self.results['cross_validation']['std']
            if cv_std < 0.02:
                analysis['stability'] = "ë§¤ìš° ì•ˆì •ì "
            elif cv_std < 0.05:
                analysis['stability'] = "ì•ˆì •ì "
            else:
                analysis['stability'] = "ë¶ˆì•ˆì • (overfitting ê°€ëŠ¥)"
        
        self.results['analysis'] = analysis
        return analysis
    
    def generate_report(self):
        """ìµœì¢… ë³´ê³ ì„œ ìƒì„±"""
        self.log_message("ğŸ“‹ ìµœì¢… ë³´ê³ ì„œ ìƒì„±")
        
        print("\n" + "="*80)
        print("ğŸ¯ CICIDS2017 Overfitting í•´ê²° ê²€ì¦ ë³´ê³ ì„œ")
        print("="*80)
        
        # ê¸°ë³¸ ì •ë³´
        print(f"ğŸ“… í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ”§ TensorFlow ë²„ì „: {check_tensorflow_availability()[1] or 'N/A'}")
        
        # ì„±ëŠ¥ ë¹„êµ
        print("\nğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼:")
        print("-" * 50)
        
        if 'baseline' in self.results and 'improved' in self.results:
            baseline = self.results['baseline']
            improved = self.results['improved']
            
            print(f"ê¸°ì¡´ ë°©ì‹ ì •í™•ë„:    {baseline['accuracy']:.3f}")
            print(f"ê°œì„ ëœ ë°©ì‹ ì •í™•ë„:  {improved['accuracy']:.3f}")
            print(f"ì •í™•ë„ ë³€í™”:       {improved['accuracy'] - baseline['accuracy']:+.3f}")
            
            print(f"\nê¸°ì¡´ ë°©ì‹ F1:       {baseline['f1_score']:.3f}")
            print(f"ê°œì„ ëœ ë°©ì‹ F1:     {improved['f1_score']:.3f}")
            print(f"F1 ë³€í™”:          {improved['f1_score'] - baseline['f1_score']:+.3f}")
        
        # êµì°¨ê²€ì¦ ê²°ê³¼
        if 'cross_validation' in self.results:
            cv = self.results['cross_validation']
            print(f"\nğŸ”„ êµì°¨ê²€ì¦ ê²°ê³¼:")
            print(f"í‰ê·  ì •í™•ë„: {cv['mean']:.3f} Â± {cv['std']:.3f}")
            print(f"95% ì‹ ë¢°êµ¬ê°„: Â±{cv['confidence_interval']:.3f}")
        
        # Overfitting ë¶„ì„
        if 'analysis' in self.results:
            analysis = self.results['analysis']
            print(f"\nğŸ” Overfitting ë¶„ì„:")
            print("-" * 30)
            for key, value in analysis.items():
                print(f"{key}: {value}")
        
        # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
        print(f"\nğŸ¯ ëª©í‘œ ë‹¬ì„± í‰ê°€:")
        print("-" * 30)
        
        if 'improved' in self.results:
            improved_acc = self.results['improved']['accuracy']
            if 0.85 <= improved_acc <= 0.95:
                print("âœ… ëª©í‘œ ë‹¬ì„±! ì •í™•ë„ê°€ 0.85~0.95 ë²”ìœ„ ë‚´")
            elif improved_acc > 0.95:
                print("âš ï¸ ë¶€ë¶„ ë‹¬ì„±: ì •í™•ë„ê°€ ì—¬ì „íˆ ë†’ìŒ (ì¶”ê°€ ì¡°ì • í•„ìš”)")
            else:
                print("âŒ ëª©í‘œ ë¯¸ë‹¬ì„±: ì •í™•ë„ê°€ 0.85 ë¯¸ë§Œ")
        
        print("\n" + "="*80)
        
        return self.results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ CICIDS2017 Overfitting í•´ê²° ê²€ì¦ ì‹œì‘")
    print("="*60)
    
    # TensorFlow í™•ì¸
    tf_available, tf_version = check_tensorflow_availability()
    if not tf_available:
        print("âŒ TensorFlowê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install tensorflow")
        return
    
    print(f"âœ… TensorFlow {tf_version} ì¤€ë¹„ ì™„ë£Œ")
    
    # ê²€ì¦ ì‹¤í–‰
    validator = OverfittingValidator()
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        dataset = validator.load_cicids_data(sample_size=30000)  # ì‘ì€ ìƒ˜í”Œë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        
        # 2. ë°ì´í„° ì „ì²˜ë¦¬
        X, y, features = validator.prepare_model_data(dataset)
        
        # 3. ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸
        validator.test_baseline_model(X, y)
        
        # 4. ê°œì„ ëœ ë°©ì‹ í…ŒìŠ¤íŠ¸
        validator.test_improved_model(X, y)
        
        # 5. êµì°¨ê²€ì¦
        validator.test_cross_validation(X, y)
        
        # 6. ë¶„ì„ ë° ë³´ê³ ì„œ
        validator.analyze_overfitting()
        results = validator.generate_report()
        
        # 7. ê²°ê³¼ ì €ì¥
        results_file = f"overfitting_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        validator.log_message(f"ğŸ“ ê²°ê³¼ ì €ì¥: {results_file}")
        
        return results
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None


if __name__ == "__main__":
    results = main()
