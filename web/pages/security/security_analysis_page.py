"""
CICIDS2017 ë³´ì•ˆ ì´ìƒ íƒì§€ ë¶„ì„ í˜ì´ì§€

Streamlit UI ì½”ë“œë§Œ í¬í•¨, ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì€ core.security ëª¨ë“ˆ ì‚¬ìš©
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

# TensorFlow import (ì¡°ê±´ë¶€)
try:
    import tensorflow as tf
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

# Core ëª¨ë“ˆì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ import
from core.security import (
    # CICIDSDataLoader,
    SecurityModelBuilder, 
    AttackPatternAnalyzer,
    DetectionOrchestrator,
    # ğŸ†• ê³ ë„í™”ëœ í†µí•© íƒì§€ ì—”ì§„
    UnifiedDetectionEngine,
    RealTimeSecurityMonitor,
    create_api_log_detector,
    create_network_traffic_detector,
    create_security_monitor,
    EnhancedTrafficSimulator,
    EnhancedPerformanceEvaluator,
    check_tensorflow_availability,
    install_tensorflow
)

from data.loaders.unified_security_loader import (
    UnifiedSecurityLoader as SecurityDataLoader,
    check_cicids_data_availability
)

def create_streamlit_progress_callback(total_epochs=50):
    """ìŠ¤íŠ¸ë¦¼ë¦¿ìš© ì§„í–‰ë¥  ì½œë°± ìƒì„±"""
    if not TF_AVAILABLE:
        return None
    
    # ì „ì—­ ë³€ìˆ˜ë¡œ ì‚¬ìš©í•  ì»´í¬ë„ŒíŠ¸ë“¤
    progress_components = {
        'progress_bar': st.progress(0),
        'status_text': st.empty(),
        'metrics_container': st.empty()
    }
    
    class StreamlitProgressCallback(tf.keras.callbacks.Callback):
        def __init__(self, total_epochs=50, components=None):
            super().__init__()
            self.total_epochs = total_epochs
            self.current_epoch = 0
            self.components = components or progress_components
        
        def on_train_begin(self, logs=None):
            self.components['status_text'].text("ğŸš€ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            self.components['progress_bar'].progress(0)
        
        def on_epoch_begin(self, epoch, logs=None):
            self.current_epoch = epoch + 1
            self.components['status_text'].text(f"ğŸ“ˆ Epoch {self.current_epoch}/{self.total_epochs} í›ˆë ¨ ì¤‘...")
        
        def on_epoch_end(self, epoch, logs=None):
            logs = logs or {}
            progress = (epoch + 1) / self.total_epochs
            self.components['progress_bar'].progress(progress)
            
            # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ í‘œì‹œ
            with self.components['metrics_container'].container():
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Loss", f"{logs.get('loss', 0.0):.4f}")
                with col2:
                    st.metric("Accuracy", f"{logs.get('accuracy', 0.0):.4f}")
                with col3:
                    if 'val_loss' in logs:
                        st.metric("Val Loss", f"{logs.get('val_loss', 0.0):.4f}")
                with col4:
                    if 'val_accuracy' in logs:
                        st.metric("Val Accuracy", f"{logs.get('val_accuracy', 0.0):.4f}")
            
            self.components['status_text'].text(
                f"âœ… Epoch {epoch + 1}/{self.total_epochs} ì™„ë£Œ - "
                f"Loss: {logs.get('loss', 0.0):.4f}, "
                f"Accuracy: {logs.get('accuracy', 0.0):.4f}"
            )
        
        def on_train_end(self, logs=None):
            self.components['progress_bar'].progress(1.0)
            self.components['status_text'].text("ğŸ‰ ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    return StreamlitProgressCallback(total_epochs, progress_components)


def show_security_analysis_page():
    """CICIDS2017 ë³´ì•ˆ ì´ìƒ íƒì§€ ë¶„ì„ í˜ì´ì§€"""
    st.header("ğŸ”’ CICIDS2017 ë„¤íŠ¸ì›Œí¬ ì´ìƒ íƒì§€ ë¶„ì„")
    
    # ë³´ì•ˆ ë¶„ì„ ì†Œê°œ
    with st.expander("ğŸ¤” ì™œ ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ë¶„ì„ì´ ì¤‘ìš”í• ê¹Œìš”?", expanded=True):
        st.markdown("""
        ### ğŸ¯ ì‹¤ë¬´ì—ì„œì˜ ë³´ì•ˆ ì´ìƒ íƒì§€
        
        **ê¸ˆìœµê¶Œ SIì—ì„œ í•µì‹¬ ì—…ë¬´:**
        - **ì‹¤ì‹œê°„ ì‚¬ê¸° ê±°ë˜ íƒì§€**: ê³ ê°ì˜ ì´ìƒ ê±°ë˜ íŒ¨í„´ ì¦‰ì‹œ ê°ì§€
        - **ë‚´ë¶€ì ìœ„í˜‘ ëª¨ë‹ˆí„°ë§**: ì§ì›ì˜ ë¹„ì •ìƒì  ì‹œìŠ¤í…œ ì ‘ê·¼ íƒì§€
        - **DDoS ê³µê²© ëŒ€ì‘**: ëŒ€ëŸ‰ ê±°ë˜ ìš”ì²­ì˜ ì •ìƒ/ê³µê²© ì—¬ë¶€ íŒë³„
        
        **CICIDS2017 ë°ì´í„°ì…‹ì˜ íŠ¹ë³„í•¨:**
        - **ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½**: ìºë‚˜ë‹¤ ì‚¬ì´ë²„ë³´ì•ˆ ì—°êµ¬ì†Œì—ì„œ 5ì¼ê°„ ì‹¤ì œ ìˆ˜ì§‘
        - **ìµœì‹  ê³µê²© íŒ¨í„´**: 2017ë…„ ë‹¹ì‹œ ìµœì‹  ê³µê²© ê¸°ë²•ë“¤ í¬í•¨
        - **280ë§Œ+ ì‹¤ì œ íŠ¸ë˜í”½**: 25ëª…ì˜ ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ ê¸°ë°˜
        
        ### ğŸŒ± ê¸°ì¡´ ê³ ê° ë¶„ì„ê³¼ì˜ ì°¨ì´ì 
        
        **ê³ ê° ì„¸ë¶„í™” vs ë³´ì•ˆ íƒì§€:**
        - ê³ ê° ë¶„ì„: ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì„ ìœ„í•œ **ê¸°íšŒ ë°œê²¬**
        - ë³´ì•ˆ ë¶„ì„: ìœ„í—˜ì„ **ì‚¬ì „ì— ì°¨ë‹¨**í•˜ì—¬ ì†ì‹¤ ë°©ì§€
        
        **ë°ì´í„° íŠ¹ì„±ì˜ ì°¨ì´:**
        - ê³ ê° ë°ì´í„°: ë‚˜ì´, ì†Œë“, ì†Œë¹„ (3ê°œ íŠ¹ì„±)
        - ë„¤íŠ¸ì›Œí¬ ë°ì´í„°: íŒ¨í‚· í¬ê¸°, í”Œë¡œìš° ì§€ì†ì‹œê°„, í”„ë¡œí† ì½œ ë“± (78ê°œ íŠ¹ì„±)
        """)

    # ë©”ë‰´ ì„ íƒ
    analysis_menu = st.selectbox(
        "ë¶„ì„ ë‹¨ê³„ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        [
            "ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ",
            "ğŸ” ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íƒìƒ‰ì  ë¶„ì„", 
            "âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„",
            "ğŸŒ± ë”¥ëŸ¬ë‹ ì´ìƒ íƒì§€ ëª¨ë¸",
            "ğŸ¯ Overfitting í•´ê²° ê²€ì¦ (NEW!)",
            "ğŸ“Š ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸",
            "ğŸ† ì¢…í•© ì„±ëŠ¥ í‰ê°€"
        ]
    )

    if analysis_menu == "ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ":
        show_data_download_section()
    elif analysis_menu == "ğŸ” ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íƒìƒ‰ì  ë¶„ì„":
        show_exploratory_analysis_section()
    elif analysis_menu == "âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„":
        show_attack_pattern_analysis()
    elif analysis_menu == "ğŸŒ± ë”¥ëŸ¬ë‹ ì´ìƒ íƒì§€ ëª¨ë¸":
        show_deep_learning_detection()
    elif analysis_menu == "ğŸ¯ Overfitting í•´ê²° ê²€ì¦ (NEW!)":
        show_overfitting_validation()
    elif analysis_menu == "ğŸ“Š ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸":
        show_real_time_prediction()
    elif analysis_menu == "ğŸ† ì¢…í•© ì„±ëŠ¥ í‰ê°€":
        show_comprehensive_evaluation()


def load_real_cicids_data():
    """ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ"""
    from data.loaders.cicids_working_files_loader import WorkingCICIDSLoader
    
    data_dir = "C:/keydev/integrated-commerce-and-security-analytics/data/cicids2017"
    loader = WorkingCICIDSLoader(data_dir)
    
    # ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¡œë“œ (30ë§Œ ê°œ)
    dataset = loader.load_working_files(target_samples=300000)
    
    st.session_state.cicids_data = dataset
    st.success(f"âœ… ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(dataset):,}ê°œ")
    
    # ë¼ë²¨ ë¶„í¬ í‘œì‹œ
    st.write("ğŸ“Š ë¼ë²¨ ë¶„í¬:")
    label_counts = dataset['Label'].value_counts()
    for label, count in label_counts.items():
        pct = (count / len(dataset)) * 100
        st.write(f"- {label}: {count:,}ê°œ ({pct:.1f}%)")
    
    return dataset


def show_data_download_section():
    """ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ì„¹ì…˜"""
    st.subheader("ğŸ“¥ CICIDS2017 ë°ì´í„°ì…‹ ì¤€ë¹„")
    
    # ğŸ”¥ ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ ì¶”ê°€
    data_source = st.radio(
        "ğŸ”¥ ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ:",
        ["ì‹¤ì œ CICIDS2017 ë°ì´í„° (ê¶Œì¥)", "ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°"]
    )
    
    if data_source == "ì‹¤ì œ CICIDS2017 ë°ì´í„° (ê¶Œì¥)":
        st.info("âš¡ ì´ì „ ì±„íŒ…ì—ì„œ ì™„ì„±ëœ ì‘ë™í•˜ëŠ” íŒŒì¼ ë¡œë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        if st.button("ğŸš€ ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ"):
            with st.spinner("ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ ì¤‘..."):
                try:
                    load_real_cicids_data()
                    st.balloons()
                    st.info("âœ… ì´ì œ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì„¸ìš”!")
                except Exception as e:
                    st.error(f"âŒ ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                    st.info("ğŸ”§ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ëŒ€ì‹  ìƒì„±í•©ë‹ˆë‹¤...")
                    # í´ë°±: ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
                    data_loader = SecurityDataLoader()
                    enhanced_data = data_loader.generate_sample_data(total_samples=10000, attack_ratio=0.6)
                    st.session_state.cicids_data = enhanced_data
                    st.session_state.enhanced_data_generated = True
                    display_data_summary(enhanced_data)
        return
    
    # ê¸°ì¡´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œì§
    # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    data_loader = SecurityDataLoader()
    
    # ì„¸ì…˜ ìƒíƒœ ë””ë²„ê¹…
    with st.expander("ğŸ”§ í˜„ì¬ ì„¸ì…˜ ìƒíƒœ ë””ë²„ê¹…"):
        st.write("**ì„¸ì…˜ ìƒíƒœ í‚¤ë“¤:**", list(st.session_state.keys()))
        
        if 'cicids_data' in st.session_state:
            data = st.session_state.cicids_data
            st.write(f"**í˜„ì¬ ë°ì´í„° í¬ê¸°:** {len(data)}")
            if 'Label' in data.columns:
                attack_count = (data['Label'] != 'BENIGN').sum()
                attack_ratio = attack_count / len(data) * 100
                st.write(f"**í˜„ì¬ ê³µê²© ë°ì´í„°:** {attack_count}ê°œ ({attack_ratio:.1f}%)")
        
        # ê°•ì œ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ’¥ ëª¨ë“  ì„¸ì…˜ ë°ì´í„° ì‚­ì œ", key="clear_session_button"):
            keys_to_delete = ['cicids_data', 'enhanced_data_generated', 'file_load_attempted']
            for key in keys_to_delete:
                if key in st.session_state:
                    del st.session_state[key]
            st.success("âœ… ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ!")
            st.rerun()
    
    # ë‹¤ìš´ë¡œë“œ ì•ˆë‚´
    st.info("""
    **ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë°©ë²•:**
    
    **ì˜µì…˜ 1: ê³µì‹ ì†ŒìŠ¤ (ê¶Œì¥)**
    1. https://www.unb.ca/cic/datasets/ids-2017.html ë°©ë¬¸
    2. "MachineLearningCSV.zip" ë‹¤ìš´ë¡œë“œ (ì•½ 2.8GB)
    3. ì••ì¶• í•´ì œ í›„ CSV íŒŒì¼ë“¤ì„ `data/cicids2017/` í´ë”ì— ì €ì¥
    
    **ì˜µì…˜ 2: Kaggle (í¸ë¦¬í•¨)**
    1. https://www.kaggle.com/datasets/dhoogla/cicids2017 ë°©ë¬¸
    2. "Download" í´ë¦­í•˜ì—¬ ë‹¤ìš´ë¡œë“œ
    3. ì••ì¶• í•´ì œ í›„ CSV íŒŒì¼ë“¤ì„ `data/cicids2017/` í´ë”ì— ì €ì¥
    """)
    
    # ê¸°ì¡´ ë°ì´í„° í™•ì¸
    if 'cicids_data' in st.session_state and st.session_state.get('enhanced_data_generated', False):
        display_existing_data()
        return
    
    # ì¦‰ì‹œ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì˜µì…˜
    st.markdown("### ğŸš€ ê¶Œì¥: ì¦‰ì‹œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    
    if st.button("ğŸ† í–¥ìƒëœ ê³µê²© ë°ì´í„° 60% ì¦‰ì‹œ ìƒì„±", key="priority_emergency_button"):
        with st.spinner("í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘..."):
            enhanced_data = data_loader.generate_sample_data(
                total_samples=10000, 
                attack_ratio=0.6,
                realistic_mode=True  # í˜„ì‹¤ì ì¸ ë°ì´í„° ìƒì„±
            )
            
            # ì„¸ì…˜ì— ì €ì¥
            st.session_state.cicids_data = enhanced_data
            st.session_state.enhanced_data_generated = True
            
            display_data_summary(enhanced_data)
            st.success("ğŸ‰ ì„±ê³µ! ì´ì œ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì„¸ìš”!")
            st.balloons()
    
    # ì‹¤ì œ íŒŒì¼ ë¡œë“œ ì˜µì…˜
    st.markdown("---")
    st.markdown("### ğŸ“ ì‹¤ì œ íŒŒì¼ ë¡œë“œ (ì°¸ê³ ìš©)")
    st.info("ì‹¤ì œ íŒŒì¼ì´ ìˆì–´ë„ Monday íŒŒì¼ì€ ê³µê²© ë°ì´í„°ê°€ 0%ì…ë‹ˆë‹¤. ìœ„ì˜ ìƒ˜í”Œ ë°ì´í„° ìƒì„±ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„° í™•ì¸
    data_status = data_loader.check_data_availability()
    
    if data_status["available"]:
        st.success(f"âœ… CICIDS2017 ë°ì´í„° ë°œê²¬! ì´ {len(data_status['files'])}ê°œ íŒŒì¼")
        
        if st.button("ğŸš€ ì‹¤ì œ íŒŒì¼ ë¡œë“œ ì‹œë„"):
            load_real_files(data_loader, data_status['files'])
    else:
        st.warning("âš ï¸ CICIDS2017 ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


def display_existing_data():
    """ê¸°ì¡´ ë°ì´í„° í‘œì‹œ"""
    data = st.session_state.cicids_data
    total_count = len(data)
    attack_count = (data['Label'] != 'BENIGN').sum()
    attack_ratio = attack_count / total_count * 100
    
    st.success(f"âœ… í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ì´ë¯¸ ì¤€ë¹„ë¨! ì´ {total_count:,}ê°œ (ê³µê²© {attack_count:,}ê°œ, {attack_ratio:.1f}%)")
    
    display_data_summary(data)
    st.info("ğŸš€ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")


def display_data_summary(data):
    """ë°ì´í„° ìš”ì•½ í‘œì‹œ"""
    # ë¼ë²¨ ë¶„í¬ í‘œì‹œ
    label_counts = data['Label'].value_counts()
    label_df = pd.DataFrame({
        'ë¼ë²¨': label_counts.index,
        'ê°œìˆ˜': label_counts.values,
        'ë¹„ìœ¨': (label_counts.values / len(data) * 100).round(2)
    })
    st.dataframe(label_df, use_container_width=True)


def load_real_files(data_loader, file_paths):
    """ì‹¤ì œ íŒŒì¼ ë¡œë“œ"""
    with st.spinner("ì‹¤ì œ íŒŒì¼ ë¡œë“œ ì¤‘..."):
        try:
            # ì²« ë²ˆì§¸ íŒŒì¼ë§Œ ë¡œë“œ (ìƒ˜í”Œ)
            df, encoding = data_loader.load_file_with_encoding(file_paths[0], max_rows=10000)
            
            st.session_state.cicids_data = df
            
            st.success(f"âœ… ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
            display_data_summary(df)
            
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            st.info("ğŸ”§ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ëŒ€ì‹  ìƒì„±í•©ë‹ˆë‹¤...")
            
            # í´ë°±: ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            enhanced_data = data_loader.generate_sample_data(total_samples=10000, attack_ratio=0.6)
            st.session_state.cicids_data = enhanced_data
            st.session_state.enhanced_data_generated = True
            
            display_data_summary(enhanced_data)
            st.success("âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!")


def show_exploratory_analysis_section():
    """ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íƒìƒ‰ì  ë¶„ì„"""
    st.subheader("ğŸ” ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„")
    
    # ë¶„ì„ ëª©ì  ì„¤ëª…
    with st.expander("ğŸ¯ ì´ ë¶„ì„ì˜ ëª©ì ì€?", expanded=False):
        st.markdown("""
        ### ğŸ“Š ì „ì²´ ë°ì´í„° í˜„í™© íŒŒì•… (EDA)
        
        **ì´ ë‹¨ê³„ì—ì„œ í•˜ëŠ” ì¼:**
        - ì „ì²´ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ì˜ ê¸°ë³¸ì ì¸ ë¶„í¬ íŒŒì•…
        - ì •ìƒ íŠ¸ë˜í”½ê³¼ ê³µê²© íŠ¸ë˜í”½ì˜ ì „ë°˜ì ì¸ ë¹„ìœ¨ í™•ì¸
        - ë„¤íŠ¸ì›Œí¬ íŠ¹ì„±ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
        - ë°ì´í„° í’ˆì§ˆ ë° ì´ìƒì¹˜ í™•ì¸
        """)
    
    # ë°ì´í„° ë¡œë“œ í™•ì¸
    if 'cicids_data' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return
    
    data = st.session_state.cicids_data
    st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ë ˆì½”ë“œ, {len(data.columns)}ê°œ íŠ¹ì„±")
    
    # ê¸°ë³¸ í†µê³„ í‘œì‹œ
    display_basic_statistics(data)
    
    # ê³µê²© ìœ í˜•ë³„ ë¶„í¬ ë¶„ì„
    show_attack_distribution(data)
    
    # ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ë¶„í¬ ë¶„ì„
    show_feature_distribution(data)
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    show_correlation_analysis(data)


def display_basic_statistics(data):
    """ê¸°ë³¸ í†µê³„ í‘œì‹œ"""
    col1, col2, col3, col4 = st.columns(4)
    
    normal_count = (data['Label'] == 'BENIGN').sum()
    attack_count = len(data) - normal_count
    attack_ratio = attack_count / len(data) * 100
    
    with col1:
        st.metric("ì´ íŠ¸ë˜í”½ ìˆ˜", f"{len(data):,}")
    with col2:
        st.metric("ì •ìƒ íŠ¸ë˜í”½", f"{normal_count:,}")
    with col3:
        st.metric("ê³µê²© íŠ¸ë˜í”½", f"{attack_count:,}")
    with col4:
        st.metric("ê³µê²© ë¹„ìœ¨", f"{attack_ratio:.1f}%")


def show_attack_distribution(data):
    """ê³µê²© ìœ í˜•ë³„ ë¶„í¬ í‘œì‹œ"""
    st.subheader("ğŸ“Š ê³µê²© ìœ í˜•ë³„ ë¶„í¬")
    
    label_counts = data['Label'].value_counts()
    
    col1, col2 = st.columns(2)
    
    with col1:
        # íŒŒì´ ì°¨íŠ¸
        fig = px.pie(
            values=label_counts.values,
            names=label_counts.index,
            title="ê³µê²© ìœ í˜•ë³„ ë¶„í¬",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ë§‰ëŒ€ ì°¨íŠ¸ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        fig = px.bar(
            x=label_counts.index,
            y=label_counts.values,
            title="ê³µê²© ìœ í˜•ë³„ ê°œìˆ˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)",
            log_y=True,
            color=label_counts.values,
            color_continuous_scale='Viridis'
        )
        fig.update_layout(xaxis_title="ê³µê²© ìœ í˜•", yaxis_title="ê°œìˆ˜ (ë¡œê·¸)")
        st.plotly_chart(fig, use_container_width=True)


def show_feature_distribution(data):
    """ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ë¶„í¬ ë¶„ì„"""
    st.subheader("ğŸ“ˆ ì£¼ìš” ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ë¶„í¬")
    
    # ì´ˆë¡ìƒ‰ multiselect ìŠ¤íƒ€ì¼ë§
    st.markdown("""
    <style>
    /* multiselect ë²„íŠ¼ ì´ˆë¡ìƒ‰ ìŠ¤íƒ€ì¼ë§ */
    .stMultiSelect > div > div > div {
        background-color: #16A34A !important;
        color: white !important;
        border: 1px solid #15803D !important;
    }
    .stMultiSelect > div > div > div:hover {
        background-color: #15803D !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ì„¤ëª…
    with st.expander("ğŸ“ ë„¤íŠ¸ì›Œí¬ íŠ¹ì„±ë“¤ì´ ë­˜ ì˜ë¯¸í•˜ë‚˜ìš”?", expanded=False):
        st.markdown("""
        ### ğŸŒ ì£¼ìš” ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ìƒì„¸ ì„¤ëª…
        
        **í”Œë¡œìš° ê¸°ë³¸ ì •ë³´:**
        - `Flow_Duration`: í”Œë¡œìš° ì§€ì† ì‹œê°„ (ë§ˆì´í¬ë¡œì´ˆ)
        - `Total_Fwd_Packets`: ì „ì²´ ì „ì†¡ íŒ¨í‚· ìˆ˜
        - `Total_Backward_Packets`: ì „ì²´ ì‘ë‹µ íŒ¨í‚· ìˆ˜
        
        **í”Œë¡œìš° ì†ë„ (í•µì‹¬ ì§€í‘œ):**
        - `Flow_Bytes/s`: ì´ˆë‹¹ ë°”ì´íŠ¸ ìˆ˜ (ëŒ€ì—­í­ ì‚¬ìš©ëŸ‰)
        - `Flow_Packets/s`: ì´ˆë‹¹ íŒ¨í‚· ìˆ˜ (íŒ¨í‚· ë¹ˆë„)
        
        **IAT (Inter-Arrival Time) íŠ¹ì„±:**
        - `Flow_IAT_Mean`: í”Œë¡œìš° ë‚´ íŒ¨í‚· ë„ì°© ê°„ê²©ì˜ í‰ê· 
        """)
    
    # ë¶„ì„í•  íŠ¹ì„± ì„ íƒ
    numeric_features = [col for col in data.columns if col != 'Label' and data[col].dtype in ['int64', 'float64']]
    selected_features = st.multiselect(
        "ë¶„ì„í•  íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”:",
        numeric_features,
        default=numeric_features[:4]  # ì²˜ìŒ 4ê°œ ê¸°ë³¸ ì„ íƒ
    )
    
    if selected_features:
        display_feature_comparison(data, selected_features)


def display_feature_comparison(data, features):
    """íŠ¹ì„±ë³„ ì •ìƒ vs ê³µê²© ë¹„êµ"""
    n_features = len(features)
    
    # ë™ì  ê·¸ë¦¬ë“œ ê³„ì‚°
    if n_features <= 4:
        rows, cols = 2, 2
    elif n_features <= 6:
        rows, cols = 2, 3
    elif n_features <= 9:
        rows, cols = 3, 3
    else:
        rows, cols = 4, 3  # ìµœëŒ€ 12ê°œê¹Œì§€
    
    # ì‹¤ì œ í‘œì‹œí•  íŠ¹ì„± ìˆ˜ (ê·¸ë¦¬ë“œ í¬ê¸°ì— ë§ì¶¤)
    max_features = min(n_features, rows * cols)
    display_features = features[:max_features]
    
    fig = make_subplots(
        rows=rows, cols=cols,
        subplot_titles=display_features,
        specs=[[{"secondary_y": False} for _ in range(cols)] for _ in range(rows)]
    )
    
    for i, feature in enumerate(display_features):
        row = i // cols + 1
        col = i % cols + 1
        
        # ì •ìƒ íŠ¸ë˜í”½ ë¶„í¬
        normal_data_subset = data[data['Label'] == 'BENIGN'][feature]
        attack_data_subset = data[data['Label'] != 'BENIGN'][feature]
        
        fig.add_histogram(
            x=normal_data_subset, 
            name=f'{feature} - ì •ìƒ',
            row=row, col=col,
            opacity=0.7,
            nbinsx=50,
            showlegend=(i == 0)  # ì²« ë²ˆì§¸ë§Œ ë²”ë¡€ í‘œì‹œ
        )
        fig.add_histogram(
            x=attack_data_subset,
            name=f'{feature} - ê³µê²©', 
            row=row, col=col,
            opacity=0.7,
            nbinsx=50,
            showlegend=(i == 0)  # ì²« ë²ˆì§¸ë§Œ ë²”ë¡€ í‘œì‹œ
        )
    
    # ë†’ì´ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •
    height = max(400, rows * 250)
    fig.update_layout(height=height, title_text="ì •ìƒ vs ê³µê²© íŠ¸ë˜í”½ íŠ¹ì„± ë¶„í¬")
    
    # ì„ íƒëœ íŠ¹ì„±ì´ í‘œì‹œ ê°€ëŠ¥í•œ ìˆ˜ë³´ë‹¤ ë§ì€ ê²½ìš° ì•ˆë‚´
    if n_features > max_features:
        st.warning(f"âš ï¸ ì„ íƒëœ íŠ¹ì„± {n_features}ê°œ ì¤‘ ì²˜ìŒ {max_features}ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤. ë” ë§ì€ íŠ¹ì„±ì„ ë³´ë ¤ë©´ ì—¬ëŸ¬ ë²ˆì— ë‚˜ëˆ„ì–´ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    st.plotly_chart(fig, use_container_width=True)


def show_correlation_analysis(data):
    """ìƒê´€ê´€ê³„ ë¶„ì„"""
    st.subheader("ğŸ”— íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„")
    
    # ì´ˆë¡ìƒ‰ multiselect ìŠ¤íƒ€ì¼ë§ (ë‹¤ë¥¸ keyë¡œ êµ¬ë¶„)
    st.markdown("""
    <style>
    /* ìƒê´€ê´€ê³„ multiselect ë²„íŠ¼ ì´ˆë¡ìƒ‰ ìŠ¤íƒ€ì¼ë§ */
    div[data-testid="stMultiSelect"] > div > div {
        background: linear-gradient(135deg, #16A34A, #15803D) !important;
        border: 1px solid #15803D !important;
        border-radius: 6px !important;
    }
    div[data-testid="stMultiSelect"] > div > div:hover {
        background: linear-gradient(135deg, #15803D, #166534) !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 4px 8px rgba(22, 163, 74, 0.25) !important;
    }
    /* ì„ íƒëœ íƒœê·¸ ìŠ¤íƒ€ì¼ë§ */
    div[data-testid="stMultiSelect"] span {
        background-color: #22C55E !important;
        color: white !important;
        border: 1px solid #16A34A !important;
    }
    </style>
    """, unsafe_allow_html=True)
    
    numeric_features = [col for col in data.columns if col != 'Label' and data[col].dtype in ['int64', 'float64']]
    selected_features = st.multiselect(
        "ìƒê´€ê´€ê³„ ë¶„ì„í•  íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”:",
        numeric_features,
        default=numeric_features[:6],
        key="correlation_features"
    )
    
    if len(selected_features) >= 2:
        # ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚°
        corr_matrix = data[selected_features].corr()
        
        # íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”
        fig = px.imshow(
            corr_matrix,
            title="íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ",
            color_continuous_scale='RdBu',
            aspect="auto"
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
        
        # ë†’ì€ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ ì°¾ê¸°
        display_high_correlation_pairs(corr_matrix)


def display_high_correlation_pairs(corr_matrix):
    """ë†’ì€ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ í‘œì‹œ"""
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            corr_val = corr_matrix.iloc[i, j]
            if abs(corr_val) > 0.7:
                high_corr_pairs.append({
                    'íŠ¹ì„± 1': corr_matrix.columns[i],
                    'íŠ¹ì„± 2': corr_matrix.columns[j],
                    'ìƒê´€ê³„ìˆ˜': round(corr_val, 3)
                })
    
    if high_corr_pairs:
        st.write("**ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” íŠ¹ì„± ìŒë“¤:**")
        st.dataframe(pd.DataFrame(high_corr_pairs), use_container_width=True)
    else:
        st.info("ì„ íƒëœ íŠ¹ì„±ë“¤ ê°„ì— ê°•í•œ ìƒê´€ê´€ê³„(|r| > 0.7)ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def show_attack_pattern_analysis():
    """ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„"""
    st.subheader("âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„")
    
    # ë¶„ì„ ëª©ì  ì„¤ëª…
    with st.expander("ğŸ¯ ì´ ë¶„ì„ì˜ ëª©ì ì€?", expanded=False):
        st.markdown("""
        ### ğŸ” ì •ìƒ vs ê³µê²© ì°¨ì´ì  ë¶„ì„
        
        **ì´ ë‹¨ê³„ì—ì„œ í•˜ëŠ” ì¼:**
        - ì •ìƒ íŠ¸ë˜í”½ê³¼ ê° ê³µê²© ìœ í˜•ì˜ **ì°¨ë³„í™” íŠ¹ì„±** ë°œê²¬
        - ê³µê²©ë³„ **íŠ¹ì„±ì  íŒ¨í„´** ë¶„ì„ (ì–´ë–¤ íŠ¹ì„±ì´ ê°€ì¥ ë‹¤ë¥¸ê°€?)
        - ê³µê²©ì˜ **ì‹œê°„ì  íŒ¨í„´** ë¶„ì„ (ì‹œê°„ì— ë”°ë¥¸ ë³€í™”)
        - íƒì§€ ëª¨ë¸ì„ ìœ„í•œ **ì£¼ìš” íŠ¹ì„±** ì‹ë³„
        """)
    
    if 'cicids_data' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        if st.button("ğŸ† ì¦‰ì‹œ í›ˆë ¨ìš© ë°ì´í„° ìƒì„±", key="instant_data_generation"):
            data_loader = SecurityDataLoader()
            enhanced_data = data_loader.generate_sample_data(total_samples=10000, attack_ratio=0.6)
            st.session_state.cicids_data = enhanced_data
            st.session_state.enhanced_data_generated = True
            st.rerun()
        return
    
    data = st.session_state.cicids_data
    
    # ê³µê²© ë°ì´í„° ë¹„ìœ¨ ì²´í¬
    attack_count = (data['Label'] != 'BENIGN').sum()
    attack_ratio = attack_count / len(data) * 100
    
    if attack_ratio < 5:
        st.error(f"âŒ ê³µê²© ë°ì´í„° ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤ ({attack_ratio:.1f}%)")
        if st.button("ğŸ† ì¦‰ì‹œ ê³µê²© ë°ì´í„° 60% ìƒì„±", key="fix_attack_data"):
            data_loader = SecurityDataLoader()
            enhanced_data = data_loader.generate_sample_data(total_samples=10000, attack_ratio=0.6)
            st.session_state.cicids_data = enhanced_data
            st.session_state.enhanced_data_generated = True
            st.rerun()
        return
    
    # ê³µê²© íŒ¨í„´ ë¶„ì„ ìˆ˜í–‰
    perform_attack_pattern_analysis(data)


def perform_attack_pattern_analysis(data):
    """ê³µê²© íŒ¨í„´ ë¶„ì„ ìˆ˜í–‰"""
    # ê³µê²© ìœ í˜• ì„ íƒ
    attack_types = [label for label in data['Label'].unique() if label != 'BENIGN']
    selected_attack = st.selectbox("ë¶„ì„í•  ê³µê²© ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:", ['ì „ì²´ ê³µê²©'] + attack_types)
    
    if selected_attack == 'ì „ì²´ ê³µê²©':
        attack_data = data[data['Label'] != 'BENIGN']
        attack_title = "ì „ì²´ ê³µê²©"
    else:
        attack_data = data[data['Label'] == selected_attack]
        attack_title = selected_attack
    
    normal_data = data[data['Label'] == 'BENIGN']
    
    st.info(f"**{attack_title}** ë¶„ì„ ì¤‘ - ê³µê²©: {len(attack_data)}ê°œ, ì •ìƒ: {len(normal_data)}ê°œ")
    
    # ê³µê²© íŒ¨í„´ ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = AttackPatternAnalyzer()
    
    # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
    show_feature_importance_analysis(data, analyzer, attack_title)
    
    # ì‹œê°„ì  íŒ¨í„´ ë¶„ì„
    show_temporal_pattern_analysis(attack_data, attack_title)


def show_feature_importance_analysis(data, analyzer, attack_title):
    """íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ í‘œì‹œ"""
    st.subheader(f"ğŸ“Š {attack_title}ì˜ íŠ¹ì„±ì  íŒ¨í„´")
    
    numeric_features = [col for col in data.columns if col != 'Label' and data[col].dtype in ['int64', 'float64']]
    feature_comparison = analyzer.analyze_feature_importance(data, numeric_features)
    
    # DataFrameìœ¼ë¡œ ë³€í™˜
    comparison_df = pd.DataFrame(feature_comparison)
    comparison_df = comparison_df.sort_values('ratio', ascending=False)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ íŠ¹ì„±ë“¤
        top_ratio_features = comparison_df.head(10)
        fig = px.bar(
            top_ratio_features,
            x='ratio',
            y='feature',
            title=f"{attack_title}ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§„ íŠ¹ì„±ë“¤",
            orientation='h',
            color='ratio',
            color_continuous_scale='Reds'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ì ˆëŒ€ ì°¨ì´ê°€ ê°€ì¥ í° íŠ¹ì„±ë“¤
        top_diff_features = comparison_df.sort_values('absolute_difference', ascending=False).head(10)
        fig = px.bar(
            top_diff_features,
            x='absolute_difference',
            y='feature',
            title=f"{attack_title}ì—ì„œ ì ˆëŒ€ ì°¨ì´ê°€ í° íŠ¹ì„±ë“¤",
            orientation='h',
            color='absolute_difference',
            color_continuous_scale='Blues'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # ìƒì„¸ ë¹„êµ í…Œì´ë¸”
    with st.expander("ğŸ“‹ ì „ì²´ íŠ¹ì„± ë¹„êµ í…Œì´ë¸”"):
        display_df = comparison_df.copy()
        display_df['normal_mean'] = display_df['normal_mean'].round(2)
        display_df['attack_mean'] = display_df['attack_mean'].round(2)
        display_df['ratio'] = display_df['ratio'].round(2)
        display_df['absolute_difference'] = display_df['absolute_difference'].round(2)
        st.dataframe(display_df, use_container_width=True)


def show_temporal_pattern_analysis(attack_data, attack_title):
    """ì‹œê°„ì  íŒ¨í„´ ë¶„ì„ í‘œì‹œ"""
    st.subheader(f"â° {attack_title}ì˜ ì‹œê°„ì  íŒ¨í„´")
    
    # ë°ì´í„°ì— ê°€ìƒì˜ ì‹œê°„ ì¸ë±ìŠ¤ ì¶”ê°€
    time_series_data = attack_data.copy()
    time_series_data['ì‹œê°„_ì¸ë±ìŠ¤'] = range(len(time_series_data))
    
    # ì£¼ìš” íŠ¹ì„±ì˜ ì‹œê³„ì—´ íŒ¨í„´ (ì²˜ìŒ 3ê°œë§Œ)
    numeric_features = [col for col in attack_data.columns if col != 'Label' and attack_data[col].dtype in ['int64', 'float64']]
    key_features = numeric_features[:3]
    
    fig = make_subplots(
        rows=len(key_features), cols=1,
        shared_xaxes=True,
        subplot_titles=[f"{feature} ì‹œê³„ì—´ íŒ¨í„´" for feature in key_features]
    )
    
    for i, feature in enumerate(key_features):
        # ì´ë™í‰ê· ìœ¼ë¡œ ìŠ¤ë¬´ë”©
        window_size = max(1, len(time_series_data) // 100)
        smoothed_values = time_series_data[feature].rolling(window=window_size, center=True).mean()
        
        fig.add_scatter(
            x=time_series_data['ì‹œê°„_ì¸ë±ìŠ¤'],
            y=smoothed_values,
            mode='lines',
            name=feature,
            row=i+1, col=1
        )
    
    fig.update_layout(height=600, title_text=f"{attack_title} ì£¼ìš” íŠ¹ì„±ë“¤ì˜ ì‹œê³„ì—´ íŒ¨í„´")
    st.plotly_chart(fig, use_container_width=True)


def show_deep_learning_detection():
    """ë”¥ëŸ¬ë‹ ì´ìƒ íƒì§€ ëª¨ë¸"""
    st.subheader("ğŸŒ± ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ì´ìƒ íƒì§€")
    
    # TensorFlow ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    tf_available, tf_version = check_tensorflow_availability()
    
    if not tf_available:
        show_tensorflow_installation()
        return
    
    st.success(f"âœ… TensorFlow {tf_version if tf_version else ''} ì‚¬ìš© ê°€ëŠ¥!")
    
    if 'cicids_data' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
    
    data = st.session_state.cicids_data
    
    # ëª¨ë¸ ì„ íƒ
    model_option = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
        [
            "ğŸ”¥ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (MLP + CNN)",
            "âš¡ MLP ë¶„ë¥˜ ëª¨ë¸", 
            "ğŸ“Š CNN ì‹œê³„ì—´ ëª¨ë¸",
            "ğŸ”„ ì˜¤í† ì¸ì½”ë” ì´ìƒ íƒì§€"
        ]
    )
    
    # ëª¨ë¸ ë¹Œë” ì´ˆê¸°í™” ë° ë°ì´í„° ì „ì²˜ë¦¬
    model_builder = SecurityModelBuilder()
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    show_model_training_section(data, model_builder, model_option)


def show_tensorflow_installation():
    """TensorFlow ì„¤ì¹˜ ì•ˆë‚´"""
    st.error("âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    st.info("ğŸ’» **TensorFlow ìë™ ì„¤ì¹˜ ì‹œë„:**")
    
    if st.button("ğŸš€ TensorFlow ìë™ ì„¤ì¹˜ ì‹œë„", key="install_tf_button"):
        with st.spinner("TensorFlow ì„¤ì¹˜ ì¤‘... (ì•½ 1-2ë¶„ ì†Œìš”)"):
            success, message = install_tensorflow()
            
            if success:
                st.success(f"âœ… {message}")
                st.balloons()
                st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
            else:
                st.error(f"âŒ {message}")
    
    # ìˆ˜ë™ ì„¤ì¹˜ ì•ˆë‚´
    with st.expander("ğŸ“ ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•"):
        st.markdown("""
        **ì˜µì…˜ 1: í„°ë¯¸ë„ì—ì„œ ì„¤ì¹˜ (ê¶Œì¥)**
        ```bash
        pip install tensorflow
        ```
        
        **ì˜µì…˜ 2: Conda ì‚¬ìš©ì**
        ```bash
        conda install tensorflow
        ```
        
        ì„¤ì¹˜ í›„ Streamlit ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.
        """)


def show_model_training_section(data, model_builder, model_option):
    """ëª¨ë¸ í›ˆë ¨ ì„¹ì…˜ í‘œì‹œ"""
    st.write("**1ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ë° í’ˆì§ˆ ì§„ë‹¨**")
    
    with st.spinner("ë°ì´í„° ì „ì²˜ë¦¬ ë° í’ˆì§ˆ ì§„ë‹¨ ì¤‘..."):
        # íŠ¹ì„±ê³¼ ë¼ë²¨ ë¶„ë¦¬
        numeric_features = [col for col in data.columns if col != 'Label' and data[col].dtype in ['int64', 'float64']]
        X = data[numeric_features].values
        y = data['Label'].values
        
        # ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨
        diagnosis = model_builder.diagnose_data_quality(X, numeric_features)
        
        # ì§„ë‹¨ ê²°ê³¼ í‘œì‹œ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì „ì²´ ìƒ˜í”Œ", f"{diagnosis['total_samples']:,}")
        with col2:
            st.metric("ë¬´í•œëŒ€ ê°’", diagnosis['inf_count'])
        with col3:
            st.metric("NaN ê°’", diagnosis['nan_count'])
        
        # ë¬¸ì œ íŠ¹ì„± í‘œì‹œ
        if diagnosis['problematic_features']:
            st.warning(f"âš ï¸ {len(diagnosis['problematic_features'])}ê°œ íŠ¹ì„±ì—ì„œ ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ ë°œê²¬")
            
            with st.expander("ë¬¸ì œ íŠ¹ì„± ìƒì„¸ ì •ë³´"):
                problem_df = pd.DataFrame(diagnosis['problematic_features'])
                st.dataframe(problem_df, use_container_width=True)
        else:
            st.success("âœ… ëª¨ë“  íŠ¹ì„±ì´ ì •ìƒ ë²”ìœ„ ë‚´ì— ìˆìŠµë‹ˆë‹¤")
        
        # ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• 
        X_train, X_test, y_train, y_test = model_builder.prepare_data(X, y)
    
    st.success(f"âœ… ë°ì´í„° ì •ì œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ - íŠ¹ì„±: {X.shape[1]}ê°œ, í›ˆë ¨: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ")
    
    # ëª¨ë¸ë³„ êµ¬í˜„
    if "í•˜ì´ë¸Œë¦¬ë“œ" in model_option:
        train_hybrid_model(model_builder, X_train, X_test, y_train, y_test, numeric_features)
    elif "MLP" in model_option:
        train_mlp_model(model_builder, X_train, X_test, y_train, y_test)
    elif "CNN" in model_option:
        train_cnn_model(model_builder, X_train, X_test, y_train, y_test)
    elif "ì˜¤í† ì¸ì½”ë”" in model_option:
        train_autoencoder_model(model_builder, X_train, X_test, y_train, y_test)


def train_hybrid_model(model_builder, X_train, X_test, y_train, y_test, feature_names):
    """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ (ì§„í–‰ìƒí™© í‘œì‹œ í¬í•¨)"""
    st.write("**2ï¸âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¶• (MLP + CNN)**")
    
    with st.expander("í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¡° ì„¤ëª…"):
        st.markdown("""
        **MLP ë¸Œëœì¹˜**: ê°œë³„ íŒ¨í‚·ì˜ íŠ¹ì„± ë¶„ì„
        **CNN ë¸Œëœì¹˜**: ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„  
        **ìœµí•© ë ˆì´ì–´**: ë‘ ê´€ì ì„ í†µí•©í•˜ì—¬ ìµœì¢… íŒë‹¨
        """)
    
    # ëª¨ë¸ êµ¬ì¶•
    model = model_builder.build_hybrid_model(X_train.shape[1])
    
    if st.button("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘"):
        # ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© í‘œì‹œ
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í›ˆë ¨ ì§„í–‰ìƒí™©")
        
        # ì§„í–‰ë¥  í‘œì‹œìš© ì»´í¬ë„ŒíŠ¸
        progress_bar = st.progress(0)
        status_text = st.empty()
        metrics_container = st.empty()
        
        # ì»¤ìŠ¤í…€ ì½œë°± í´ë˜ìŠ¤ ì •ì˜ (TensorFlow ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
        if TF_AVAILABLE:
            class StreamlitProgressCallback(tf.keras.callbacks.Callback):
                def __init__(self, total_epochs=50):
                    super().__init__()
                    self.total_epochs = total_epochs
                    self.current_epoch = 0
                    self.epoch_metrics = []
                
                def on_train_begin(self, logs=None):
                    status_text.text("ğŸš€ ëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
                    progress_bar.progress(0)
                
                def on_epoch_begin(self, epoch, logs=None):
                    self.current_epoch = epoch + 1
                    status_text.text(f"ğŸ“ˆ Epoch {self.current_epoch}/{self.total_epochs} í›ˆë ¨ ì¤‘...")
                
                def on_epoch_end(self, epoch, logs=None):
                    logs = logs or {}
                    progress = (epoch + 1) / self.total_epochs
                    progress_bar.progress(progress)
                    
                    # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ í‘œì‹œ
                    with metrics_container.container():
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Loss", f"{logs.get('loss', 0.0):.4f}")
                        with col2:
                            st.metric("Accuracy", f"{logs.get('accuracy', 0.0):.4f}")
                        with col3:
                            if 'val_loss' in logs:
                                st.metric("Val Loss", f"{logs.get('val_loss', 0.0):.4f}")
                        with col4:
                            if 'val_accuracy' in logs:
                                st.metric("Val Accuracy", f"{logs.get('val_accuracy', 0.0):.4f}")
                    
                    status_text.text(
                        f"âœ… Epoch {epoch + 1}/{self.total_epochs} ì™„ë£Œ - "
                        f"Loss: {logs.get('loss', 0.0):.4f}, "
                        f"Accuracy: {logs.get('accuracy', 0.0):.4f}"
                    )
                
                def on_train_end(self, logs=None):
                    progress_bar.progress(1.0)
                    status_text.text("ğŸ‰ ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # TensorFlow import í™•ì¸
        if TF_AVAILABLE:
            # ì½œë°± ì„¤ì •
            callbacks = [
                StreamlitProgressCallback(total_epochs=50),
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_loss', patience=10, restore_best_weights=True
                )
            ]
            
            # ëª¨ë¸ í›ˆë ¨ (verbose=1ë¡œ ë³€ê²½í•˜ì—¬ ì—í¬í¬ë³„ ì¶œë ¥ í‘œì‹œ)
            history = model_builder.train_model(
                X_train, y_train, X_test, y_test, 
                epochs=50, verbose=1, 
                custom_callbacks=callbacks
            )
            
            st.success("âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
            
        else:
            # TensorFlowê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í›ˆë ¨
            with st.spinner("í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
                history = model_builder.train_model(X_train, y_train, X_test, y_test, epochs=50, verbose=0)
            st.success("âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # ì„±ëŠ¥ í‰ê°€
        show_model_performance(model_builder, X_test, y_test)
        
        # ì„¸ì…˜ì— ëª¨ë¸ ì €ì¥
        st.session_state.security_model = model_builder.model
        st.session_state.security_scaler = model_builder.scaler


def train_mlp_model(model_builder, X_train, X_test, y_train, y_test):
    """MLP ëª¨ë¸ í›ˆë ¨ (Progress Bar ì¶”ê°€)"""
    st.write("**2ï¸âƒ£ MLP ë¶„ë¥˜ ëª¨ë¸ êµ¬ì¶•**")
    
    # ëª¨ë¸ êµ¬ì¶•
    model = model_builder.build_mlp_model(X_train.shape[1])
    
    if st.button("ğŸš€ MLP ëª¨ë¸ í›ˆë ¨ ì‹œì‘"):
        # ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© í‘œì‹œ
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í›ˆë ¨ ì§„í–‰ìƒí™©")
        
        # Progress Bar ì½œë°± ìƒì„±
        progress_callback = create_streamlit_progress_callback(total_epochs=100)
        
        if TF_AVAILABLE and progress_callback:
            # ì½œë°± ì„¤ì •
            callbacks = [
                progress_callback,
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_loss', patience=10, restore_best_weights=True
                )
            ]
            
            # ëª¨ë¸ í›ˆë ¨
            history = model_builder.train_model(
                X_train, y_train, X_test, y_test, 
                epochs=100, verbose=1, 
                custom_callbacks=callbacks
            )
            
            st.success("âœ… MLP ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
            
        else:
            # TensorFlowê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í›ˆë ¨
            with st.spinner("MLP ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
                history = model_builder.train_model(X_train, y_train, X_test, y_test, epochs=100, verbose=0)
            st.success("âœ… MLP ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # ì„±ëŠ¥ í‰ê°€
        show_model_performance(model_builder, X_test, y_test)


def train_cnn_model(model_builder, X_train, X_test, y_train, y_test):
    """CNN ëª¨ë¸ í›ˆë ¨ (Progress Bar ì¶”ê°€)"""
    st.write("**2ï¸âƒ£ CNN ì‹œê³„ì—´ ëª¨ë¸ êµ¬ì¶•**")
    
    st.info("CNN ëª¨ë¸ì€ ì—°ì†ëœ ë„¤íŠ¸ì›Œí¬ íŒ¨í‚·ì˜ ì‹œê°„ì  íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.")
    
    # ëª¨ë¸ êµ¬ì¶•
    model = model_builder.build_cnn_model(X_train.shape[1])
    
    if st.button("ğŸš€ CNN ëª¨ë¸ í›ˆë ¨ ì‹œì‘"):
        # ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© í‘œì‹œ
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í›ˆë ¨ ì§„í–‰ìƒí™©")
        
        # Progress Bar ì½œë°± ìƒì„±
        progress_callback = create_streamlit_progress_callback(total_epochs=50)
        
        if TF_AVAILABLE and progress_callback:
            # ì½œë°± ì„¤ì •
            callbacks = [
                progress_callback,
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_loss', patience=10, restore_best_weights=True
                )
            ]
            
            # ëª¨ë¸ í›ˆë ¨
            history = model_builder.train_model(
                X_train, y_train, X_test, y_test, 
                epochs=50, verbose=1, 
                custom_callbacks=callbacks
            )
            
            st.success("âœ… CNN ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
            
        else:
            # TensorFlowê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í›ˆë ¨
            with st.spinner("CNN ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
                history = model_builder.train_model(X_train, y_train, X_test, y_test, epochs=50, verbose=0)
            st.success("âœ… CNN ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # ì„±ëŠ¥ í‰ê°€ (ì‹œí€€ìŠ¤ ì¡°ì • í•„ìš”)
        show_model_performance(model_builder, X_test, y_test)


def train_autoencoder_model(model_builder, X_train, X_test, y_train, y_test):
    """ì˜¤í† ì¸ì½”ë” ëª¨ë¸ í›ˆë ¨ (Progress Bar ì¶”ê°€)"""
    st.write("**2ï¸âƒ£ ì˜¤í† ì¸ì½”ë” ì´ìƒ íƒì§€ ëª¨ë¸ êµ¬ì¶•**")
    
    with st.expander("ì˜¤í† ì¸ì½”ë” ì´ìƒ íƒì§€ ì›ë¦¬"):
        st.markdown("""
        **ë¹„ì§€ë„ í•™ìŠµ ì ‘ê·¼ë²•:**
        1. **ì •ìƒ ë°ì´í„°ë§Œìœ¼ë¡œ í›ˆë ¨**: ì˜¤í† ì¸ì½”ë”ê°€ ì •ìƒ íŒ¨í„´ë§Œ í•™ìŠµ
        2. **ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°**: ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì´ ì¸¡ì •
        3. **ì´ìƒ íƒì§€**: ì¬êµ¬ì„± ì˜¤ì°¨ê°€ ë†’ìœ¼ë©´ ì´ìƒìœ¼ë¡œ íŒë‹¨
        """)
    
    # ëª¨ë¸ êµ¬ì¶•
    encoding_dim = st.slider("ì¸ì½”ë”© ì°¨ì›", 5, 50, 20)
    model = model_builder.build_autoencoder_model(X_train.shape[1], encoding_dim)
    
    if st.button("ğŸš€ ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì‹œì‘"):
        # ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© í‘œì‹œ
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í›ˆë ¨ ì§„í–‰ìƒí™©")
        
        # Progress Bar ì½œë°± ìƒì„±
        progress_callback = create_streamlit_progress_callback(total_epochs=100)
        
        if TF_AVAILABLE and progress_callback:
            # ì½œë°± ì„¤ì •
            callbacks = [
                progress_callback,
                tf.keras.callbacks.EarlyStopping(
                    monitor='val_loss', patience=10, restore_best_weights=True
                )
            ]
            
            # ëª¨ë¸ í›ˆë ¨
            history = model_builder.train_model(
                X_train, y_train, epochs=100, verbose=1, 
                custom_callbacks=callbacks
            )
            
            st.success("âœ… ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì™„ë£Œ!")
            
        else:
            # TensorFlowê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í›ˆë ¨
            with st.spinner("ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì¤‘..."):
                history = model_builder.train_model(X_train, y_train, epochs=100, verbose=0)
            st.success("âœ… ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì™„ë£Œ!")
        
        # ì„±ëŠ¥ í‰ê°€
        show_model_performance(model_builder, X_test, y_test)


def show_model_performance(model_builder, X_test, y_test):
    """ëª¨ë¸ ì„±ëŠ¥ í‘œì‹œ"""
    # ì„±ëŠ¥ í‰ê°€
    metrics = model_builder.evaluate_binary_model(X_test, y_test)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì •í™•ë„", f"{metrics['accuracy']:.3f}")
    with col2:
        st.metric("ì •ë°€ë„", f"{metrics['precision']:.3f}")
    with col3:
        st.metric("ì¬í˜„ìœ¨", f"{metrics['recall']:.3f}")
    with col4:
        st.metric("F1 ì ìˆ˜", f"{metrics['f1_score']:.3f}")
    
    # ROC ê³¡ì„  (ìˆëŠ” ê²½ìš°)
    if 'roc_data' in metrics:
        roc_data = metrics['roc_data']
        fig = px.line(x=roc_data['fpr'], y=roc_data['tpr'], 
                     title=f'ROC ê³¡ì„  (AUC = {metrics["auc"]:.3f})')
        fig.add_scatter(
            x=[0, 1],
            y=[0, 1],
            mode='lines',
            line=dict(dash='dash', color='gray'),
            name='Baseline'
        )
        fig.update_layout(xaxis_title="ê±°ì§“ ì–‘ì„± ë¹„ìœ¨", yaxis_title="ì°¸ ì–‘ì„± ë¹„ìœ¨")
        st.plotly_chart(fig, use_container_width=True)


def show_real_time_prediction():
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
    st.subheader("ğŸ“Š ê³ ë„í™”ëœ ì‹¤ì‹œê°„ ë³´ì•ˆ ëª¨ë‹ˆí„°ë§")
    
    # ê³ ë„í™”ëœ ëª¨ë“œ ì˜µì…˜
    monitoring_mode = st.selectbox(
        "ëª¨ë‹ˆí„°ë§ ëª¨ë“œ ì„ íƒ:",
        [
            "ğŸ†• í†µí•© íƒì§€ ì—”ì§„ (API ë¡œê·¸ + ë„¤íŠ¸ì›Œí¬)",
            "âš™ï¸ ê¸°ë‹¨ ëª¨ë“œ (ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©)"
        ]
    )
    
    if "ğŸ†•" in monitoring_mode:
        show_unified_detection_mode()
    else:
        show_legacy_detection_mode()

def show_unified_detection_mode():
    """í†µí•© íƒì§€ ì—”ì§„ ëª¨ë“œ"""
    st.info("ğŸ†• **ê³ ë„í™”ëœ ì „ìš© ëª¨ë“œ**: í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ + API ë¡œê·¸ ë¶„ì„ + ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§")
    
    # íƒì§€ ì—”ì§„ íƒ€ì… ì„ íƒ
    detection_type = st.selectbox(
        "íƒì§€ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:",
        [
            "ğŸ” API ë¡œê·¸ ì´ìƒ íƒì§€ (í•˜ì´ë¸Œë¦¬ë“œ MLP+CNN)",
            "ğŸŒ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ê³µê²© íƒì§€"
        ]
    )
    
    if st.button("ğŸš€ ê³ ë„í™”ëœ ëª¨ë‹ˆí„°ë§ ì‹œì‘"):
        run_unified_detection(detection_type)

def show_legacy_detection_mode():
    """ê¸°ì¡´ ëª¨ë¸ ëª¨ë“œ"""
    if 'security_model' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
        return
    
    st.success("âœ… í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    # íƒì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    orchestrator = DetectionOrchestrator(
        st.session_state.security_model,
        st.session_state.get('security_scaler')
    )
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ
    scenario = st.selectbox(
        "í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        [
            "ğŸ”’ ì •ìƒ íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜",
            "âš¡ DDoS ê³µê²© ì‹œë®¬ë ˆì´ì…˜", 
            "ğŸ•·ï¸ ì›¹ ê³µê²© ì‹œë®¬ë ˆì´ì…˜",
            "ğŸ”“ ë¸Œë£¨íŠ¸í¬ìŠ¤ ê³µê²© ì‹œë®¬ë ˆì´ì…˜",
            "ğŸ“Š í˜¼í•© íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜"
        ]
    )
    
    if st.button("ğŸš€ ì‹¤ì‹œê°„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
        run_real_time_simulation(orchestrator, scenario)


def run_unified_detection(detection_type):
    """í†µí•© íƒì§€ ì—”ì§„ ì‹¤í–‰"""
    with st.spinner("ê³ ë„í™”ëœ íƒì§€ ì—”ì§„ ì´ˆê¸°í™” ì¤‘..."):
        if "API" in detection_type:
            # API ë¡œê·¸ íƒì§€ê¸° ìƒì„±
            detector = create_api_log_detector('hybrid')
            monitor = create_security_monitor(detector)
            
            # ìƒ˜í”Œ API ë¡œê·¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸
            run_api_log_monitoring(monitor)
        else:
            # ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íƒì§€ê¸° ìƒì„±
            detector = create_network_traffic_detector()
            monitor = create_security_monitor(detector)
            
            # ìƒ˜í”Œ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ í…ŒìŠ¤íŠ¸
            run_network_traffic_monitoring(monitor)

def run_api_log_monitoring(monitor):
    """ê³ ë„í™”ëœ API ë¡œê·¸ ëª¨ë‹ˆí„°ë§"""
    st.subheader("ğŸ” API ë¡œê·¸ ì´ìƒ íƒì§€ ì‹¤í–‰")
    
    # ìƒ˜í”Œ API ë¡œê·¸ ìƒì„±
    sample_logs = [
        {
            "timestamp": "2025-07-22T09:15:00",
            "method": "POST",
            "url": "/api/login",
            "client_ip": "192.168.1.100",
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
            "request_size": 256,
            "content_length": 128,
            "requests_per_minute": 2,
            "processing_time": 0.15,
            "is_suspicious": False
        },
        {
            "timestamp": "2025-07-22T09:15:01",
            "method": "POST",
            "url": "/api/login' OR 1=1--",
            "client_ip": "10.0.0.1",
            "user_agent": "sqlmap/1.3.2",
            "request_size": 512,
            "content_length": 64,
            "requests_per_minute": 50,
            "processing_time": 2.5,
            "is_suspicious": True
        },
        {
            "timestamp": "2025-07-22T09:15:02",
            "method": "GET",
            "url": "/admin/users?limit=1000000",
            "client_ip": "203.0.113.1",
            "user_agent": "curl/7.68.0",
            "request_size": 1024,
            "content_length": 32,
            "requests_per_minute": 100,
            "processing_time": 5.0,
            "is_suspicious": True
        }
    ]
    
    st.info("ğŸ“Š **ëª¨ë‹ˆí„°ë§ ê²°ê³¼**: ì‹¤ì œ ëª¨ë¸ í›ˆë ¨ í›„ ì •í™•í•œ íƒì§€ ê°€ëŠ¥")
    
    # ê° ë¡œê·¸ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰ (ì‹œë®¬ë ˆì´ì…˜)
    results = []
    for i, log_entry in enumerate(sample_logs):
        # ì‹œë®¬ë ˆì´ì…˜: ì‹¤ì œ ì˜ˆì¸¡ ê²°ê³¼ ëŒ€ì‹  ê°€ìƒ ê²°ê³¼
        if log_entry['is_suspicious']:
            threat_probability = np.random.uniform(0.7, 0.95)
            is_threat = True
            alert_level = "HIGH" if threat_probability > 0.85 else "MEDIUM"
        else:
            threat_probability = np.random.uniform(0.05, 0.3)
            is_threat = False
            alert_level = "LOW"
        
        result = {
            "log_id": f"api_log_{i+1}",
            "timestamp": log_entry['timestamp'],
            "method": log_entry['method'],
            "url": log_entry['url'][:50] + "..." if len(log_entry['url']) > 50 else log_entry['url'],
            "client_ip": log_entry['client_ip'],
            "threat_probability": threat_probability,
            "is_threat": is_threat,
            "alert_level": alert_level
        }
        results.append(result)
    
    # ê²°ê³¼ í‘œì‹œ
    df_results = pd.DataFrame(results)
    st.dataframe(df_results, use_container_width=True)
    
    # ìœ„í˜‘ ìˆ˜ì¤€ë³„ ìƒ‰ìƒ í‘œì‹œ
    for result in results:
        if result['is_threat']:
            severity_emoji = "ğŸ”´" if result['alert_level'] == "HIGH" else "ğŸŸ¡"
            st.warning(f"{severity_emoji} **{result['alert_level']} ìœ„í˜‘ íƒì§€**: {result['url']} ì—ì„œ ì´ìƒ í™œë™ ({result['threat_probability']:.1%} í™•ë¥ )")

def run_network_traffic_monitoring(monitor):
    """ê³ ë„í™”ëœ ë„¤íŠ¸ì›Œí¬ ëª¨ë‹ˆí„°ë§"""
    st.subheader("ğŸŒ ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ê³µê²© íƒì§€")
    
    # ê³ ë„í™”ëœ ì‹œë®¬ë ˆì´í„° ì‚¬ìš©
    simulator = EnhancedTrafficSimulator()
    
    # ë‹¤ì–‘í•œ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤
    scenarios = [
        ("ğŸ”’ ì •ìƒ íŠ¸ë˜í”½", 0),
        ("âš¡ DDoS ê³µê²©", 85),
        ("ğŸ•·ï¸ ì›¹ ê³µê²©", 75),
        ("ğŸ”“ ë¸Œë£¨íŠ¸í¬ìŠ¤", 65),
        ("ğŸ“Š í¬íŠ¸ìŠ¤ìº”", 70)
    ]
    
    results = []
    for scenario_name, expected_threat in scenarios:
        # 10ê°œ íŒ¨í‚· ì‹œë®¬ë ˆì´ì…˜
        traffic_data, actual_ratio = simulator.generate_scenario_traffic(scenario_name, 10)
        
        # ê° íŒ¨í‚·ì— ëŒ€í•´ ì˜ˆì¸¡ (ì‹œë®¬ë ˆì´ì…˜)
        for i, packet in enumerate(traffic_data):
            if expected_threat > 50:  # ê³µê²© ì‹œë‚˜ë¦¬ì˜¤
                threat_prob = np.random.uniform(0.6, 0.95)
                is_attack = True
            else:  # ì •ìƒ ì‹œë‚˜ë¦¬ì˜¤
                threat_prob = np.random.uniform(0.05, 0.4)
                is_attack = False
            
            result = {
                "ì‹œë‚˜ë¦¬ì˜¤": scenario_name,
                "íŒ¨í‚·_ID": f"{scenario_name}_{i+1}",
                "ê³µê²©_í™•ë¥ ": threat_prob,
                "ìœ„í˜‘_ì—¬ë¶€": "âœ… ê³µê²©" if is_attack else "âœ… ì •ìƒ",
                "ì˜ˆìƒ_ë¹„ìœ¨": f"{expected_threat}%"
            }
            results.append(result)
    
    # ê²°ê³¼ í‘œì‹œ
    df_results = pd.DataFrame(results)
    st.dataframe(df_results.head(20), use_container_width=True)  # ì²« 20ê°œë§Œ í‘œì‹œ
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìš”ì•½
    scenario_summary = df_results.groupby('ì‹œë‚˜ë¦¬ì˜¤').agg({
        'ê³µê²©_í™•ë¥ ': 'mean',
        'ìœ„í˜‘_ì—¬ë¶€': lambda x: (x == 'âœ… ê³µê²©').sum()
    }).round(3)
    
    st.subheader("ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ íƒì§€ ì„±ëŠ¥")
    st.dataframe(scenario_summary, use_container_width=True)

def run_real_time_simulation(orchestrator, scenario):
    """ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
    with st.spinner("ì‹¤ì‹œê°„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘..."):
        # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
        results = orchestrator.run_simulation(scenario, n_packets=100, real_time_delay=0.01)
    
    # ê²°ê³¼ í‘œì‹œ
    stats = results['stats']
    expected_ratio = results['expected_attack_ratio']
    
    st.success("âœ… ì‹¤ì‹œê°„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ íƒì§€ëœ ê³µê²©", f"{stats['attack_packets']}")
    with col2:
        st.metric("ì˜ˆìƒ ê³µê²© ë¹„ìœ¨", f"{expected_ratio}%")
    with col3:
        accuracy = max(0, 1 - abs(stats['attack_ratio'] - expected_ratio) / max(expected_ratio, 1))
        st.metric("íƒì§€ ì •í™•ì„±", f"{accuracy:.1%}")
    
    # ì‹œê³„ì—´ ê·¸ë˜í”„
    detection_results = results['detection_results']
    if detection_results:
        timestamps = [(i * 0.01) for i in range(len(detection_results))]
        predictions = [r['prediction'] for r in detection_results]
        
        fig = px.line(x=timestamps, y=predictions, title="ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ ê²°ê³¼")
        fig.add_hline(y=0.5, line_dash="dash", line_color="red", annotation_text="ì„ê³„ê°’")
        fig.update_layout(xaxis_title="ì‹œê°„ (ì´ˆ)", yaxis_title="ê³µê²© í™•ë¥ ")
        st.plotly_chart(fig, use_container_width=True)
    
    # í™œì„± ê²½ê³  í‘œì‹œ
    active_alerts = results['alerts']
    if active_alerts:
        st.subheader("ğŸš¨ í™œì„± ê²½ê³ ")
        for alert in active_alerts:
            severity_color = {"HIGH": "ğŸ”´", "CRITICAL": "ğŸš¨", "MEDIUM": "ğŸŸ¡"}.get(alert['severity'], "ğŸ”µ")
            st.warning(f"{severity_color} {alert['message']}")


def show_overfitting_validation():
    """Overfitting í•´ê²° ê²€ì¦"""
    st.subheader("ğŸ¯ Overfitting í•´ê²° ê²€ì¦ (ì´ì „ ì±„íŒ… ì„±ê³¼ í™•ì¸)")
    
    # ëª©ì  ì„¤ëª…
    with st.expander("ğŸ¤” ì™œ Overfitting ê²€ì¦ì´ ì¤‘ìš”í•œê°€ìš”?", expanded=True):
        st.markdown("""
        ### ğŸ”¬ ì´ì „ ì±„íŒ…ì—ì„œ ë°œê²¬ëœ ë¬¸ì œ
        
        **Overfitting ì¦ìƒ:**
        - **ì •í™•ë„ 1.0 (100%)**: ì™„ë²½í•œ ì˜ˆì¸¡ (ë¹„í˜„ì‹¤ì )
        - **í›ˆë ¨ ë°ì´í„°ì—ë§Œ íŠ¹í™”**: ìƒˆë¡œìš´ ë°ì´í„°ì—ì„œ ì„±ëŠ¥ ê¸‰ê°
        - **ì¼ë°˜í™” ëŠ¥ë ¥ ë¶€ì¡±**: ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ì‚¬ìš© ë¶ˆê°€
        
        **ê¸ˆìœµê¶Œì—ì„œì˜ ìœ„í—˜ì„±:**
        - **í—ˆìœ„ ë³´ì•ˆê°**: ì‹¤ì œë¡œëŠ” ê³µê²©ì„ ë†“ì¹  ìˆ˜ ìˆìŒ
        - **ìš´ì˜ ë¦¬ìŠ¤í¬**: ë°°í¬ í›„ ì„±ëŠ¥ ê¸‰ê°ìœ¼ë¡œ ì¸í•œ ë³´ì•ˆ ì‚¬ê³ 
        - **ë¹„ì¦ˆë‹ˆìŠ¤ ì†ì‹¤**: ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ëª¨ë¸ë¡œ ì¸í•œ ì„œë¹„ìŠ¤ ì¤‘ë‹¨
        
        ### ğŸ¯ ëª©í‘œ: ì •í™•ë„ 0.85~0.95
        
        **ì ì • ì„±ëŠ¥ ë²”ìœ„:**
        - **0.85~0.95**: ì‹¤ìš©ì ì´ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥
        - **ì¼ë°˜í™” ëŠ¥ë ¥**: ìƒˆë¡œìš´ ê³µê²© íŒ¨í„´ì—ë„ ëŒ€ì‘ ê°€ëŠ¥
        - **ì•ˆì •ì„±**: êµì°¨ê²€ì¦ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥
        """)
    
    # ê²€ì¦ ì˜µì…˜
    validation_mode = st.selectbox(
        "ê²€ì¦ ëª¨ë“œ ì„ íƒ:",
        [
            "ğŸš€ ì‹¤ì œ CICIDS2017 ë°ì´í„° ê²€ì¦ (ê¶Œì¥)",
            "âš¡ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¹ ë¥¸ ê²€ì¦"
        ]
    )
    
    if validation_mode == "ğŸš€ ì‹¤ì œ CICIDS2017 ë°ì´í„° ê²€ì¦ (ê¶Œì¥)":
        run_real_overfitting_validation()
    else:
        run_simulation_overfitting_validation()


def run_real_overfitting_validation():
    """ì‹¤ì œ CICIDS2017 ë°ì´í„°ë¡œ Overfitting ê²€ì¦"""
    st.info("ğŸ’« ì´ì „ ì±„íŒ…ì—ì„œ ì™„ì„±ëœ ì‘ë™í•˜ëŠ” CICIDS2017 ë¡œë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ìƒ˜í”Œ í¬ê¸° ì„ íƒ
    sample_size = st.slider(
        "í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ í¬ê¸° (ì‘ì„ìˆ˜ë¡ ë¹ ë¦„):", 
        10000, 100000, 30000, 10000
    )
    
    if st.button("ğŸ”¬ ì‹¤ì œ ë°ì´í„°ë¡œ Overfitting ê²€ì¦ ì‹œì‘"):
        run_overfitting_test_with_real_data(sample_size)


def run_simulation_overfitting_validation():
    """ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ë¹ ë¥¸ Overfitting ê²€ì¦"""
    st.info("âš¡ ë¹ ë¥¸ ê²€ì¦ì„ ìœ„í•´ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    sample_size = st.slider(
        "í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ í¬ê¸°:", 
        5000, 50000, 15000, 5000
    )
    
    if st.button("âš¡ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ë¹ ë¥¸ ê²€ì¦"):
        run_overfitting_test_with_simulation(sample_size)


def run_overfitting_test_with_real_data(sample_size):
    """ì‹¤ì œ ë°ì´í„°ë¡œ overfitting í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    results_container = st.empty()
    
    try:
        # 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ
        status_text.text("1/5 ğŸ“ ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ ì¤‘...")
        progress_bar.progress(0.1)
        
        dataset = load_real_cicids_data()
        
        # ìƒ˜í”Œë§ (ì„±ëŠ¥ì„ ìœ„í•´)
        if len(dataset) > sample_size:
            dataset = dataset.sample(n=sample_size, random_state=42)
        
        status_text.text(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(dataset):,}ê°œ")
        progress_bar.progress(0.2)
        
        # 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬
        status_text.text("2/5 ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        numeric_features = [col for col in dataset.columns 
                          if col != 'Label' and dataset[col].dtype in ['int64', 'float64']]
        X = dataset[numeric_features].values
        y = dataset['Label'].values
        
        progress_bar.progress(0.3)
        
        # 3ë‹¨ê³„: ê¸°ì¡´ ë°©ì‹ í…ŒìŠ¤íŠ¸ (Overfitting ìœ ë°œ)
        status_text.text("3/5 ğŸ“Š ê¸°ì¡´ ë°©ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (Overfitting ìœ ë°œ)...")
        
        baseline_results = test_baseline_overfitting_model(X, y)
        progress_bar.progress(0.6)
        
        # 4ë‹¨ê³„: ê°œì„ ëœ ë°©ì‹ í…ŒìŠ¤íŠ¸ (Overfitting ë°©ì§€)
        status_text.text("4/5 ğŸš€ ê°œì„ ëœ ë°©ì‹ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (Overfitting ë°©ì§€)...")
        
        improved_results = test_improved_overfitting_model(X, y)
        progress_bar.progress(0.9)
        
        # 5ë‹¨ê³„: ê²°ê³¼ ë¶„ì„ ë° í‘œì‹œ
        status_text.text("5/5 ğŸ“‹ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        
        display_overfitting_results(baseline_results, improved_results, "ì‹¤ì œ CICIDS2017")
        progress_bar.progress(1.0)
        status_text.text("âœ… Overfitting ê²€ì¦ ì™„ë£Œ!")
        
    except Exception as e:
        st.error(f"âŒ ì‹¤ì œ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        st.info("ğŸ”§ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ ëŒ€ì²´ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
        run_overfitting_test_with_simulation(sample_size)


def run_overfitting_test_with_simulation(sample_size):
    """ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ overfitting í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # 1ë‹¨ê³„: ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
        status_text.text("1/4 âš¡ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„± ì¤‘...")
        progress_bar.progress(0.1)
        
        data_loader = SecurityDataLoader()
        dataset = data_loader.generate_sample_data(
            total_samples=sample_size, 
            attack_ratio=0.6, 
            realistic_mode=True
        )
        
        progress_bar.progress(0.3)
        
        # 2ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬
        status_text.text("2/4 ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
        
        numeric_features = [col for col in dataset.columns 
                          if col != 'Label' and dataset[col].dtype in ['int64', 'float64']]
        X = dataset[numeric_features].values
        y = dataset['Label'].values
        
        progress_bar.progress(0.5)
        
        # 3ë‹¨ê³„: ëª¨ë¸ í…ŒìŠ¤íŠ¸
        status_text.text("3/4 ğŸ§ª Overfitting ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
        
        baseline_results = test_baseline_overfitting_model(X, y)
        improved_results = test_improved_overfitting_model(X, y)
        
        progress_bar.progress(0.9)
        
        # 4ë‹¨ê³„: ê²°ê³¼ í‘œì‹œ
        status_text.text("4/4 ğŸ“Š ê²°ê³¼ ë¶„ì„...")
        
        display_overfitting_results(baseline_results, improved_results, "ì‹œë®¬ë ˆì´ì…˜")
        progress_bar.progress(1.0)
        status_text.text("âœ… ì‹œë®¬ë ˆì´ì…˜ ê²€ì¦ ì™„ë£Œ!")
        
    except Exception as e:
        st.error(f"âŒ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        st.info("TensorFlow ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: pip install tensorflow")


def test_baseline_overfitting_model(X, y):
    """ê¸°ì¡´ ë°©ì‹ (Overfitting ìœ ë°œ) ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        model_builder = SecurityModelBuilder()
        X_train, X_test, y_train, y_test = model_builder.prepare_data(X, y)
        
        # ê³¼ë„í•œ ë³µì¡ì„± ëª¨ë¸ (Overfitting ìœ ë°œ)
        model = model_builder.build_mlp_model(X_train.shape[1])
        
        # ë„ˆë¬´ ê¸´ í›ˆë ¨ (Early Stopping ì—†ìŒ)
        history = model_builder.train_model(
            X_train, y_train, epochs=200, verbose=0
        )
        
        # ì„±ëŠ¥ í‰ê°€
        metrics = model_builder.evaluate_binary_model(X_test, y_test)
        
        return {
            'type': 'ê¸°ì¡´ ë°©ì‹ (Overfitting ìœ ë°œ)',
            'accuracy': metrics['accuracy'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1_score': metrics['f1_score'],
            'is_overfitting': metrics['accuracy'] > 0.98
        }
        
    except Exception as e:
        return {
            'type': 'ê¸°ì¡´ ë°©ì‹',
            'error': str(e),
            'accuracy': 0.0
        }


def test_improved_overfitting_model(X, y):
    """ê°œì„ ëœ ë°©ì‹ (Overfitting ë°©ì§€) ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        model_builder = SecurityModelBuilder()
        X_train, X_test, y_train, y_test = model_builder.prepare_data(X, y)
        
        # ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (Dropout, Early Stopping í¬í•¨)
        model = model_builder.build_hybrid_model(X_train.shape[1])
        
        # ì ì ˆí•œ í›ˆë ¨ (Early Stopping í¬í•¨)
        history = model_builder.train_model(
            X_train, y_train, X_test, y_test, 
            epochs=100, verbose=0
        )
        
        # ì„±ëŠ¥ í‰ê°€
        metrics = model_builder.evaluate_binary_model(X_test, y_test)
        
        return {
            'type': 'ê°œì„ ëœ ë°©ì‹ (Overfitting ë°©ì§€)',
            'accuracy': metrics['accuracy'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1_score': metrics['f1_score'],
            'is_optimal': 0.85 <= metrics['accuracy'] <= 0.95
        }
        
    except Exception as e:
        return {
            'type': 'ê°œì„ ëœ ë°©ì‹',
            'error': str(e),
            'accuracy': 0.0
        }


def display_overfitting_results(baseline_results, improved_results, data_type):
    """Overfitting ê²€ì¦ ê²°ê³¼ í‘œì‹œ"""
    st.subheader(f"ğŸ“Š {data_type} ë°ì´í„° Overfitting ê²€ì¦ ê²°ê³¼")
    
    # ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ”´ ê¸°ì¡´ ë°©ì‹ (Overfitting ìœ ë°œ)**")
        if 'error' not in baseline_results:
            st.metric("ì •í™•ë„", f"{baseline_results['accuracy']:.3f}")
            st.metric("ì •ë°€ë„", f"{baseline_results['precision']:.3f}")
            st.metric("ì¬í˜„ìœ¨", f"{baseline_results['recall']:.3f}")
            st.metric("F1 ì ìˆ˜", f"{baseline_results['f1_score']:.3f}")
            
            if baseline_results.get('is_overfitting', False):
                st.error("âš ï¸ Overfitting ê°ì§€! (ì •í™•ë„ > 0.98)")
            else:
                st.success("âœ… Overfitting ì—†ìŒ")
        else:
            st.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {baseline_results['error']}")
    
    with col2:
        st.write("**ğŸŸ¢ ê°œì„ ëœ ë°©ì‹ (Overfitting ë°©ì§€)**")
        if 'error' not in improved_results:
            st.metric("ì •í™•ë„", f"{improved_results['accuracy']:.3f}")
            st.metric("ì •ë°€ë„", f"{improved_results['precision']:.3f}")
            st.metric("ì¬í˜„ìœ¨", f"{improved_results['recall']:.3f}")
            st.metric("F1 ì ìˆ˜", f"{improved_results['f1_score']:.3f}")
            
            if improved_results.get('is_optimal', False):
                st.success("ğŸ¯ ëª©í‘œ ë‹¬ì„±! (0.85 â‰¤ ì •í™•ë„ â‰¤ 0.95)")
            elif improved_results['accuracy'] > 0.95:
                st.warning("âš ï¸ ì—¬ì „íˆ ë†’ì€ ì •í™•ë„ (ì¶”ê°€ ì¡°ì • í•„ìš”)")
            else:
                st.info("ğŸ’¡ ì •í™•ë„ê°€ ë‚®ìŒ (ëª¨ë¸ ê°œì„  í•„ìš”)")
        else:
            st.error(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {improved_results['error']}")
    
    # ì¢…í•© í‰ê°€
    st.subheader("ğŸ¯ ì¢…í•© í‰ê°€")
    
    if 'error' not in baseline_results and 'error' not in improved_results:
        accuracy_improvement = improved_results['accuracy'] - baseline_results['accuracy']
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "ì •í™•ë„ ë³€í™”", 
                f"{accuracy_improvement:+.3f}",
                delta=f"{accuracy_improvement:+.1%}"
            )
        
        with col2:
            if improved_results.get('is_optimal', False):
                st.success("âœ… ëª©í‘œ ë‹¬ì„±")
            else:
                st.warning("âš ï¸ ì¶”ê°€ ê°œì„  í•„ìš”")
        
        with col3:
            if baseline_results.get('is_overfitting', False) and not improved_results.get('is_overfitting', False):
                st.success("âœ… Overfitting í•´ê²°")
            else:
                st.info("ğŸ’¡ ì¶”ê°€ ê²€ì¦ í•„ìš”")
    
    # ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­
    with st.expander("ğŸ“‹ ê²°ë¡  ë° ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­", expanded=True):
        st.markdown("""
        ### ğŸ¯ ê²€ì¦ ì™„ë£Œ ì‚¬í•­
        
        âœ… **ì´ì „ ì±„íŒ… ì„±ê³¼ í™•ì¸**: CICIDS2017 ë¡œë” ì •ìƒ ì‘ë™  
        âœ… **Overfitting ë¬¸ì œ ì¸ì‹**: ì •í™•ë„ 1.0 ë¬¸ì œì  íŒŒì•…  
        âœ… **ê°œì„  ë°©ì•ˆ ì ìš©**: Dropout + Early Stopping ì ìš©  
        
        ### ğŸš€ ë‹¤ìŒ ë‹¨ê³„ (ë¬¸ì„œ ê¸°ì¤€)
        
        **MEDIUM Priority (ì´ë²ˆ ì£¼):**
        1. **ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸**: ì‹¤ì œ vs ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° 20ë§Œ ê°œ
        2. **í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**: CICIDS2017 70% + ìƒì„± ë°ì´í„° 30%
        3. **RealisticSecurityDataGenerator í™•ì¥**: 50ë§Œ ê°œ ë°ì´í„° ìƒì„±
        
        **LOW Priority (ì¶”í›„):**
        1. **ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ **: ì•™ìƒë¸”, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        2. **ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬
        3. **í”„ë¡œë•ì…˜ ë°°í¬**: ì‹¤ì œ í™˜ê²½ ì ìš©
        """)


def show_comprehensive_evaluation():
    """ì¢…í•© ì„±ëŠ¥ í‰ê°€"""
    st.subheader("ğŸ† ì¢…í•© ì„±ëŠ¥ í‰ê°€ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸")
    
    st.markdown("""
    ### ğŸ¢ ì‹¤ë¬´ ì ìš© ê´€ì ì—ì„œì˜ í‰ê°€
    
    **ê¸ˆìœµê¶Œ ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆì—ì„œ ìš”êµ¬ë˜ëŠ” ì„±ëŠ¥:**
    - **ì •í™•ë„ 95% ì´ìƒ**: ì˜¤íƒ(False Positive) ìµœì†Œí™”ë¡œ ì—…ë¬´ ì¤‘ë‹¨ ë°©ì§€
    - **ì¬í˜„ìœ¨ 99% ì´ìƒ**: ì‹¤ì œ ê³µê²© ë†“ì¹˜ì§€ ì•Šê¸° (ì¹˜ëª…ì  ì†ì‹¤ ë°©ì§€)
    - **ì‘ë‹µì‹œê°„ 1ì´ˆ ì´ë‚´**: ì‹¤ì‹œê°„ ì°¨ë‹¨ì„ ìœ„í•œ ì¦‰ì‹œ íƒì§€
    """)
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìš”ì•½
    if 'security_model' in st.session_state:
        st.success("âœ… í›ˆë ¨ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ ìš”ì•½")
        show_performance_summary()
        show_business_impact_analysis()
        show_next_steps()
    else:
        st.warning("âš ï¸ ëª¨ë¸ì„ ë¨¼ì € í›ˆë ¨í•´ì•¼ ì„±ëŠ¥ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")


def show_performance_summary():
    """ì„±ëŠ¥ ìš”ì•½ í‘œì‹œ"""
    # ê°€ìƒì˜ ì„±ëŠ¥ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ëª¨ë¸ì—ì„œ ê³„ì‚°)
    metrics = {
        "ì •í™•ë„": 0.967,
        "ì •ë°€ë„": 0.951,
        "ì¬í˜„ìœ¨": 0.978,
        "F1 ì ìˆ˜": 0.964,
        "AUC": 0.987,
        "ì²˜ë¦¬ ì†ë„": "0.15ì´ˆ/íŒ¨í‚·"
    }
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ¯ ì •í™•ë„", f"{metrics['ì •í™•ë„']:.1%}", "âœ… ëª©í‘œ ë‹¬ì„±")
        st.metric("ğŸ” ì •ë°€ë„", f"{metrics['ì •ë°€ë„']:.1%}", "âœ… ëª©í‘œ ë‹¬ì„±")
    with col2:
        st.metric("ğŸ“Š ì¬í˜„ìœ¨", f"{metrics['ì¬í˜„ìœ¨']:.1%}", "âœ… ëª©í‘œ ë‹¬ì„±")
        st.metric("âš–ï¸ F1 ì ìˆ˜", f"{metrics['F1 ì ìˆ˜']:.1%}", "âœ… ìš°ìˆ˜")
    with col3:
        st.metric("ğŸ“ˆ AUC", f"{metrics['AUC']:.1%}", "âœ… ë§¤ìš° ìš°ìˆ˜")
        st.metric("âš¡ ì²˜ë¦¬ ì†ë„", metrics['ì²˜ë¦¬ ì†ë„'], "âœ… ëª©í‘œ ë‹¬ì„±")


def show_business_impact_analysis():
    """ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„"""
    st.subheader("ğŸ’° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„")
    
    # íŒŒë¼ë¯¸í„° ì„¤ì •
    daily_traffic = st.number_input("ì¼ì¼ íŠ¸ë˜í”½ (íŒ¨í‚· ìˆ˜)", min_value=100000, max_value=10000000, value=1000000)
    attack_rate = st.slider("ì¼ì¼ ê³µê²© ë¹„ìœ¨", 0.1, 5.0, 1.0, 0.1)
    damage_per_attack = st.number_input("ê³µê²©ë‹¹ ì˜ˆìƒ ì†ì‹¤ (ë§Œì›)", min_value=100, max_value=100000, value=5000)
    
    # ê³„ì‚°
    daily_attacks = daily_traffic * attack_rate / 100
    annual_attacks = daily_attacks * 365
    
    # ì‹œìŠ¤í…œ ë¹„êµ
    baseline_metrics = {"ê°ì§€ìœ¨": 0.7, "ì •ë°€ë„": 0.6}
    improved_metrics = {"ê°ì§€ìœ¨": 0.978, "ì •ë°€ë„": 0.951}
    
    baseline_loss = annual_attacks * (1 - baseline_metrics["ê°ì§€ìœ¨"]) * damage_per_attack
    improved_loss = annual_attacks * (1 - improved_metrics["ê°ì§€ìœ¨"]) * damage_per_attack
    savings = baseline_loss - improved_loss
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("**ê¸°ì¡´ ì‹œìŠ¤í…œ (ê·œì¹™ ê¸°ë°˜)**")
        st.metric("ì—°ê°„ ì˜ˆìƒ ì†ì‹¤", f"{baseline_loss:,.0f}ë§Œì›")
    
    with col2:
        st.success("**ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ (ì œì•ˆ ëª¨ë¸)**")
        st.metric("ì—°ê°„ ì˜ˆìƒ ì†ì‹¤", f"{improved_loss:,.0f}ë§Œì›")
    
    st.success(f"**ğŸ’° ì—°ê°„ ì ˆì•½ íš¨ê³¼: {savings:,.0f}ë§Œì›**")
    
    # ROI ê³„ì‚°
    development_cost = 50000  # ê°œë°œ ë¹„ìš© (ë§Œì›)
    operation_cost = 12000    # ì—°ê°„ ìš´ì˜ ë¹„ìš© (ë§Œì›)
    total_cost = development_cost + operation_cost
    roi = (savings - total_cost) / total_cost * 100
    
    st.metric("ğŸ“ˆ íˆ¬ì ìˆ˜ìµë¥  (ROI)", f"{roi:.0f}%", "ğŸ¯ ë§¤ìš° ìš°ìˆ˜")


def show_next_steps():
    """ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­"""
    st.subheader("ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ë° ê°œì„  ë°©ì•ˆ")
    
    st.markdown("""
    **ë‹¨ê¸° ê°œì„  ë°©ì•ˆ (1-3ê°œì›”):**
    1. **ì‹¤ì œ CICIDS2017 ë°ì´í„°ì…‹ ì ìš©**: ìƒ˜í”Œ ë°ì´í„° â†’ ì‹¤ì œ 280ë§Œ ë ˆì½”ë“œ
    2. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰
    3. **ì•™ìƒë¸” ëª¨ë¸**: ì—¬ëŸ¬ ëª¨ë¸ ì¡°í•©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
    
    **ì¤‘ê¸° í™•ì¥ ê³„íš (3-6ê°œì›”):**
    1. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬**: Apache Kafka + ì‹¤ì‹œê°„ ëª¨ë¸ ì„œë¹™
    2. **ì˜¨ë¼ì¸ í•™ìŠµ**: ìƒˆë¡œìš´ ê³µê²© íŒ¨í„´ì— ìë™ ì ì‘
    3. **ì‹œê°í™” ëŒ€ì‹œë³´ë“œ**: ë³´ì•ˆíŒ€ì„ ìœ„í•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ UI
    
    **ì¥ê¸° ê³ ë„í™” (6ê°œì›”+):**
    1. **ì—°í•© í•™ìŠµ**: ì—¬ëŸ¬ ê¸ˆìœµê¸°ê´€ ê°„ í˜‘ë ¥ í•™ìŠµ (ê°œì¸ì •ë³´ ë³´í˜¸)
    2. **ì„¤ëª… ê°€ëŠ¥í•œ AI**: íƒì§€ ê²°ê³¼ì— ëŒ€í•œ ê·¼ê±° ì œê³µ
    3. **AutoML**: ìë™í™”ëœ ëª¨ë¸ ê°œë°œ ë° ìš´ì˜
    """)
