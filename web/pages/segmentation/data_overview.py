"""
ê³ ê° ë°ì´í„° ê°œìš” í˜ì´ì§€ - ì™„ì „ ì‘ë™ ë²„ì „

ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ(data/processors/segmentation_data_processor.py)ì„ í™œìš©í•˜ì—¬
ê³ í’ˆì§ˆ ë°ì´í„° ê°œìš” ë° ë¶„ì„ ê¸°ëŠ¥ì„ ì œê³µ
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots


def get_data_processor():
    """ë°ì´í„° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” - ì•ˆì „í•œ í´ë°± ë©”ì»¤ë‹ˆì¦˜"""
    try:
        # ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ ì‚¬ìš©
        from data.processors.segmentation_data_processor import DataProcessor
        processor = DataProcessor()
        return processor, 'new_data_layer'
    except ImportError as e:
        st.error(f"âŒ ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, 'failed'


def create_sample_data():
    """í‘œì¤€ Mall Customer ìƒ˜í”Œ ë°ì´í„° ìƒì„± - Arror í˜¸í™˜ì„± ê°œì„ """
    np.random.seed(42)
    n_customers = 200

    data = pd.DataFrame({
        'CustomerID': range(1, n_customers + 1),
        'Gender': np.random.choice(['Male', 'Female'], n_customers, p=[0.44, 0.56]),
        'Age': np.random.normal(38.85, 13.97, n_customers).astype(int).clip(18, 70),
        'Annual Income (k$)': np.random.normal(60.56, 26.26, n_customers).astype(int).clip(15, 137),
        'Spending Score (1-100)': np.random.normal(50.2, 25.82, n_customers).astype(int).clip(1, 99)
    })

    # Arrow í˜¸í™˜ì„±ì„ ìœ„í•´ ëª…ì‹œì  íƒ€ì… ì§€ì •
    data['Gender'] = data['Gender'].astype(str)
    data['CustomerID'] = data['CustomerID'].astype('int64')
    data['Age'] = data['Age'].astype('int64')
    data['Annual Income (k$)'] = data['Annual Income (k$)'].astype('int64')
    data['Spending Score (1-100)'] = data['Spending Score (1-100)'].astype('int64')

    return data


def show_data_overview_page():
    """ê³ ê° ë°ì´í„° ê°œìš” í˜ì´ì§€ ë©”ì¸ í•¨ìˆ˜"""
    st.header("ğŸ“Š ê³ ê° ë°ì´í„° ê°œìš” ë° ë¶„ì„")

    # ë°ì´í„° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    data_processor, status = get_data_processor()

    if data_processor is None:
        st.warning("âš ï¸ ë°ì´í„° í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        data = create_sample_data()
        st.info("ğŸ¯ í‘œì¤€ Mall Customer ìƒ˜í”Œ ë°ì´í„° (200ëª…)")
    else:
        # ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ ì‚¬ìš©
        with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
            try:
                data = data_processor.load_data()
                st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data):,}ëª…ì˜ ê³ ê° ë°ì´í„°")
            except Exception as e:
                st.error(f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
                data = create_sample_data()
                st.info("ğŸ”„ ìƒ˜í”Œ ë°ì´í„°ë¡œ ëŒ€ì²´")

    if data is None or data.empty:
        st.error("âŒ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ë°ì´í„° ê²€ì¦ ë° ê¸°ë³¸ ì •ë³´
    validation_results = get_validation_results(data, data_processor)

    # í˜ì´ì§€ êµ¬ì„±
    show_basic_info(data, validation_results)
    show_data_quality_check(data, validation_results)
    show_statistical_summary(data)
    show_data_distribution(data)
    show_correlation_analysis(data)
    show_advanced_analysis(data)
    show_data_preview(data)

    return data


def get_validation_results(data, data_processor):
    """ë°ì´í„° ê²€ì¦ ê²°ê³¼ ìƒì„±"""
    try:
        if data_processor is not None:
            return data_processor.validate_data(data)
        else:
            # ê¸°ë³¸ ê²€ì¦
            return {
                'total_rows': len(data),
                'total_columns': len(data.columns),
                'data_types': data.dtypes,
                'has_missing': data.isnull().any().any(),
                'missing_values': data.isnull().sum(),
                'numeric_columns': len(data.select_dtypes(include=[np.number]).columns),
                'categorical_columns': len(data.select_dtypes(exclude=[np.number]).columns),
                'duplicate_rows': data.duplicated().sum()
            }
    except Exception as e:
        st.warning(f"ë°ì´í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            'total_rows': len(data),
            'total_columns': len(data.columns),
            'data_types': data.dtypes,
            'has_missing': False,
            'missing_values': pd.Series([0] * len(data.columns), index=data.columns),
            'numeric_columns': 3,
            'categorical_columns': 2,
            'duplicate_rows': 0
        }


def show_basic_info(data, validation_results):
    """ê¸°ë³¸ ë°ì´í„°ì…‹ ì •ë³´ í‘œì‹œ"""
    st.subheader("ğŸ“‹ ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ì „ì²´ ê³ ê° ìˆ˜", f"{validation_results['total_rows']:,}ëª…")
    with col2:
        st.metric("íŠ¹ì„± ìˆ˜", f"{validation_results['total_columns']}ê°œ")
    with col3:
        numeric_count = validation_results.get('numeric_columns',
                                               len(data.select_dtypes(include=[np.number]).columns))
        st.metric("ìˆ˜ì¹˜í˜• íŠ¹ì„±", f"{numeric_count}ê°œ")
    with col4:
        categorical_count = validation_results.get('categorical_columns',
                                                   len(data.select_dtypes(exclude=[np.number]).columns))
        st.metric("ë²”ì£¼í˜• íŠ¹ì„±", f"{categorical_count}ê°œ")

    # ë°ì´í„° íƒ€ì… ì •ë³´ (í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜)
    with st.expander("ğŸ“Š ì»¬ëŸ¼ë³„ ìƒì„¸ ì •ë³´"):
        dtypes_df = pd.DataFrame({
            "ì»¬ëŸ¼ëª…": data.columns,
            "ë°ì´í„° íƒ€ì…": [str(dtype) for dtype in data.dtypes],
            "ê²°ì¸¡ê°’ ìˆ˜": validation_results['missing_values'].values,
            "ìœ ë‹ˆí¬ ê°’ ìˆ˜": [data[col].nunique() for col in data.columns]
        })
        st.dataframe(dtypes_df, use_container_width=True)


def show_data_quality_check(data, validation_results):
    """ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼"""
    st.subheader("ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬")

    col1, col2 = st.columns(2)

    with col1:
        # ê²°ì¸¡ê°’ í˜„í™©
        st.write("**ğŸ“‰ ê²°ì¸¡ê°’ í˜„í™©**")
        if not validation_results['has_missing']:
            st.success("âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            missing_data = validation_results['missing_values'][validation_results['missing_values'] > 0]
            st.warning(f"âš ï¸ {len(missing_data)}ê°œ ì»¬ëŸ¼ì— ê²°ì¸¡ê°’ ë°œê²¬")
            for col, count in missing_data.items():
                percentage = (count / len(data)) * 100
                st.write(f"- {col}: {count}ê°œ ({percentage:.1f}%)")

        # ì¤‘ë³µê°’ í˜„í™©
        st.write("**ğŸ”„ ì¤‘ë³µê°’ í˜„í™©**")
        duplicate_count = validation_results.get('duplicate_rows', 0)
        if duplicate_count == 0:
            st.success("âœ… ì¤‘ë³µ í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning(f"âš ï¸ {duplicate_count}ê°œì˜ ì¤‘ë³µ í–‰ ë°œê²¬")

    with col2:
        # ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)
        st.write("**ğŸ“Š ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)**")
        numeric_cols = data.select_dtypes(include=[np.number]).columns

        for col in numeric_cols:
            if col != 'CustomerID':  # IDëŠ” ì œì™¸
                Q1 = data[col].quantile(0.25)
                Q3 = data[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR

                outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]
                outlier_count = len(outliers)
                outlier_percentage = (outlier_count / len(data)) * 100

                if outlier_count > 0:
                    st.warning(f"âš ï¸ {col}: {outlier_count}ê°œ ({outlier_percentage:.1f}%)")
                else:
                    st.success(f"âœ… {col}: ì´ìƒì¹˜ ì—†ìŒ")


def show_statistical_summary(data):
    """í†µê³„ì  ìš”ì•½"""
    st.subheader("ğŸ“Š í†µê³„ì  ìš”ì•½")

    col1, col2 = st.columns(2)

    with col1:
        st.write("**ìˆ˜ì¹˜í˜• íŠ¹ì„± ê¸°ë³¸ í†µê³„**")
        numeric_data = data.select_dtypes(include=[np.number])
        if not numeric_data.empty:
            st.dataframe(numeric_data.describe(), use_container_width=True)
        else:
            st.info("ìˆ˜ì¹˜í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with col2:
        st.write("**ë²”ì£¼í˜• íŠ¹ì„± ë¶„í¬**")
        categorical_data = data.select_dtypes(exclude=[np.number])
        if not categorical_data.empty:
            for col in categorical_data.columns:
                if col != 'CustomerID':
                    st.write(f"**{col}:**")
                    value_counts = data[col].value_counts()
                    for value, count in value_counts.items():
                        percentage = (count / len(data)) * 100
                        st.write(f"  - {value}: {count}ëª… ({percentage:.1f}%)")
        else:
            st.info("ë²”ì£¼í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


def show_data_distribution(data):
    """ë°ì´í„° ë¶„í¬ ì‹œê°í™”"""
    st.subheader("ğŸ“ˆ ê³ ê° íŠ¹ì„± ë¶„í¬")

    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì„ íƒ (CustomerID ì œì™¸)
    numeric_cols = [col for col in data.select_dtypes(include=[np.number]).columns
                    if col != 'CustomerID']

    if len(numeric_cols) == 0:
        st.warning("ì‹œê°í™”í•  ìˆ˜ì¹˜í˜• ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # íˆìŠ¤í† ê·¸ë¨ ìƒì„±
    if len(numeric_cols) > 0:
        # ë™ì ìœ¼ë¡œ subplot êµ¬ì„±
        n_cols = min(3, len(numeric_cols))
        n_rows = (len(numeric_cols) + n_cols - 1) // n_cols

        fig = make_subplots(
            rows=n_rows, cols=n_cols,
            subplot_titles=numeric_cols
        )

        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']

        for i, col in enumerate(numeric_cols):
            row = i // n_cols + 1
            col_pos = i % n_cols + 1

            fig.add_histogram(
                x=data[col],
                name=col,
                row=row, col=col_pos,
                marker_color=colors[i % len(colors)],
                opacity=0.7,
                nbinsx=25,
                showlegend=False
            )

        fig.update_layout(
            height=400 * n_rows,
            title_text="ê³ ê° íŠ¹ì„±ë³„ ë¶„í¬"
        )
        st.plotly_chart(fig, use_container_width=True)

    # ë²”ì£¼í˜• ë°ì´í„° ë¶„í¬
    show_categorical_visualizations(data)


def show_categorical_visualizations(data):
    """ë²”ì£¼í˜• ë°ì´í„° ì‹œê°í™”"""
    categorical_cols = [col for col in data.select_dtypes(exclude=[np.number]).columns
                        if col != 'CustomerID']

    if not categorical_cols:
        return

    st.write("**ğŸ‘¥ ë²”ì£¼í˜• íŠ¹ì„± ë¶„í¬**")

    for col in categorical_cols:
        if data[col].nunique() <= 10:  # ì¹´í…Œê³ ë¦¬ê°€ 10ê°œ ì´í•˜ì¸ ê²½ìš°ë§Œ ì‹œê°í™”
            col1, col2 = st.columns(2)

            with col1:
                # íŒŒì´ ì°¨íŠ¸
                value_counts = data[col].value_counts()
                fig = px.pie(
                    values=value_counts.values,
                    names=value_counts.index,
                    title=f"{col} ë¶„í¬",
                    color_discrete_sequence=px.colors.qualitative.Set3
                )
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                # ë§‰ëŒ€ ì°¨íŠ¸
                fig = px.bar(
                    x=value_counts.index,
                    y=value_counts.values,
                    title=f"{col} ê°œìˆ˜",
                    labels={'x': col, 'y': 'ê°œìˆ˜'}
                )
                st.plotly_chart(fig, use_container_width=True)


def show_correlation_analysis(data):
    """ìƒê´€ê´€ê³„ ë¶„ì„"""
    st.subheader("ğŸ”— íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„")

    # ìˆ˜ì¹˜í˜• ë°ì´í„°ë§Œ ì„ íƒ
    numeric_data = data.select_dtypes(include=[np.number])
    if 'CustomerID' in numeric_data.columns:
        numeric_data = numeric_data.drop('CustomerID', axis=1)

    if numeric_data.shape[1] < 2:
        st.info("ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ê°œì˜ ìˆ˜ì¹˜í˜• íŠ¹ì„±ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    correlation_matrix = numeric_data.corr()

    col1, col2 = st.columns(2)

    with col1:
        # íˆíŠ¸ë§µ
        fig = px.imshow(
            correlation_matrix,
            labels=dict(color="ìƒê´€ê³„ìˆ˜"),
            title="ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ",
            color_continuous_scale='RdBu_r',
            aspect="auto",
            text_auto=True
        )

        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        # ìƒê´€ê´€ê³„ í•´ì„
        st.write("**ğŸ“Š ìƒê´€ê´€ê³„ í•´ì„:**")
        st.markdown("""
        - **0.7 ì´ìƒ**: ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„ âœ…
        - **-0.7 ì´í•˜**: ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„ âŒ
        - **0.3 ~ 0.7**: ì¤‘ê°„ ì •ë„ì˜ ì–‘ì˜ ìƒê´€ê´€ê³„ ğŸ“ˆ
        - **-0.3 ~ -0.7**: ì¤‘ê°„ ì •ë„ì˜ ìŒì˜ ìƒê´€ê´€ê³„ ğŸ“‰
        - **-0.3 ~ 0.3**: ì•½í•œ ìƒê´€ê´€ê³„ â¡ï¸
        """)

        # ê°•í•œ ìƒê´€ê´€ê³„ ì°¾ê¸°
        strong_correlations = []
        for i in range(len(correlation_matrix.columns)):
            for j in range(i + 1, len(correlation_matrix.columns)):
                corr_value = correlation_matrix.iloc[i, j]
                if abs(corr_value) > 0.5:
                    col1_name = correlation_matrix.columns[i]
                    col2_name = correlation_matrix.columns[j]
                    strong_correlations.append((col1_name, col2_name, corr_value))

        if strong_correlations:
            st.write("**ğŸ¯ ì£¼ëª©í•  ë§Œí•œ ìƒê´€ê´€ê³„:**")
            for col1, col2, corr in strong_correlations:
                direction = "ì–‘ì˜" if corr > 0 else "ìŒì˜"
                strength = "ê°•í•œ" if abs(corr) > 0.7 else "ì¤‘ê°„"
                st.write(f"- {col1} â†” {col2}: {corr:.3f} ({strength} {direction} ìƒê´€)")


def show_advanced_analysis(data):
    """ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥"""
    st.subheader("ğŸ§  ê³ ê¸‰ ë¶„ì„")

    # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ”§ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ë¯¸ë¦¬ë³´ê¸°"):
        if st.button("ğŸš€ íŒŒìƒ íŠ¹ì„± ìƒì„±"):
            enhanced_data = create_derived_features(data)

            st.write("**ìƒˆë¡œ ìƒì„±ëœ íŠ¹ì„±:**")
            new_columns = [col for col in enhanced_data.columns if col not in data.columns]

            if new_columns:
                col1, col2 = st.columns(2)

                # ì»¬ëŸ¼ì„ ë‘ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                half = len(new_columns) // 2 if len(new_columns) > 1 else 1

                with col1:
                    for col in new_columns[:half]:
                        st.write(f"**{col}:**")
                        try:
                            value_counts = enhanced_data[col].value_counts()
                            # Arrow í˜¸í™˜ì„±ì„ ìœ„í•´ use_container_width=Falseë¡œ ë³€ê²½
                            st.dataframe(value_counts.to_frame('ê³ ê° ìˆ˜'), use_container_width=False)
                        except Exception as e:
                            st.write(f"í‘œì‹œ ì˜¤ë¥˜: {e}")
                            st.write(enhanced_data[col].value_counts().to_dict())

                with col2:
                    for col in new_columns[half:]:
                        st.write(f"**{col}:**")
                        try:
                            value_counts = enhanced_data[col].value_counts()
                            st.dataframe(value_counts.to_frame('ê³ ê° ìˆ˜'), use_container_width=False)
                        except Exception as e:
                            st.write(f"í‘œì‹œ ì˜¤ë¥˜: {e}")
                            st.write(enhanced_data[col].value_counts().to_dict())
            else:
                st.warning("ìƒˆë¡œìš´ íŠ¹ì„±ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                st.write("ë””ë²„ê¹… ì •ë³´:")
                st.write(f"ì›ë³¸ ì»¬ëŸ¼: {list(data.columns)}")
                st.write(f"í–¥ìƒëœ ë°ì´í„° ì»¬ëŸ¼: {list(enhanced_data.columns)}")

    # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ¯ ê³ ê° ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¯¸ë¦¬ë³´ê¸°"):
        if st.button("ğŸ“Š ê°„ë‹¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰"):
            show_basic_segmentation(data)


def create_derived_features(data):
    """íŒŒìƒ íŠ¹ì„± ìƒì„±"""
    enhanced_data = data.copy()

    # ë‚˜ì´ ê·¸ë£¹
    if 'Age' in data.columns:
        enhanced_data['Age_Group'] = pd.cut(
            data['Age'],
            bins=[0, 25, 35, 50, 100],
            labels=['ì²­ë…„ì¸µ(~25)', 'ì„±ì¸ì¸µ(26-35)', 'ì¤‘ë…„ì¸µ(36-50)', 'ì¥ë…„ì¸µ(51+)']
        ).astype(str)  # â† ì´ ë¶€ë¶„ ì¶”ê°€!

    # ì†Œë“ ê·¸ë£¹  
    if 'Annual Income (k$)' in data.columns:
        enhanced_data['Income_Group'] = pd.cut(
            data['Annual Income (k$)'],
            bins=[0, 40, 70, 100, 200],
            labels=['ì €ì†Œë“(~40k)', 'ì¤‘ì†Œë“(41-70k)', 'ê³ ì†Œë“(71-100k)', 'ìµœê³ ì†Œë“(101k+)']
        ).astype(str)  # â† ì´ ë¶€ë¶„ ì¶”ê°€!

    # ì§€ì¶œ ê·¸ë£¹
    if 'Spending Score (1-100)' in data.columns:
        enhanced_data['Spending_Group'] = pd.cut(
            data['Spending Score (1-100)'],
            bins=[0, 30, 60, 100],
            labels=['ì €ì§€ì¶œ(~30)', 'ì¤‘ì§€ì¶œ(31-60)', 'ê³ ì§€ì¶œ(61+)']
        ).astype(str)  # â† ì´ ë¶€ë¶„ ì¶”ê°€!

    # ì§€ì¶œ ì„±í–¥ (ì†Œë“ ëŒ€ë¹„ ì§€ì¶œ)
    if all(col in data.columns for col in ['Annual Income (k$)', 'Spending Score (1-100)']):
        enhanced_data['Spending_Propensity'] = (
                data['Spending Score (1-100)'] / data['Annual Income (k$)'] * 100
        ).round(2)

    return enhanced_data


def show_basic_segmentation(data):
    """ê¸°ë³¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰"""
    if not all(col in data.columns for col in ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']):
        st.warning("ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•œ í•„ìˆ˜ ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return

    # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜
    segmented_data = data.copy()

    # ì¡°ê±´ ì •ì˜
    conditions = [
        (data['Age'] < 35) & (data['Spending Score (1-100)'] > 60),
        (data['Age'] >= 35) & (data['Annual Income (k$)'] > 70) & (data['Spending Score (1-100)'] > 60),
        (data['Annual Income (k$)'] <= 50) & (data['Spending Score (1-100)'] <= 40),
        (data['Annual Income (k$)'] > 70) & (data['Spending Score (1-100)'] <= 40),
    ]

    choices = [
        'ì Šì€ ê³ ì†Œë¹„ì',
        'ì„±ìˆ™í•œ í”„ë¦¬ë¯¸ì—„ ê³ ê°',
        'ì €ì†Œë“ ì ˆì•½í˜•',
        'ê³ ì†Œë“ ì‹ ì¤‘í˜•'
    ]

    segmented_data['Segment'] = np.select(conditions, choices, default='ì¼ë°˜ ê³ ê°')

    # ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ ì‹œê°í™”
    segment_counts = segmented_data['Segment'].value_counts()

    col1, col2 = st.columns(2)

    with col1:
        fig = px.pie(
            values=segment_counts.values,
            names=segment_counts.index,
            title="ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬"
        )
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.write("**ì„¸ê·¸ë¨¼íŠ¸ë³„ ê³ ê° ìˆ˜:**")
        for segment, count in segment_counts.items():
            percentage = (count / len(data)) * 100
            st.write(f"- {segment}: {count}ëª… ({percentage:.1f}%)")


def show_data_preview(data):
    """ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"""
    st.subheader("ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")

    col1, col2 = st.columns(2)

    with col1:
        sample_size = st.selectbox("í‘œì‹œí•  í–‰ ìˆ˜:", [5, 10, 20, 50, 100], index=1)

    with col2:
        show_full_stats = st.checkbox("ì „ì²´ í†µê³„ ì •ë³´ í‘œì‹œ", False)

    # ì„ íƒëœ í–‰ ìˆ˜ë§Œí¼ ë°ì´í„° í‘œì‹œ
    st.dataframe(data.head(sample_size), use_container_width=True)

    # ì „ì²´ í†µê³„ ì •ë³´ (ì„ íƒì‚¬í•­)
    if show_full_stats:
        st.write("**ğŸ“Š ì „ì²´ í†µê³„ ì •ë³´:**")
        st.dataframe(data.describe(include='all'), use_container_width=True)


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
if __name__ == "__main__":
    show_data_overview_page()
