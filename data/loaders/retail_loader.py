"""
ë¦¬í…Œì¼ ë°ì´í„° ë¡œë” (ë§ˆì´ê·¸ë ˆì´ì…˜ë¨)

ê¸°ì¡´ core/retail/data_loader.pyì—ì„œ ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ë¨.
ìƒˆë¡œìš´ data/base í´ë˜ìŠ¤ë“¤ì„ í™œìš©í•˜ì—¬ ë” ì²´ê³„ì ì¸ ë°ì´í„° ì²˜ë¦¬ ì œê³µ.
"""

import pandas as pd
import numpy as np
import warnings
from datetime import datetime, timedelta
from typing import Dict, List, Optional

# ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ import
from data.base import DataValidator
from config.logging import setup_logger

warnings.filterwarnings("ignore")
logger = setup_logger(__name__)


class RetailDataLoader:
    """
    Online Retail ë°ì´í„° ë¡œë”© ë° í’ˆì§ˆ ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤
    
    ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ë” ì²´ê³„ì ì¸ ë°ì´í„° ì²˜ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    ê¸°ì¡´ core/retail/data_loader.pyì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜ë¨.
    """
    
    def __init__(self):
        """ì´ˆê¸°í™” ë©”ì„œë“œ"""
        self.raw_data = None
        self.data_quality_report = {}
        self.column_mapping = {}
        self.validator = DataValidator()  # ìƒˆë¡œìš´ ê²€ì¦ í´ë˜ìŠ¤ í™œìš©
        
    def load_data(self) -> pd.DataFrame:
        """
        UCI ML Repositoryì—ì„œ Online Retail ë°ì´í„° ë¡œë”©
        
        Returns:
            pd.DataFrame: ì›ë³¸ ë°ì´í„°
        """
        try:
            # UCI ML Repositoryì—ì„œ ë°ì´í„° ë¡œë”© ì‹œë„
            from ucimlrepo import fetch_ucirepo
            logger.info("ğŸ“¥ UCI ML Repositoryì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ì¤‘...")
            
            # Online Retail ë°ì´í„°ì…‹ (ID: 352)
            online_retail = fetch_ucirepo(id=352)
            
            # ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            if hasattr(online_retail.data, 'features'):
                data = online_retail.data.features.copy()
                if hasattr(online_retail.data, 'targets') and online_retail.data.targets is not None:
                    data = pd.concat([data, online_retail.data.targets], axis=1)
            else:
                data = online_retail.data.copy()
            
            logger.info(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {data.shape[0]:,}ê°œ ë ˆì½”ë“œ, {data.shape[1]}ê°œ ì»¬ëŸ¼")
            logger.debug(f"ğŸ“Š ì‹¤ì œ ì»¬ëŸ¼ëª…: {list(data.columns)}")
            logger.debug(f"ğŸ“Š ë°ì´í„° íƒ€ì…:\n{data.dtypes}")
            logger.debug(f"ğŸ“Š ë°ì´í„° ìƒ˜í”Œ (5í–‰):\n{data.head()}")
            
            # ì»¬ëŸ¼ ë§¤í•‘ ìƒì„± ë° ê¸°ë³¸ ê²€ì¦
            self.column_mapping = self._create_column_mapping(data.columns)
            logger.debug(f"ğŸ”„ ì»¬ëŸ¼ ë§¤í•‘: {self.column_mapping}")
            
            # ìƒˆë¡œìš´ ê²€ì¦ ì‹œìŠ¤í…œ í™œìš©
            self.validator.validate_dataframe(data)
            
        except ImportError:
            logger.warning("âš ï¸  ucimlrepo íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤...")
            data = self._load_data_fallback()
            
        except Exception as e:
            logger.error(f"âš ï¸  UCI ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            logger.info("ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¡œë”©í•©ë‹ˆë‹¤...")
            data = self._load_data_fallback()
            
        self.raw_data = data.copy()
        return data
    
    def _create_column_mapping(self, columns: list) -> dict:
        """ì‹¤ì œ ë°ì´í„° ì»¬ëŸ¼ì„ í‘œì¤€ ì»¬ëŸ¼ëª…ì— ë§¤í•‘"""
        
        column_mapping = {
            'invoice_no': None,
            'stock_code': None,
            'description': None,
            'quantity': None,
            'invoice_date': None,
            'unit_price': None,
            'customer_id': None,
            'country': None
        }
        
        # ì»¬ëŸ¼ëª… ë§¤í•‘ ë£° (case-insensitive)
        for col in columns:
            col_lower = col.lower().replace(' ', '_').replace('-', '_')
            
            if any(x in col_lower for x in ['invoice']) and any(x in col_lower for x in ['no', 'number', 'id']):
                column_mapping['invoice_no'] = col
            elif any(x in col_lower for x in ['invoice']) and any(x in col_lower for x in ['date', 'time']):
                column_mapping['invoice_date'] = col
            elif any(x in col_lower for x in ['stock', 'item', 'product']) and any(x in col_lower for x in ['code', 'id', 'no']):
                column_mapping['stock_code'] = col
            elif any(x in col_lower for x in ['description', 'desc', 'name']) and 'customer' not in col_lower:
                column_mapping['description'] = col
            elif any(x in col_lower for x in ['quantity', 'qty']) and 'unit' not in col_lower:
                column_mapping['quantity'] = col
            elif any(x in col_lower for x in ['price', 'cost']) and any(x in col_lower for x in ['unit', 'per']):
                column_mapping['unit_price'] = col
            elif any(x in col_lower for x in ['customer', 'client']) and any(x in col_lower for x in ['id', 'no']):
                column_mapping['customer_id'] = col
            elif any(x in col_lower for x in ['country', 'nation']):
                column_mapping['country'] = col
        
        logger.debug(f"ì»¬ëŸ¼ ë§¤í•‘ ìƒì„± ì™„ë£Œ: {column_mapping}")
        return column_mapping
    
    def _load_data_fallback(self) -> pd.DataFrame:
        """ëŒ€ì²´ ë°ì´í„° ë¡œë”© ë°©ë²•"""
        try:
            url = "https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx"
            logger.info(f"ğŸ“¥ ì§ì ‘ URLì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ì¤‘: {url}")
            
            data = pd.read_excel(url, engine='openpyxl')
            logger.info(f"âœ… ëŒ€ì²´ ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ë¡œë”© ì™„ë£Œ: {data.shape[0]:,}ê°œ ë ˆì½”ë“œ")
            
            # ì»¬ëŸ¼ ë§¤í•‘ ìƒì„± ë° ê²€ì¦
            self.column_mapping = self._create_column_mapping(data.columns)
            self.validator.validate_dataframe(data)
            
            return data
            
        except Exception as e:
            logger.error(f"âš ï¸  ëŒ€ì²´ ë°©ë²•ë„ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            return self._generate_sample_data()
    
    def _generate_sample_data(self) -> pd.DataFrame:
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        logger.info("ğŸ”§ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...")
        
        np.random.seed(42)
        n_records = 10000
        
        # ë‚ ì§œ ë²”ìœ„: 2010ë…„ 12ì›” ~ 2011ë…„ 12ì›”
        start_date = datetime(2010, 12, 1)
        end_date = datetime(2011, 12, 9)
        date_range = pd.date_range(start_date, end_date, freq='H')
        
        data = {
            'InvoiceNo': [f'C{np.random.randint(536365, 581587)}' if np.random.random() < 0.02 
                         else str(np.random.randint(536365, 581587)) for _ in range(n_records)],
            'StockCode': [f'{np.random.choice(["POST", "BANK", "M", "S", "AMAZONFEE"])}'  if np.random.random() < 0.05
                         else f'{np.random.randint(10000, 99999)}{np.random.choice(["", "A", "B", "C"])}' 
                         for _ in range(n_records)],
            'Description': [np.random.choice([
                'WHITE HANGING HEART T-LIGHT HOLDER',
                'WHITE METAL LANTERN', 
                'CREAM CUPID HEARTS COAT HANGER',
                'KNITTED UNION FLAG HOT WATER BOTTLE',
                'RED WOOLLY HOTTIE WHITE HEART',
                'SET 7 BABUSHKA NESTING BOXES',
                'GLASS STAR FROSTED T-LIGHT HOLDER',
                np.nan
            ]) for _ in range(n_records)],
            'Quantity': np.random.randint(-80, 80, n_records),
            'InvoiceDate': np.random.choice(date_range, n_records),
            'UnitPrice': np.round(np.random.lognormal(1.5, 1) * np.random.choice([0.1, 0.5, 1, 2, 5, 10]), 2),
            'CustomerID': [np.random.randint(12346, 18287) if np.random.random() < 0.85 
                          else np.nan for _ in range(n_records)],
            'Country': np.random.choice([
                'United Kingdom', 'France', 'Australia', 'Netherlands', 
                'Germany', 'Norway', 'EIRE', 'Spain', 'Belgium', 'Sweden'
            ], n_records, p=[0.7, 0.05, 0.05, 0.04, 0.04, 0.03, 0.03, 0.02, 0.02, 0.02])
        }
        
        df = pd.DataFrame(data)
        
        # ì»¬ëŸ¼ ë§¤í•‘ ìƒì„± ë° ê²€ì¦
        self.column_mapping = self._create_column_mapping(df.columns)
        self.validator.validate_dataframe(df)
        
        logger.info(f"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {df.shape[0]:,}ê°œ ë ˆì½”ë“œ")
        return df
    
    def analyze_data_quality(self, data: pd.DataFrame) -> Dict:
        """
        ë°ì´í„° í’ˆì§ˆ ë¶„ì„ (ìƒˆë¡œìš´ ê²€ì¦ ì‹œìŠ¤í…œ í™œìš©)
        
        ê¸°ì¡´ ë¡œì§ê³¼ ìƒˆë¡œìš´ data/base í´ë˜ìŠ¤ë“¤ì„ ì¡°í•©í•˜ì—¬ 
        ë” ì²´ê³„ì ì¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.
        """
        logger.info("ğŸ” ë°ì´í„° í’ˆì§ˆ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ê¸°ë³¸ ê²€ì¦ ë¨¼ì € ìˆ˜í–‰
        self.validator.validate_dataframe(data)
        
        # ìƒˆë¡œìš´ ê²€ì¦ ì‹œìŠ¤í…œ í™œìš©
        missing_info = self.validator.check_missing_values(data, threshold=0.5)
        outliers_info = self.validator.detect_outliers(data, method='iqr')
        
        # ê¸°ì¡´ ë¡œì§ê³¼ í†µí•©í•œ í’ˆì§ˆ ë¦¬í¬íŠ¸
        quality_report = {
            'basic_info': {
                'total_records': len(data),
                'total_columns': len(data.columns),
                'memory_usage_mb': round(data.memory_usage(deep=True).sum() / 1024**2, 2),
                'duplicate_rows': data.duplicated().sum(),
            },
            'missing_values': missing_info,  # ìƒˆë¡œìš´ ê²€ì¦ ì‹œìŠ¤í…œ ê²°ê³¼
            'outliers': outliers_info,       # ìƒˆë¡œìš´ ê²€ì¦ ì‹œìŠ¤í…œ ê²°ê³¼
            'data_types': {},
            'data_range': {}
        }
        
        # ë°ì´í„° íƒ€ì… ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        logger.info("ğŸ”¤ ë°ì´í„° íƒ€ì… ë¶„ì„ ì¤‘...")
        for col in data.columns:
            quality_report['data_types'][col] = {
                'current_type': str(data[col].dtype),
                'non_null_count': data[col].count(),
                'unique_values': data[col].nunique()
            }
        
        # ë°ì´í„° ë²”ìœ„ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        logger.info("ğŸ“ ë°ì´í„° ë²”ìœ„ ë¶„ì„ ì¤‘...")
        for col in data.columns:
            if data[col].dtype in ['int64', 'float64']:
                quality_report['data_range'][col] = {
                    'min': data[col].min(),
                    'max': data[col].max(),
                    'mean': round(data[col].mean(), 2),
                    'std': round(data[col].std(), 2)
                }
            elif data[col].dtype == 'object':
                quality_report['data_range'][col] = {
                    'unique_count': data[col].nunique(),
                    'most_common': data[col].mode().iloc[0] if len(data[col].mode()) > 0 else None,
                    'sample_values': data[col].dropna().head(3).tolist()
                }
        
        self.data_quality_report = quality_report
        logger.info("âœ… ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ")
        
        return quality_report
    
    def get_column_mapping(self) -> dict:
        """ì»¬ëŸ¼ ë§¤í•‘ ì •ë³´ ë°˜í™˜"""
        return self.column_mapping.copy()
    
    def save_processed_data(self, df: pd.DataFrame, filename: str = None) -> str:
        """
        ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ retail ë„ë©”ì¸ í´ë”ì— ì €ì¥
        
        ìƒˆë¡œìš´ ë°ì´í„° ê³„ì¸µ êµ¬ì¡°ë¥¼ í™œìš©í•œ ë°ì´í„° ì €ì¥ ê¸°ëŠ¥
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"retail_data_{timestamp}.csv"
        
        save_path = f"data/processed/retail/{filename}"
        df.to_csv(save_path, index=False)
        
        logger.info(f"ë¦¬í…Œì¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {save_path}")
        return save_path
