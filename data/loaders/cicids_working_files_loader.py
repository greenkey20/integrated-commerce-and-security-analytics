# íŒŒì¼ëª…: cicids_working_files_loader.py
# ìœ„ì¹˜: data/loaders/cicids_working_files_loader.py

import pandas as pd
import os
from typing import List, Dict


class WorkingCICIDSLoader:
    """ì‘ë™í•˜ëŠ” CICIDS2017 íŒŒì¼ë§Œ í™œìš©í•˜ëŠ” ë¡œë”"""

    def __init__(self, data_dir: str):
        self.data_dir = data_dir

        # íŒŒì¼ë³„ ê³µê²© ë°ì´í„° ìœ„ì¹˜ ì •ë³´ (ì§„ë‹¨ ê²°ê³¼ ê¸°ë°˜)
        self.file_info = {
            # ê¸°ì¡´ (ìœ ì§€)
            'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv': {
                'attack_start': 100000,
                'expected_labels': ['PortScan', 'BENIGN']
            },
            
            # ì‹ ê·œ ì¶”ê°€ - TODOì—ì„œ í™•ì¸ëœ íŒŒì¼ë“¤
            'Tuesday-WorkingHours.pcap_ISCX.csv': {
                'attack_start': 50000,
                'expected_labels': ['FTP-Patator', 'BENIGN']
            },
            'Wednesday-workingHours.pcap_ISCX.csv': {
                'attack_start': 50000,
                'expected_labels': ['DoS slowloris', 'BENIGN']
            },
            'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv': {
                'attack_start': 50000,
                'expected_labels': ['Web Attack â€“ Brute Force', 'BENIGN']  # ì‹¤ì œ ë¼ë²¨ëª… ì‚¬ìš©
            },
            'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv': {
                'attack_start': 50000,
                'expected_labels': ['DDoS', 'BENIGN']
            },
            'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv': {
                'attack_start': 100000,  # Infiltrationì€ ë” ë’¤ì— ìœ„ì¹˜í•  ìˆ˜ ìˆìŒ
                'expected_labels': ['Infiltration', 'BENIGN']
            }
        }

    def load_working_files(self, target_samples: int = 300000) -> pd.DataFrame:
        """ì‘ë™í•˜ëŠ” íŒŒì¼ë“¤ë§Œ ë¡œë“œ"""

        all_data = []

        for filename, info in self.file_info.items():
            file_path = os.path.join(self.data_dir, filename)

            if not os.path.exists(file_path):
                print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {filename}")
                continue

            print(f"ğŸ“ ë¡œë”©: {filename}")

            # ê³µê²© ë°ì´í„°ê°€ ìˆëŠ” ë¶€ë¶„ë¶€í„° ë¡œë“œ
            df = pd.read_csv(
                file_path,
                skiprows=range(1, info['attack_start']),  # ì•ë¶€ë¶„ ìŠ¤í‚µ
                nrows=target_samples // len(self.file_info),
                encoding='utf-8'
            )

            # ì»¬ëŸ¼ëª… ì •ë¦¬
            df.columns = [col.strip() for col in df.columns]

            print(f"   ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {len(df)}ê°œ")
            print(f"   ğŸ·ï¸ ë¼ë²¨ ë¶„í¬: {df['Label'].value_counts().to_dict()}")

            all_data.append(df)

        if not all_data:
            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ CICIDS2017 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

        # ë°ì´í„° ê²°í•©
        combined_df = pd.concat(all_data, ignore_index=True)

        # ì„ê¸°
        combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)

        print(f"\nâœ… ìµœì¢… ê²°í•© ë°ì´í„°:")
        print(f"   ğŸ“Š ì´ ìƒ˜í”Œ ìˆ˜: {len(combined_df)}")
        print(f"   ğŸ·ï¸ ë¼ë²¨ ë¶„í¬:")
        for label, count in combined_df['Label'].value_counts().items():
            percentage = (count / len(combined_df)) * 100
            print(f"      - {label}: {count:,}ê°œ ({percentage:.1f}%)")

        return combined_df


def quick_validate_more_files():
    """ë‹¤ë¥¸ íŒŒì¼ë“¤ë„ ë¹ ë¥´ê²Œ ê²€ì¦"""

    data_dir = "C:/keydev/integrated-commerce-and-security-analytics/data/cicids2017"

    candidates = [
        'Monday-WorkingHours.pcap_ISCX.csv',
        'Tuesday-WorkingHours.pcap_ISCX.csv',
        'Wednesday-workingHours.pcap_ISCX.csv',
        'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv'
    ]

    working_files = []

    for filename in candidates:
        file_path = os.path.join(data_dir, filename)

        if not os.path.exists(file_path):
            continue

        print(f"\nğŸ” ê²€ì¦: {filename}")

        try:
            # ì—¬ëŸ¬ ìœ„ì¹˜ì—ì„œ ìƒ˜í”Œë§
            positions = [0, 50000, 100000, 150000, 200000]
            found_attacks = False

            for pos in positions:
                try:
                    if pos == 0:
                        df_sample = pd.read_csv(file_path, nrows=100, encoding='utf-8')
                    else:
                        df_sample = pd.read_csv(
                            file_path,
                            nrows=100,
                            skiprows=range(1, pos),
                            encoding='utf-8'
                        )

                    # ì»¬ëŸ¼ëª… ì •ë¦¬
                    df_sample.columns = [col.strip() for col in df_sample.columns]

                    # BENIGN ì´ì™¸ ë¼ë²¨ ì°¾ê¸°
                    labels = df_sample['Label'].unique()
                    non_benign = [l for l in labels if 'BENIGN' not in str(l).upper()]

                    if non_benign:
                        print(f"   âœ… ìœ„ì¹˜ {pos}: {non_benign} ë°œê²¬!")
                        found_attacks = True
                        break

                except Exception as e:
                    continue  # í•´ë‹¹ ìœ„ì¹˜ì—ì„œ ì½ê¸° ì‹¤íŒ¨ì‹œ ë‹¤ìŒ ìœ„ì¹˜ ì‹œë„

            if found_attacks:
                working_files.append(filename)
                print(f"   ğŸ¯ {filename} â†’ ì‚¬ìš© ê°€ëŠ¥!")
            else:
                print(f"   âŒ {filename} â†’ BENIGNë§Œ ìˆìŒ")

        except Exception as e:
            print(f"   ğŸ’¥ {filename} â†’ ì˜¤ë¥˜: {str(e)[:50]}")

    return working_files


if __name__ == "__main__":
    print("ğŸš€ CICIDS2017 ì‘ë™ íŒŒì¼ ê²€ì¦")
    print("=" * 50)

    # 1. ì¶”ê°€ íŒŒì¼ë“¤ ê²€ì¦
    working_files = quick_validate_more_files()

    print(f"\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ë“¤: {working_files}")

    # 2. ì‘ë™í•˜ëŠ” íŒŒì¼ë¡œ ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸
    try:
        loader = WorkingCICIDSLoader("C:/keydev/integrated-commerce-and-security-analytics/data/cicids2017")
        
        # ì´ë¯¸ file_infoì— ëª¨ë“  íŒŒì¼ì´ ì„¤ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì„¤ì • ë¶ˆí•„ìš”
        
        # ë°ì´í„° ë¡œë“œ (ë” ë§ì€ ìƒ˜í”Œ)
        dataset = loader.load_working_files(target_samples=300000)
        print("\nğŸ‰ CICIDS2017 ë¶€ë¶„ í™œìš© ì„±ê³µ!")
        
    except Exception as e:
        print(f"\nâŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ RealisticSecurityDataGenerator í™•ì¥ì„ ê¶Œì¥í•©ë‹ˆë‹¤")