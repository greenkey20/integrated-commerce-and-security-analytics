import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib.patches import Ellipse
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA  # PCA ì¶”ê°€
from sklearn.metrics import silhouette_score
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import warnings
warnings.filterwarnings('ignore')

@st.cache_resource
def setup_korean_font_for_streamlit():
    """Streamlitìš© í•œê¸€ í°íŠ¸ ì„¤ì • (ìºì‹± ì ìš©)"""
    
    # ì§„ë‹¨ì—ì„œ í™•ì¸ëœ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” í°íŠ¸ë“¤
    reliable_fonts = [
        {
            'name': 'AppleGothic',
            'path': '/System/Library/Fonts/Supplemental/AppleGothic.ttf'
        },
        {
            'name': 'Arial Unicode MS',
            'path': '/Library/Fonts/Arial Unicode.ttf'
        },
        {
            'name': 'Helvetica',
            'path': '/System/Library/Fonts/Helvetica.ttc'
        }
    ]
    
    for font_info in reliable_fonts:
        font_path = font_info['path']
        font_name = font_info['name']
        
        if os.path.exists(font_path):
            try:
                # í°íŠ¸ë¥¼ matplotlibì— ë“±ë¡
                fm.fontManager.addfont(font_path)
                
                # FontProperties ê°ì²´ ìƒì„±
                font_prop = fm.FontProperties(fname=font_path)
                actual_name = font_prop.get_name()
                
                # matplotlib ì „ì—­ ì„¤ì • ì ìš©
                plt.rcParams['font.family'] = [actual_name]
                plt.rcParams['font.sans-serif'] = [actual_name] + plt.rcParams['font.sans-serif']
                plt.rcParams['axes.unicode_minus'] = False
                
                return font_prop, actual_name
                
            except Exception:
                continue
    
    # í°íŠ¸ ì„¤ì • ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
    return None, None

def analyze_cluster_characteristics(data_with_clusters, n_clusters):
    """í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ ë™ì  ë¼ë²¨ê³¼ ìƒ‰ìƒì„ ìƒì„±"""
    
    cluster_profiles = []
    
    for cluster_id in range(n_clusters):
        cluster_data = data_with_clusters[data_with_clusters['Cluster'] == cluster_id]
        
        if len(cluster_data) == 0:
            continue
            
        profile = {
            'cluster_id': cluster_id,
            'size': len(cluster_data),
            'avg_income': cluster_data['Annual Income (k$)'].mean(),
            'avg_spending': cluster_data['Spending Score (1-100)'].mean(),
            'avg_age': cluster_data['Age'].mean(),
            'std_income': cluster_data['Annual Income (k$)'].std(),
            'std_spending': cluster_data['Spending Score (1-100)'].std(),
        }
        cluster_profiles.append(profile)
    
    # ì „ì²´ í´ëŸ¬ìŠ¤í„° ëŒ€ë¹„ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚°
    all_incomes = [p['avg_income'] for p in cluster_profiles]
    all_spendings = [p['avg_spending'] for p in cluster_profiles]
    all_ages = [p['avg_age'] for p in cluster_profiles]
    
    income_quartiles = np.percentile(all_incomes, [25, 50, 75])
    spending_quartiles = np.percentile(all_spendings, [25, 50, 75])
    age_quartiles = np.percentile(all_ages, [25, 50, 75])
    
    # ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ ë™ì  ë¼ë²¨ ìƒì„±
    for profile in cluster_profiles:
        # ì†Œë“ ìˆ˜ì¤€ ë¶„ë¥˜ (ë” ì„¸ë¶„í™”)
        if profile['avg_income'] >= income_quartiles[2]:
            if profile['avg_income'] >= np.percentile(all_incomes, 90):
                income_level = "ìµœê³ ì†Œë“"
            else:
                income_level = "ê³ ì†Œë“"
        elif profile['avg_income'] >= income_quartiles[1]:
            income_level = "ì¤‘ìƒì†Œë“"
        elif profile['avg_income'] >= income_quartiles[0]:
            income_level = "ì¤‘í•˜ì†Œë“"
        else:
            income_level = "ì €ì†Œë“"
        
        # ì§€ì¶œ ìˆ˜ì¤€ ë¶„ë¥˜ (ë” ì„¸ë¶„í™”)
        if profile['avg_spending'] >= spending_quartiles[2]:
            if profile['avg_spending'] >= np.percentile(all_spendings, 90):
                spending_level = "ìµœê³ ì§€ì¶œ"
            else:
                spending_level = "ê³ ì§€ì¶œ"
        elif profile['avg_spending'] >= spending_quartiles[1]:
            spending_level = "ì¤‘ìƒì§€ì¶œ"
        elif profile['avg_spending'] >= spending_quartiles[0]:
            spending_level = "ì¤‘í•˜ì§€ì¶œ"
        else:
            spending_level = "ì €ì§€ì¶œ"
        
        # ì—°ë ¹ëŒ€ ë¶„ë¥˜
        if profile['avg_age'] <= age_quartiles[0]:
            age_group = "ì²­ë…„ì¸µ"
        elif profile['avg_age'] <= age_quartiles[1]:
            age_group = "ì²­ì¥ë…„ì¸µ"
        elif profile['avg_age'] <= age_quartiles[2]:
            age_group = "ì¤‘ë…„ì¸µ"
        else:
            age_group = "ì¥ë…„ì¸µ"
        
        # ê³ ê° ìœ í˜• ê²°ì • (ì†Œë“ê³¼ ì§€ì¶œ ì¡°í•©)
        if income_level in ["ìµœê³ ì†Œë“", "ê³ ì†Œë“"] and spending_level in ["ìµœê³ ì§€ì¶œ", "ê³ ì§€ì¶œ"]:
            customer_type = "í”„ë¦¬ë¯¸ì—„"
        elif income_level in ["ìµœê³ ì†Œë“", "ê³ ì†Œë“"] and spending_level in ["ì €ì§€ì¶œ", "ì¤‘í•˜ì§€ì¶œ"]:
            customer_type = "ë³´ìˆ˜ì "
        elif income_level in ["ì €ì†Œë“", "ì¤‘í•˜ì†Œë“"] and spending_level in ["ê³ ì§€ì¶œ", "ìµœê³ ì§€ì¶œ"]:
            customer_type = "ì ê·¹ì†Œë¹„"
        elif income_level in ["ì €ì†Œë“", "ì¤‘í•˜ì†Œë“"] and spending_level in ["ì €ì§€ì¶œ", "ì¤‘í•˜ì§€ì¶œ"]:
            customer_type = "ì ˆì•½í˜•"
        else:
            customer_type = "ì¼ë°˜"
        
        # ìµœì¢… ë¼ë²¨ ìƒì„±
        profile['label'] = f"{customer_type} {age_group}"
        profile['income_level'] = income_level
        profile['spending_level'] = spending_level
        profile['age_group'] = age_group
        profile['customer_type'] = customer_type
    
    return cluster_profiles

def generate_dynamic_colors(cluster_profiles):
    """í´ëŸ¬ìŠ¤í„° íŠ¹ì„±ì— ë”°ë¥¸ ì¼ê´€ëœ ìƒ‰ìƒ ë§¤í•‘ ìƒì„±"""
    
    # ê¸°ë³¸ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (ë” ë§ì€ ìƒ‰ìƒ)
    base_colors = [
        '#e41a1c',  # ë¹¨ê°• - í”„ë¦¬ë¯¸ì—„/ê³ ì†Œë“
        '#377eb8',  # íŒŒë‘ - ë³´ìˆ˜ì /ì•ˆì •ì 
        '#4daf4a',  # ì´ˆë¡ - ì¼ë°˜/ê· í˜•ì 
        '#984ea3',  # ë³´ë¼ - ì ê·¹ì†Œë¹„/ì Šì€ì¸µ
        '#ff7f00',  # ì£¼í™© - ì ˆì•½í˜•/ì‹¤ìš©ì 
        '#ffff33',  # ë…¸ë‘ - íŠ¹ë³„ ì¹´í…Œê³ ë¦¬
        '#a65628',  # ê°ˆìƒ‰ - ì¤‘ë…„ì¸µ/ì „í†µì 
        '#f781bf',  # ë¶„í™ - ì—¬ì„±ì /ê°ì„±ì 
        '#999999',  # íšŒìƒ‰ - ì¤‘ë¦½ì 
        '#66c2a5',  # ì²­ë¡
    ]
    
    colors = []
    for i, profile in enumerate(cluster_profiles):
        # ê³ ê° ìœ í˜•ì— ë”°ë¥¸ ìƒ‰ìƒ ì„ íƒ
        if profile['customer_type'] == "í”„ë¦¬ë¯¸ì—„":
            colors.append('#e41a1c')  # ë¹¨ê°•
        elif profile['customer_type'] == "ë³´ìˆ˜ì ":
            colors.append('#377eb8')  # íŒŒë‘
        elif profile['customer_type'] == "ì ê·¹ì†Œë¹„":
            colors.append('#984ea3')  # ë³´ë¼
        elif profile['customer_type'] == "ì ˆì•½í˜•":
            colors.append('#ff7f00')  # ì£¼í™©
        else:  # ì¼ë°˜
            colors.append(base_colors[i % len(base_colors)])
    
    return colors

def generate_dynamic_interpretation_guide(cluster_profiles):
    """ë™ì  í´ëŸ¬ìŠ¤í„° í•´ì„ ê°€ì´ë“œ ìƒì„±"""
    
    if len(cluster_profiles) == 0:
        return "í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì†Œë“ê³¼ ì§€ì¶œ ë²”ìœ„ ê³„ì‚°
    min_income = min(p['avg_income'] for p in cluster_profiles)
    max_income = max(p['avg_income'] for p in cluster_profiles)
    min_spending = min(p['avg_spending'] for p in cluster_profiles)
    max_spending = max(p['avg_spending'] for p in cluster_profiles)
    min_age = min(p['avg_age'] for p in cluster_profiles)
    max_age = max(p['avg_age'] for p in cluster_profiles)
    
    # ë¶„ë¥˜ ê¸°ì¤€ ê³„ì‚° (ì‚¬ë¶„ìœ„ìˆ˜)
    all_incomes = [p['avg_income'] for p in cluster_profiles]
    all_spendings = [p['avg_spending'] for p in cluster_profiles]
    all_ages = [p['avg_age'] for p in cluster_profiles]
    
    income_quartiles = np.percentile(all_incomes, [25, 50, 75, 90])
    spending_quartiles = np.percentile(all_spendings, [25, 50, 75, 90])
    age_quartiles = np.percentile(all_ages, [25, 50, 75])
    
    guide_text = f"""
    **í˜„ì¬ {len(cluster_profiles)}ê°œ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼ í•´ì„:**
    
    **ì „ì²´ ë°ì´í„° ë²”ìœ„:**
    - ì†Œë“ ë²”ìœ„: ${min_income:.1f}k ~ ${max_income:.1f}k
    - ì§€ì¶œì ìˆ˜ ë²”ìœ„: {min_spending:.1f} ~ {max_spending:.1f}
    - ì—°ë ¹ ë²”ìœ„: {min_age:.1f}ì„¸ ~ {max_age:.1f}ì„¸
    
    **ë™ì  ë¼ë²¨ë§ ë¶„ë¥˜ ê¸°ì¤€:**
    
    **ì†Œë“ ìˆ˜ì¤€ ë¶„ë¥˜ ê¸°ì¤€:**
    - ìµœê³ ì†Œë“: ${income_quartiles[3]:.1f}k ì´ìƒ (ìƒìœ„ 10%)
    - ê³ ì†Œë“: ${income_quartiles[2]:.1f}k ~ ${income_quartiles[3]:.1f}k (ìƒìœ„ 25%)
    - ì¤‘ìƒì†Œë“: ${income_quartiles[1]:.1f}k ~ ${income_quartiles[2]:.1f}k (ìƒìœ„ 50%)
    - ì¤‘í•˜ì†Œë“: ${income_quartiles[0]:.1f}k ~ ${income_quartiles[1]:.1f}k (í•˜ìœ„ 50%)
    - ì €ì†Œë“: ${income_quartiles[0]:.1f}k ë¯¸ë§Œ (í•˜ìœ„ 25%)
    
    **ì§€ì¶œ ì„±í–¥ ë¶„ë¥˜ ê¸°ì¤€:**
    - ìµœê³ ì§€ì¶œ: {spending_quartiles[3]:.1f}ì  ì´ìƒ (ìƒìœ„ 10%)
    - ê³ ì§€ì¶œ: {spending_quartiles[2]:.1f}ì  ~ {spending_quartiles[3]:.1f}ì  (ìƒìœ„ 25%)
    - ì¤‘ìƒì§€ì¶œ: {spending_quartiles[1]:.1f}ì  ~ {spending_quartiles[2]:.1f}ì  (ìƒìœ„ 50%)
    - ì¤‘í•˜ì§€ì¶œ: {spending_quartiles[0]:.1f}ì  ~ {spending_quartiles[1]:.1f}ì  (í•˜ìœ„ 50%)
    - ì €ì§€ì¶œ: {spending_quartiles[0]:.1f}ì  ë¯¸ë§Œ (í•˜ìœ„ 25%)
    
    **ì—°ë ¹ëŒ€ ë¶„ë¥˜ ê¸°ì¤€:**
    - ì²­ë…„ì¸µ: {age_quartiles[0]:.1f}ì„¸ ë¯¸ë§Œ
    - ì²­ì¥ë…„ì¸µ: {age_quartiles[0]:.1f}ì„¸ ~ {age_quartiles[1]:.1f}ì„¸
    - ì¤‘ë…„ì¸µ: {age_quartiles[1]:.1f}ì„¸ ~ {age_quartiles[2]:.1f}ì„¸
    - ì¥ë…„ì¸µ: {age_quartiles[2]:.1f}ì„¸ ì´ìƒ
    
    **ê³ ê° ìœ í˜• ì •ì˜:**
    - **í”„ë¦¬ë¯¸ì—„**: ê³ ì†Œë“ + ê³ ì§€ì¶œ ì¡°í•© â†’ ìµœìš°ì„  ê´€ë¦¬ ëŒ€ìƒ
    - **ë³´ìˆ˜ì **: ê³ ì†Œë“ + ì €ì§€ì¶œ ì¡°í•© â†’ ì¶”ê°€ ì†Œë¹„ ìœ ë„ ê°€ëŠ¥
    - **ì ê·¹ì†Œë¹„**: ì €ì†Œë“ + ê³ ì§€ì¶œ ì¡°í•© â†’ ì‹ ìš© ê´€ë¦¬ ì§€ì› í•„ìš”
    - **ì ˆì•½í˜•**: ì €ì†Œë“ + ì €ì§€ì¶œ ì¡°í•© â†’ ê°€ì„±ë¹„ ì¤‘ì‹¬ ì ‘ê·¼
    - **ì¼ë°˜**: ìœ„ ì¡°í•©ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì¤‘ê°„ ì„±í–¥
    
    **ê° í´ëŸ¬ìŠ¤í„°ì˜ ìƒì„¸ íŠ¹ì„±:**
    """
    
    # ì†Œë“ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì„¤ëª…
    sorted_profiles = sorted(cluster_profiles, key=lambda x: x['avg_income'], reverse=True)
    
    for profile in sorted_profiles:
        guide_text += f"""
    - **í´ëŸ¬ìŠ¤í„° {profile['cluster_id']} ({profile['label']})**: 
      í‰ê·  ì†Œë“ ${profile['avg_income']:.1f}k, ì§€ì¶œì ìˆ˜ {profile['avg_spending']:.1f}, í‰ê·  ì—°ë ¹ {profile['avg_age']:.1f}ì„¸
      ê³ ê° ìˆ˜ {profile['size']}ëª…, ê³ ê° ìœ í˜•: {profile['customer_type']}
      ({profile['income_level']} Ã— {profile['spending_level']} Ã— {profile['age_group']} ì¡°í•©)
        """
    
    guide_text += f"""
    
    **í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ ì§€í‘œ:**
    - í´ëŸ¬ìŠ¤í„° ê°„ ì†Œë“ ê²©ì°¨: ${max_income - min_income:.1f}k
    - í´ëŸ¬ìŠ¤í„° ê°„ ì§€ì¶œì„±í–¥ ì°¨ì´: {max_spending - min_spending:.1f}ì 
    - í´ëŸ¬ìŠ¤í„° ê°„ ì—°ë ¹ ì°¨ì´: {max_age - min_age:.1f}ì„¸
    - ê°€ì¥ í° í´ëŸ¬ìŠ¤í„°: {max(cluster_profiles, key=lambda x: x['size'])['size']}ëª…
    - ê°€ì¥ ì‘ì€ í´ëŸ¬ìŠ¤í„°: {min(cluster_profiles, key=lambda x: x['size'])['size']}ëª…
    - í´ëŸ¬ìŠ¤í„° í¬ê¸° í¸ì°¨: {np.std([p['size'] for p in cluster_profiles]):.1f}ëª…
    """
    
    return guide_text

# í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤í–‰
korean_font_prop, korean_font_name = setup_korean_font_for_streamlit()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê³ ê° ì„¸ë¶„í™” ë¶„ì„ ì„œë¹„ìŠ¤",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì œëª© ë° ì†Œê°œ
st.title("ğŸ›ï¸ Mall Customer Segmentation Analysis")
st.markdown("""
ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ K-means í´ëŸ¬ìŠ¤í„°ë§ì„ í™œìš©í•˜ì—¬ ì‡¼í•‘ëª° ê³ ê°ì„ ì„¸ë¶„í™”í•˜ê³  
ê° ê·¸ë£¹ë³„ íŠ¹ì„±ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ë§ˆì¼€íŒ… ì „ëµì„ ì œê³µí•©ë‹ˆë‹¤.
""")

# ì‚¬ì´ë“œë°” ë©”ë‰´
st.sidebar.title("ğŸ“‹ Navigation")
menu = st.sidebar.selectbox(
    "ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
    ["ë°ì´í„° ê°œìš”", "íƒìƒ‰ì  ë°ì´í„° ë¶„ì„", "í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„", "ì£¼ì„±ë¶„ ë¶„ì„", "ê³ ê° ì˜ˆì¸¡", "ë§ˆì¼€íŒ… ì „ëµ"]
)

@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    try:
        # GitHubì—ì„œ ì§ì ‘ ë°ì´í„° ë¡œë“œ
        url = "https://raw.githubusercontent.com/tirthajyoti/Machine-Learning-with-Python/master/Datasets/Mall_Customers.csv"
        data = pd.read_csv(url)
        return data
    except:
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)
        np.random.seed(42)
        sample_data = {
            'CustomerID': range(1, 201),
            'Gender': np.random.choice(['Male', 'Female'], 200),
            'Age': np.random.normal(40, 15, 200).astype(int),
            'Annual Income (k$)': np.random.normal(60, 20, 200).astype(int),
            'Spending Score (1-100)': np.random.normal(50, 25, 200).astype(int)
        }
        data = pd.DataFrame(sample_data)
        data['Age'] = np.clip(data['Age'], 18, 80)
        data['Annual Income (k$)'] = np.clip(data['Annual Income (k$)'], 15, 150)
        data['Spending Score (1-100)'] = np.clip(data['Spending Score (1-100)'], 1, 100)
        return data

@st.cache_data
def perform_clustering(data, n_clusters=5):
    """K-means í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰"""
    # í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ íŠ¹ì„± ì„ íƒ
    features = data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]
    
    # ë°ì´í„° ì •ê·œí™”
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    
    # K-means í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(scaled_features)
    
    # ì‹¤ë£¨ì—£ ì ìˆ˜ ê³„ì‚°
    silhouette_avg = silhouette_score(scaled_features, clusters)
    
    return clusters, kmeans, scaler, silhouette_avg

def find_optimal_clusters(data, max_k=10):
    """ì—˜ë³´ìš° ë°©ë²•ìœ¼ë¡œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸°"""
    features = data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    
    inertias = []
    silhouette_scores = []
    k_range = range(2, max_k + 1)
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        clusters = kmeans.fit_predict(scaled_features)
        inertias.append(kmeans.inertia_)
        silhouette_scores.append(silhouette_score(scaled_features, clusters))
    
    return k_range, inertias, silhouette_scores

def get_dynamic_marketing_strategy(cluster_id, profile, all_profiles):
    """ê° í´ëŸ¬ìŠ¤í„°ì˜ ìƒëŒ€ì  íŠ¹ì„±ì„ ê³ ë ¤í•œ ë™ì  ë§ˆì¼€íŒ… ì „ëµ ìƒì„±"""
    
    # ì „ì²´ í´ëŸ¬ìŠ¤í„° ëŒ€ë¹„ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚°
    all_incomes = [p['avg_income'] for p in all_profiles.values()]
    all_spendings = [p['avg_spending'] for p in all_profiles.values()]
    all_ages = [p['avg_age'] for p in all_profiles.values()]
    
    income_percentile = (sum(1 for x in all_incomes if x < profile['avg_income']) / len(all_incomes)) * 100
    spending_percentile = (sum(1 for x in all_spendings if x < profile['avg_spending']) / len(all_spendings)) * 100
    age_percentile = (sum(1 for x in all_ages if x < profile['avg_age']) / len(all_ages)) * 100
    
    # ì†Œë“ ìˆ˜ì¤€ ë¶„ë¥˜
    if income_percentile >= 75:
        income_level = "ê³ ì†Œë“"
    elif income_percentile >= 40:
        income_level = "ì¤‘ê°„ì†Œë“"
    else:
        income_level = "ì €ì†Œë“"
    
    # ì§€ì¶œ ìˆ˜ì¤€ ë¶„ë¥˜
    if spending_percentile >= 75:
        spending_level = "ê³ ì§€ì¶œ"
    elif spending_percentile >= 40:
        spending_level = "ì¤‘ê°„ì§€ì¶œ"
    else:
        spending_level = "ì €ì§€ì¶œ"
    
    # ì—°ë ¹ëŒ€ ë¶„ë¥˜
    if age_percentile <= 25:
        age_group = "ì Šì€ì¸µ"
    elif age_percentile >= 75:
        age_group = "ì¤‘ì¥ë…„ì¸µ"
    else:
        age_group = "ì¤‘ê°„ì—°ë ¹ì¸µ"
    
    # ì„¸ê·¸ë¨¼íŠ¸ ëª… ìƒì„±
    segment_name = f"{income_level} {spending_level} {age_group}"
    
    # ì „ëµ ìƒì„±
    strategies = []
    priorities = []
    
    # ì†Œë“ ê¸°ë°˜ ì „ëµ
    if income_level == "ê³ ì†Œë“":
        if spending_level == "ê³ ì§€ì¶œ":
            strategies.append("í”„ë¦¬ë¯¸ì—„ ì œí’ˆ ë¼ì¸ ì§‘ì¤‘, VIP ì„œë¹„ìŠ¤")
            priorities.append("ìµœìš°ì„ ")
        elif spending_level == "ì €ì§€ì¶œ":
            strategies.append("ê°€ì¹˜ ì œì•ˆ ë§ˆì¼€íŒ…, íˆ¬ì ìƒí’ˆ ì†Œê°œ")
            priorities.append("ë†’ìŒ")
        else:
            strategies.append("í’ˆì§ˆ ì¤‘ì‹¬ ë§ˆì¼€íŒ…, ë¸Œëœë“œ ê°€ì¹˜ ê°•ì¡°")
            priorities.append("ë†’ìŒ")
    elif income_level == "ì¤‘ê°„ì†Œë“":
        if spending_level == "ê³ ì§€ì¶œ":
            strategies.append("í• ë¶€ ì„œë¹„ìŠ¤, ìºì‹œë°± í˜œíƒ")
            priorities.append("ì¤‘ê°„")
        else:
            strategies.append("í•©ë¦¬ì  ê°€ê²©ëŒ€ ì œí’ˆ, í”„ë¡œëª¨ì…˜ í™œìš©")
            priorities.append("ì¤‘ê°„")
    else:  # ì €ì†Œë“
        strategies.append("ì €ê°€ ì œí’ˆ ë¼ì¸, ëŒ€ëŸ‰ í• ì¸, ë©¤ë²„ì‹­ í˜œíƒ")
        priorities.append("ë‚®ìŒ")
    
    # ì—°ë ¹ ê¸°ë°˜ ì¶”ê°€ ì „ëµ
    if age_group == "ì Šì€ì¸µ":
        strategies.append("ì†Œì…œë¯¸ë””ì–´ ë§ˆì¼€íŒ…, ì˜¨ë¼ì¸ ì±„ë„ ê°•í™”")
    elif age_group == "ì¤‘ì¥ë…„ì¸µ":
        strategies.append("ì˜¤í”„ë¼ì¸ ë§¤ì¥ ì„œë¹„ìŠ¤, ì „í™” ìƒë‹´ ê°•í™”")
    else:
        strategies.append("ì˜´ë‹ˆì±„ë„ ì ‘ê·¼, ë‹¤ì–‘í•œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜")
    
    # íŠ¹ë³„í•œ ì¡°í•©ì— ëŒ€í•œ ë§ì¶¤ ì „ëµ
    if income_level == "ì €ì†Œë“" and spending_level == "ê³ ì§€ì¶œ":
        strategies.append("ì‹ ìš© ê´€ë¦¬ ì„œë¹„ìŠ¤, ì˜ˆì‚° ê´€ë¦¬ ë„êµ¬ ì œê³µ")
    elif income_level == "ê³ ì†Œë“" and spending_level == "ì €ì§€ì¶œ":
        strategies.append("ì ˆì•½ ë³´ìƒ í”„ë¡œê·¸ë¨, ì¥ê¸° ê³ ê° í˜œíƒ")
    
    return {
        'segment': segment_name,
        'strategy': '; '.join(strategies),
        'priority': priorities[0] if priorities else 'ë³´í†µ',
        'income_level': income_level,
        'spending_level': spending_level,
        'age_group': age_group,
        'percentiles': {
            'income': f"{income_percentile:.0f}%",
            'spending': f"{spending_percentile:.0f}%",
            'age': f"{age_percentile:.0f}%"
        }
    }

# ë°ì´í„° ë¡œë“œ
data = load_data()

if menu == "ë°ì´í„° ê°œìš”":
    st.header("ğŸ“Š ë°ì´í„° ê°œìš”")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ë°ì´í„°ì…‹ ì •ë³´")
        st.write(f"ì „ì²´ ê³ ê° ìˆ˜: {len(data):,}ëª…")
        st.write(f"íŠ¹ì„± ìˆ˜: {len(data.columns)}ê°œ")
        st.write("ë°ì´í„° íƒ€ì…:")
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì¶œë ¥
        dtypes_df = pd.DataFrame({
            'ì»¬ëŸ¼ëª…': data.columns,
            'ë°ì´í„° íƒ€ì…': [str(dtype) for dtype in data.dtypes]
        })
        st.dataframe(dtypes_df, use_container_width=True)
    
    with col2:
        st.subheader("ê¸°ë³¸ í†µê³„")
        st.write(data.describe())
    
    st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(data.head(10))
    
    # ê²°ì¸¡ê°’ í™•ì¸
    st.subheader("ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬")
    missing_values = data.isnull().sum()
    if missing_values.sum() == 0:
        st.success("âœ… ê²°ì¸¡ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ ê²°ì¸¡ê°’ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
        st.write(missing_values[missing_values > 0])

elif menu == "íƒìƒ‰ì  ë°ì´í„° ë¶„ì„":
    st.header("ğŸ” íƒìƒ‰ì  ë°ì´í„° ë¶„ì„")
    
    # ì„±ë³„ ë¶„í¬
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ì„±ë³„ ë¶„í¬")
        gender_counts = data['Gender'].value_counts()
        fig = px.pie(values=gender_counts.values, names=gender_counts.index, 
                     title="ê³ ê° ì„±ë³„ ë¶„í¬")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ì—°ë ¹ ë¶„í¬")
        fig = px.histogram(data, x='Age', nbins=20, title="ì—°ë ¹ ë¶„í¬")
        fig.update_layout(
            xaxis_title="ì—°ë ¹",
            yaxis_title="ê³ ê° ìˆ˜"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # ì†Œë“ vs ì§€ì¶œ ì ìˆ˜ ì‚°ì ë„
    st.subheader("ì†Œë“ ëŒ€ë¹„ ì§€ì¶œ ì ìˆ˜ ë¶„ì„")
    fig = px.scatter(data, x='Annual Income (k$)', y='Spending Score (1-100)', 
                     color='Gender', title="ì—°ê°„ ì†Œë“ vs ì§€ì¶œ ì ìˆ˜",
                     hover_data=['Age'])
    fig.update_layout(
        xaxis_title="ì—°ê°„ ì†Œë“ (ì²œ ë‹¬ëŸ¬)",
        yaxis_title="ì§€ì¶œ ì ìˆ˜ (1-100)"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    st.subheader("íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„")
    numeric_cols = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']
    correlation_matrix = data[numeric_cols].corr()
    
    fig = px.imshow(correlation_matrix, 
                    labels=dict(color="ìƒê´€ê³„ìˆ˜"),
                    x=numeric_cols, y=numeric_cols,
                    title="íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ")
    st.plotly_chart(fig, use_container_width=True)

elif menu == "í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„":
    st.header("ğŸ¯ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„")
    
    # í´ëŸ¬ìŠ¤í„°ë§ ì´ë¡  ì„¤ëª… ì„¹ì…˜ ì¶”ê°€
    with st.expander("ğŸ“š í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ì´ë¡  ê°€ì´ë“œ", expanded=True):
        st.markdown("""
        ### ğŸ¤” ì™œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ ê²°ì •í•´ì•¼ í• ê¹Œìš”?
        
        K-means ì•Œê³ ë¦¬ì¦˜ì˜ ê°€ì¥ í° íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” **ì‚¬ì „ì— í´ëŸ¬ìŠ¤í„° ê°œìˆ˜(K)ë¥¼ ì§€ì •í•´ì•¼ í•œë‹¤ëŠ” ê²ƒ**ì…ë‹ˆë‹¤. 
        ì´ëŠ” ë§ˆì¹˜ ì¼€ì´í¬ë¥¼ ìë¥¼ ë•Œ "ëª‡ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆŒê¹Œ?"ë¥¼ ë¯¸ë¦¬ ì •í•´ì•¼ í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. 
        í•˜ì§€ë§Œ ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¥¼ ëª¨ë¥´ê¸° ë•Œë¬¸ì—, ê³¼í•™ì ì¸ ë°©ë²•ìœ¼ë¡œ ì´ë¥¼ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.
        
        ### ğŸ“ˆ ì—˜ë³´ìš° ë°©ë²• (Elbow Method)
        
        **í•µì‹¬ ì•„ì´ë””ì–´**: í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ì— ë”°ë¥¸ "ì„±ëŠ¥ ëŒ€ë¹„ íš¨ìœ¨ì„±"ì„ ì¸¡ì •í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
        
        - **Inertia(ê´€ì„±)**: ê° ë°ì´í„° í¬ì¸íŠ¸ì™€ í•´ë‹¹ í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ê°„ì˜ ê±°ë¦¬ ì œê³±ì˜ ì´í•©
        - **í•´ì„ ë°©ë²•**: ê·¸ë˜í”„ì—ì„œ ê¸‰ê²©íˆ êº¾ì´ëŠ” ì§€ì (íŒ”ê¿ˆì¹˜ ëª¨ì–‘)ì„ ì°¾ìŠµë‹ˆë‹¤
        - **ë¹„ìœ **: ë§ˆì¹˜ ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ì„ ë”°ì§ˆ ë•Œ "ê°€ì„±ë¹„"ê°€ ê¸‰ê²©íˆ ë‚˜ë¹ ì§€ëŠ” ì§€ì ì„ ì°¾ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤
        
        **ğŸ“Š ê·¸ë˜í”„ ì½ëŠ” ë²•**: 
        - í´ëŸ¬ìŠ¤í„°ê°€ ì ìœ¼ë©´ â†’ Inertia ë†’ìŒ (ë¶„ë¥˜ê°€ ê±°ì¹¨)
        - í´ëŸ¬ìŠ¤í„°ê°€ ë§ìœ¼ë©´ â†’ Inertia ë‚®ìŒ (í•˜ì§€ë§Œ ê³¼ë„í•œ ì„¸ë¶„í™”)
        - **ìµœì ì **: Inertiaê°€ ê¸‰ê²©íˆ ê°ì†Œí•˜ë‹¤ê°€ ì™„ë§Œí•´ì§€ëŠ” ì§€ì 
        
        ### ğŸ¯ ì‹¤ë£¨ì—£ ì ìˆ˜ (Silhouette Score)
        
        **í•µì‹¬ ì•„ì´ë””ì–´**: ê° ë°ì´í„°ê°€ ìì‹ ì˜ í´ëŸ¬ìŠ¤í„°ì— ì–¼ë§ˆë‚˜ "ì˜ ë§ëŠ”ì§€"ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
        
        - **ì ìˆ˜ ë²”ìœ„**: -1 ~ 1 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        - **ì˜ë¯¸**: 
          - 0.7~1.0: ë§¤ìš° ì¢‹ì€ í´ëŸ¬ìŠ¤í„°ë§
          - 0.5~0.7: ì ì ˆí•œ í´ëŸ¬ìŠ¤í„°ë§  
          - 0.25~0.5: ì•½í•œ í´ëŸ¬ìŠ¤í„°ë§
          - 0 ì´í•˜: ì˜ëª»ëœ í´ëŸ¬ìŠ¤í„°ë§
        
        **ğŸ“Š ê·¸ë˜í”„ ì½ëŠ” ë²•**:
        - ì‹¤ë£¨ì—£ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì§€ì ì´ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜
        - ì ìˆ˜ê°€ ì§€ì†ì ìœ¼ë¡œ ê°ì†Œí•œë‹¤ë©´ ë” ì ì€ í´ëŸ¬ìŠ¤í„°ê°€ ì í•©
        
        ### ğŸ² ë‘ ë°©ë²•ì„ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì´ìœ 
        
        ì—˜ë³´ìš° ë°©ë²•ê³¼ ì‹¤ë£¨ì—£ ì ìˆ˜ëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì—ì„œ í´ëŸ¬ìŠ¤í„° í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤:
        - **ì—˜ë³´ìš°**: "íš¨ìœ¨ì„±" ê´€ì  (ë¹„ìš© ëŒ€ë¹„ íš¨ê³¼)
        - **ì‹¤ë£¨ì—£**: "í’ˆì§ˆ" ê´€ì  (ë¶„ë¥˜ì˜ ëª…í™•ì„±)
        
        **ìµœì¢… ê²°ì •**: ë‘ ë°©ë²•ì—ì„œ ê³µí†µìœ¼ë¡œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì´ëŠ” í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¥¼ ì„ íƒí•˜ëŠ” ê²ƒì´ ê°€ì¥ ì•ˆì „í•©ë‹ˆë‹¤.
        """)
    
    # ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ì°¾ê¸°
    st.subheader("ğŸ” ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •")
    st.write("ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ì— ëŒ€í•´ ì—˜ë³´ìš° ë°©ë²•ê³¼ ì‹¤ë£¨ì—£ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì ì˜ Kê°’ì„ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.")
    
    with st.spinner("ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ë¶„ì„ì¤‘ì…ë‹ˆë‹¤..."):
        k_range, inertias, silhouette_scores = find_optimal_clusters(data)
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ì—˜ë³´ìš° ë°©ë²•
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=list(k_range), y=inertias, mode='lines+markers',
                                name='Inertia', line=dict(color='blue', width=3),
                                marker=dict(size=8)))
        fig.update_layout(
            title="ì—˜ë³´ìš° ë°©ë²•: Inertia ë³€í™”", 
            xaxis_title="í´ëŸ¬ìŠ¤í„° ìˆ˜", 
            yaxis_title="Inertia (ê´€ì„±)",
            showlegend=False
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ì—˜ë³´ìš° ë°©ë²• í•´ì„
        st.info("""
        **ğŸ“Š ì´ ê·¸ë˜í”„ í•´ì„í•˜ê¸°:**
        - í´ëŸ¬ìŠ¤í„° ìˆ˜ê°€ ì¦ê°€í• ìˆ˜ë¡ InertiaëŠ” ê°ì†Œí•©ë‹ˆë‹¤
        - ê¸‰ê²©íˆ êº¾ì´ëŠ” ì§€ì (ì—˜ë³´ìš°)ì„ ì°¾ìœ¼ì„¸ìš”
        - ë³´í†µ 2-3ë²ˆ í´ëŸ¬ìŠ¤í„° ì§€ì ì—ì„œ ê¸°ìš¸ê¸°ê°€ ì™„ë§Œí•´ì§‘ë‹ˆë‹¤
        """)
    
    with col2:
        # ì‹¤ë£¨ì—£ ì ìˆ˜
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=list(k_range), y=silhouette_scores, mode='lines+markers',
                                name='Silhouette Score', line=dict(color='red', width=3),
                                marker=dict(size=8)))
        fig.update_layout(
            title="ì‹¤ë£¨ì—£ ì ìˆ˜ ë³€í™”", 
            xaxis_title="í´ëŸ¬ìŠ¤í„° ìˆ˜", 
            yaxis_title="ì‹¤ë£¨ì—£ ì ìˆ˜",
            showlegend=False
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # ì‹¤ë£¨ì—£ ì ìˆ˜ í•´ì„
        best_k_silhouette = k_range[np.argmax(silhouette_scores)]
        best_silhouette_score = max(silhouette_scores)
        
        st.info(f"""
        **ğŸ“Š ì´ ê·¸ë˜í”„ í•´ì„í•˜ê¸°:**
        - ê°€ì¥ ë†’ì€ ì ìˆ˜: {best_silhouette_score:.3f} (K={best_k_silhouette})
        - ì ìˆ˜ê°€ 0.5 ì´ìƒì´ë©´ ì ì ˆí•œ í´ëŸ¬ìŠ¤í„°ë§
        - ê°€ì¥ ë†’ì€ ì§€ì ì´ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ì…ë‹ˆë‹¤
        """)
    
    # ë¶„ì„ ê²°ê³¼ ì¢…í•© ë° ê¶Œì¥ì‚¬í•­ ì œì‹œ
    st.subheader("ğŸ¯ ë¶„ì„ ê²°ê³¼ ì¢…í•© ë° ê¶Œì¥ì‚¬í•­")
    
    # ì—˜ë³´ìš° ë°©ë²•ìœ¼ë¡œ ìµœì  K ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    inertia_diffs = np.diff(inertias)
    inertia_diffs2 = np.diff(inertia_diffs)
    elbow_k = k_range[np.argmax(inertia_diffs2) + 2] if len(inertia_diffs2) > 0 else k_range[0]
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            label="ì—˜ë³´ìš° ë°©ë²• ì¶”ì²œ", 
            value=f"{elbow_k}ê°œ í´ëŸ¬ìŠ¤í„°",
            help="Inertia ê°ì†Œìœ¨ì´ ê°€ì¥ í¬ê²Œ ë³€í•˜ëŠ” ì§€ì "
        )
    
    with col2:
        st.metric(
            label="ì‹¤ë£¨ì—£ ì ìˆ˜ ì¶”ì²œ", 
            value=f"{best_k_silhouette}ê°œ í´ëŸ¬ìŠ¤í„°",
            delta=f"ì ìˆ˜: {best_silhouette_score:.3f}",
            help="ì‹¤ë£¨ì—£ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì§€ì "
        )
    
    with col3:
        # ìµœì¢… ê¶Œì¥ê°’ (ë‘ ë°©ë²•ì˜ ì ˆì¶©ì•ˆ)
        if elbow_k == best_k_silhouette:
            recommended_k = elbow_k
            agreement = "âœ… ì™„ì „ ì¼ì¹˜"
        else:
            recommended_k = int((elbow_k + best_k_silhouette) / 2)
            agreement = f"ğŸ“Š ì ˆì¶©ì•ˆ"
        
        st.metric(
            label="ìµœì¢… ê¶Œì¥", 
            value=f"{recommended_k}ê°œ í´ëŸ¬ìŠ¤í„°",
            delta=agreement,
            help="ë‘ ë°©ë²•ì„ ì¢…í•©í•œ ìµœì¢… ê¶Œì¥ì‚¬í•­"
        )
    
    # ê¶Œì¥ì‚¬í•­ ì„¤ëª…
    if elbow_k == best_k_silhouette:
        st.success(f"ğŸ‰ **ë‘ ë°©ë²•ì´ ëª¨ë‘ {elbow_k}ê°œ í´ëŸ¬ìŠ¤í„°ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤!** ì´ëŠ” ë§¤ìš° ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ì…ë‹ˆë‹¤.")
    else:
        st.warning(f"""
        ğŸ“Š **ë‘ ë°©ë²•ì˜ ê²°ê³¼ê°€ ë‹¤ë¦…ë‹ˆë‹¤:**
        - ì—˜ë³´ìš° ë°©ë²•: {elbow_k}ê°œ (íš¨ìœ¨ì„± ê´€ì )
        - ì‹¤ë£¨ì—£ ì ìˆ˜: {best_k_silhouette}ê°œ (í’ˆì§ˆ ê´€ì )
        
        ì´ëŸ° ê²½ìš° ë„ë©”ì¸ ì§€ì‹ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ì ì„ ê³ ë ¤í•˜ì—¬ ìµœì¢… ê²°ì •í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
        """)
    
    # í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„ íƒ ìŠ¬ë¼ì´ë” (Session State í™œìš©)
    st.subheader("âš™ï¸ í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„ íƒ")
    st.write("ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ìµœì¢… í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì´ ì„¤ì •ì€ ë‹¤ìŒ í˜ì´ì§€ë“¤ì—ì„œë„ ì¼ê´€ë˜ê²Œ ì ìš©ë©ë‹ˆë‹¤.")
    
    # Session State ì´ˆê¸°í™”
    if 'selected_clusters' not in st.session_state:
        st.session_state.selected_clusters = recommended_k
    
    selected_k = st.slider(
        "í´ëŸ¬ìŠ¤í„° ìˆ˜ ì„ íƒ:", 
        min_value=2, 
        max_value=10, 
        value=st.session_state.selected_clusters,
        help=f"ë¶„ì„ ê²°ê³¼ ê¶Œì¥: {recommended_k}ê°œ"
    )
    
    # Session State ì—…ë°ì´íŠ¸
    st.session_state.selected_clusters = selected_k
    
    # ì„ íƒëœ í´ëŸ¬ìŠ¤í„° ìˆ˜ì— ëŒ€í•œ ì‹¤ì‹œê°„ í”¼ë“œë°±
    if selected_k == recommended_k:
        st.success(f"âœ… ë¶„ì„ ê¶Œì¥ê°’ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤. ({selected_k}ê°œ)")
    elif selected_k in [elbow_k, best_k_silhouette]:
        st.info(f"ğŸ“Š ë¶„ì„ ë°©ë²• ì¤‘ í•˜ë‚˜ê°€ ì¶”ì²œí•˜ëŠ” ê°’ì…ë‹ˆë‹¤. ({selected_k}ê°œ)")
    else:
        st.warning(f"âš ï¸ ë¶„ì„ ê¶Œì¥ê°’ê³¼ ë‹¤ë¦…ë‹ˆë‹¤. íŠ¹ë³„í•œ ì´ìœ ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")
    
    # ì„ íƒëœ Kë¡œ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    optimal_k = selected_k
    
    # í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    clusters, kmeans, scaler, silhouette_avg = perform_clustering(data, optimal_k)
    data_with_clusters = data.copy()
    data_with_clusters['Cluster'] = clusters
    
    st.success(f"âœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ! ì‹¤ë£¨ì—£ ì ìˆ˜: {silhouette_avg:.3f}")
    
    # ë™ì  í´ëŸ¬ìŠ¤í„° ë¶„ì„ ìˆ˜í–‰
    cluster_profiles = analyze_cluster_characteristics(data_with_clusters, optimal_k)
    dynamic_colors = generate_dynamic_colors(cluster_profiles)
    interpretation_guide = generate_dynamic_interpretation_guide(cluster_profiles)
    
    # í´ëŸ¬ìŠ¤í„°ë³„ ì‹œê°í™”
    st.subheader("í´ëŸ¬ìŠ¤í„° ì‹œê°í™”")
    
    # 3D ì‚°ì ë„
    fig = px.scatter_3d(data_with_clusters, 
                        x='Age', y='Annual Income (k$)', z='Spending Score (1-100)',
                        color='Cluster', 
                        title="3D í´ëŸ¬ìŠ¤í„° ì‹œê°í™”",
                        hover_data=['Gender'])
    st.plotly_chart(fig, use_container_width=True)
    
    # 2D ì‚°ì ë„ (ì†Œë“ vs ì§€ì¶œì ìˆ˜)
    fig = px.scatter(data_with_clusters, 
                     x='Annual Income (k$)', y='Spending Score (1-100)',
                     color='Cluster', 
                     title="í´ëŸ¬ìŠ¤í„°ë³„ ì†Œë“ vs ì§€ì¶œì ìˆ˜",
                     hover_data=['Age', 'Gender'])
    st.plotly_chart(fig, use_container_width=True)
    
    # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ë¶„ì„
    st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ë¶„ì„")
    
    cluster_summary = data_with_clusters.groupby('Cluster').agg({
        'Age': ['mean', 'std'],
        'Annual Income (k$)': ['mean', 'std'],
        'Spending Score (1-100)': ['mean', 'std']
    }).round(2)
    
    cluster_summary.columns = ['í‰ê· _ì—°ë ¹', 'í‘œì¤€í¸ì°¨_ì—°ë ¹', 'í‰ê· _ì†Œë“', 'í‘œì¤€í¸ì°¨_ì†Œë“', 
                              'í‰ê· _ì§€ì¶œì ìˆ˜', 'í‘œì¤€í¸ì°¨_ì§€ì¶œì ìˆ˜']
    
    st.dataframe(cluster_summary)
    
    # í´ëŸ¬ìŠ¤í„°ë³„ ê³ ê° ìˆ˜
    cluster_counts = data_with_clusters['Cluster'].value_counts().sort_index()
    fig = px.bar(x=cluster_counts.index, y=cluster_counts.values,
                 title="í´ëŸ¬ìŠ¤í„°ë³„ ê³ ê° ìˆ˜")
    fig.update_layout(
        xaxis_title="í´ëŸ¬ìŠ¤í„°",
        yaxis_title="ê³ ê° ìˆ˜"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ìƒˆë¡œ ì¶”ê°€: í´ëŸ¬ìŠ¤í„° ê²°ê³¼ê°€ í‘œì‹œëœ ì‚°ì ë„ (matplotlib ì‚¬ìš©)
    st.subheader("ğŸ¯ í´ëŸ¬ìŠ¤í„° ë¶„ì„ ê²°ê³¼ ìƒì„¸ ì‹œê°í™”")
    st.write("ê° ê³ ê°ì´ ì–´ë–¤ í´ëŸ¬ìŠ¤í„°ì— ì†í•˜ëŠ”ì§€ ìƒ‰ìƒê³¼ ì˜ì—­ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    
    # matplotlibë¥¼ ì‚¬ìš©í•œ ìƒì„¸ í´ëŸ¬ìŠ¤í„° ì‹œê°í™”
    fig_detailed, ax = plt.subplots(figsize=(12, 8))

    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì ì„ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ì—­ë³€í™˜
    cluster_centers_scaled = kmeans.cluster_centers_
    cluster_centers_original = scaler.inverse_transform(cluster_centers_scaled)
    
    # 2D ì‹œê°í™”ë¥¼ ìœ„í•´ Annual Income(index 1)ê³¼ Spending Score(index 2) ì¢Œí‘œë§Œ ì¶”ì¶œ
    cluster_centers_2d = cluster_centers_original[:, [1, 2]]
    
    # ê° í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ì ë“¤ ê·¸ë¦¬ê¸° (ë™ì  ìƒ‰ìƒê³¼ ë¼ë²¨ ì‚¬ìš©)
    for i, profile in enumerate(cluster_profiles):
        cluster_id = profile['cluster_id']
        mask = data_with_clusters['Cluster'] == cluster_id
        cluster_data = data_with_clusters[mask]
        
        ax.scatter(cluster_data['Annual Income (k$)'], 
                  cluster_data['Spending Score (1-100)'], 
                  c=dynamic_colors[i], 
                  alpha=0.7, 
                  s=60,
                  label=f'í´ëŸ¬ìŠ¤í„° {cluster_id}: {profile["label"]} ({profile["size"]}ëª…)',
                  edgecolors='white',
                  linewidth=0.5)
    
    # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  í‘œì‹œ
    for i, center in enumerate(cluster_centers_2d):
        ax.scatter(center[0], center[1], 
                  c='black', 
                  marker='x', 
                  s=300, 
                  linewidths=4,
                  label='í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì ' if i == 0 else "")
    
    # í´ëŸ¬ìŠ¤í„° ì˜ì—­ì„ íƒ€ì›ìœ¼ë¡œ í‘œì‹œ
    for i, profile in enumerate(cluster_profiles):
        cluster_id = profile['cluster_id']
        cluster_data = data_with_clusters[data_with_clusters['Cluster'] == cluster_id]
        
        if len(cluster_data) > 1:
            # ê° í´ëŸ¬ìŠ¤í„°ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°
            mean_income = cluster_data['Annual Income (k$)'].mean()
            mean_spending = cluster_data['Spending Score (1-100)'].mean()
            std_income = cluster_data['Annual Income (k$)'].std()
            std_spending = cluster_data['Spending Score (1-100)'].std()
            
            # íƒ€ì› ìƒì„± (2 í‘œì¤€í¸ì°¨ ë²”ìœ„)
            ellipse = Ellipse((mean_income, mean_spending), 
                             width=4*std_income, 
                             height=4*std_spending,
                             fill=False, 
                             color=dynamic_colors[i], 
                             linewidth=2, 
                             linestyle='--',
                             alpha=0.8)
            ax.add_patch(ellipse)
    
    # í•œê¸€ í°íŠ¸ ì ìš©ëœ ë ˆì´ë¸” ì„¤ì •
    if korean_font_prop:
        ax.set_xlabel('ì—°ê°„ ì†Œë“ (ì²œ ë‹¬ëŸ¬)', fontproperties=korean_font_prop, fontsize=14)
        ax.set_ylabel('ì§€ì¶œ ì ìˆ˜ (1-100)', fontproperties=korean_font_prop, fontsize=14)
        ax.set_title(f'í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼: {optimal_k}ê°œ ê³ ê° ì„¸ë¶„í™” ì™„ì„±!', fontproperties=korean_font_prop, fontsize=16, fontweight='bold')
        
        # ë²”ë¡€ì—ë„ í•œê¸€ í°íŠ¸ ì ìš©
        legend = ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
        for text in legend.get_texts():
            if korean_font_prop:
                text.set_fontproperties(korean_font_prop)
    else:
        ax.set_xlabel('Annual Income (k$)', fontsize=14)
        ax.set_ylabel('Spending Score (1-100)', fontsize=14)
        ax.set_title(f'Clustering Results: {optimal_k} Customer Segments Complete!', fontsize=16, fontweight='bold')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
    
    ax.grid(True, alpha=0.3)
    ax.set_xlim(data['Annual Income (k$)'].min() - 5, data['Annual Income (k$)'].max() + 5)
    ax.set_ylim(data['Spending Score (1-100)'].min() - 5, data['Spending Score (1-100)'].max() + 5)
    
    plt.tight_layout()
    st.pyplot(fig_detailed)
    
    # ë™ì  í´ëŸ¬ìŠ¤í„° í•´ì„ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ
    with st.expander("ğŸ” ë™ì  í´ëŸ¬ìŠ¤í„° í•´ì„ ê°€ì´ë“œ"):
        st.markdown(interpretation_guide)
    
    st.success(f"âœ… ì´ {len(data)}ëª…ì˜ ê³ ê°ì´ {optimal_k}ê°œ ê·¸ë£¹ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤!")

elif menu == "ì£¼ì„±ë¶„ ë¶„ì„":
    st.header("ğŸ”¬ ì£¼ì„±ë¶„ ë¶„ì„ (Principal Component Analysis)")
    
    # PCA ì´ë¡  ì„¤ëª… ì„¹ì…˜
    with st.expander("ğŸ“š ì£¼ì„±ë¶„ ë¶„ì„ ì´ë¡  ê°€ì´ë“œ", expanded=True):
        st.markdown("""
        ### ğŸ¤” ì™œ ì£¼ì„±ë¶„ ë¶„ì„ì´ í•„ìš”í• ê¹Œìš”?
        
        ê³ ê° ë°ì´í„°ë¥¼ ë¶„ì„í•  ë•Œ ì—°ë ¹, ì†Œë“, ì§€ì¶œì ìˆ˜ ë“± **ì—¬ëŸ¬ ë³€ìˆ˜ê°€ ë™ì‹œì— ì¡´ì¬**í•©ë‹ˆë‹¤.
        ì´ëŸ° ë‹¤ì°¨ì› ë°ì´í„°ì—ì„œëŠ” ë³€ìˆ˜ë“¤ ê°„ì˜ ë³µì¡í•œ ê´€ê³„ë¥¼ íŒŒì•…í•˜ê¸° ì–´ë µê³ , ì‹œê°í™”ë„ ì œí•œì ì…ë‹ˆë‹¤.
        
        **ì°¨ì›ì˜ ì €ì£¼**: ë³€ìˆ˜ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ë°ì´í„° ê°„ ê±°ë¦¬ê°€ ë¹„ìŠ·í•´ì ¸ì„œ íŒ¨í„´ ì°¾ê¸°ê°€ ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤.
        ë§ˆì¹˜ 3ì°¨ì› ê³µê°„ì—ì„œëŠ” ì‰½ê²Œ êµ¬ë¶„ë˜ë˜ ë¬¼ì²´ë“¤ì´ 10ì°¨ì› ê³µê°„ì—ì„œëŠ” ëª¨ë‘ ë¹„ìŠ·í•œ ê±°ë¦¬ì— ìˆëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” í˜„ìƒì…ë‹ˆë‹¤.
        
        ### ğŸ¯ ì£¼ì„±ë¶„ ë¶„ì„ì˜ í•µì‹¬ ì•„ì´ë””ì–´
        
        PCAëŠ” **"ì •ë³´ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë©´ì„œ ì°¨ì›ì„ ì¤„ì´ëŠ”"** ë°©ë²•ì…ë‹ˆë‹¤.
        
        **í•µì‹¬ ì›ë¦¬**: 
        - ë°ì´í„°ì˜ **ë¶„ì‚°(í¼ì§ ì •ë„)ì„ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” ìƒˆë¡œìš´ ì¶•**ì„ ì°¾ìŠµë‹ˆë‹¤
        - ì´ ìƒˆë¡œìš´ ì¶•ë“¤ì„ **ì£¼ì„±ë¶„(Principal Component)**ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤
        - ì²« ë²ˆì§¸ ì£¼ì„±ë¶„ì€ ë°ì´í„° ë¶„ì‚°ì„ ê°€ì¥ ë§ì´ ì„¤ëª…í•˜ê³ , ë‘ ë²ˆì§¸ëŠ” ê·¸ ë‹¤ìŒìœ¼ë¡œ ë§ì´ ì„¤ëª…í•©ë‹ˆë‹¤
        
        **ë¹„ìœ ë¡œ ì´í•´í•˜ê¸°**: 
        ê·¸ë¦¼ì ë†€ì´ë¥¼ ìƒê°í•´ë³´ì„¸ìš”. 3ì°¨ì› ë¬¼ì²´ë¥¼ ë²½ì— ë¹„ì¶˜ ê·¸ë¦¼ìëŠ” 2ì°¨ì›ì´ì§€ë§Œ, 
        ì¡°ëª… ê°ë„ì— ë”°ë¼ ë¬¼ì²´ì˜ íŠ¹ì§•ì„ ì˜ ë³´ì—¬ì£¼ê±°ë‚˜ ëª» ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        PCAëŠ” ê°€ì¥ ë§ì€ ì •ë³´ë¥¼ ë‹´ì€ "ìµœì ì˜ ê·¸ë¦¼ì ê°ë„"ë¥¼ ì°¾ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.
        
        ### ğŸ“Š ì£¼ìš” ê°œë… ì„¤ëª…
        
        **ì£¼ì„±ë¶„ (Principal Component)**:
        - ì›ë˜ ë³€ìˆ˜ë“¤ì˜ **ì„ í˜• ê²°í•©**ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ìƒˆë¡œìš´ ë³€ìˆ˜
        - ì„œë¡œ **ì§êµ(ìˆ˜ì§)**í•˜ë©° **ë…ë¦½ì **ì¸ ê´€ê³„
        - PC1 > PC2 > PC3... ìˆœìœ¼ë¡œ ì„¤ëª…ë ¥ì´ ë†’ìŠµë‹ˆë‹¤
        
        **ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨ (Explained Variance Ratio)**:
        - ê° ì£¼ì„±ë¶„ì´ ì „ì²´ ë°ì´í„° ë³€ë™ì˜ ëª‡ %ë¥¼ ì„¤ëª…í•˜ëŠ”ì§€ ë‚˜íƒ€ëƒ„
        - ëª¨ë“  ì£¼ì„±ë¶„ì˜ ì„¤ëª… ë¹„ìœ¨ì„ í•©í•˜ë©´ 100%
        - ì²˜ìŒ ëª‡ ê°œ ì£¼ì„±ë¶„ìœ¼ë¡œ 80-90% ì´ìƒ ì„¤ëª…ë˜ë©´ ì°¨ì› ì¶•ì†Œ íš¨ê³¼ì 
        
        **ëˆ„ì  ê¸°ì—¬ìœ¨ (Cumulative Explained Variance)**:
        - ì²« ë²ˆì§¸ë¶€í„° në²ˆì§¸ ì£¼ì„±ë¶„ê¹Œì§€ì˜ ëˆ„ì  ì„¤ëª… ë¹„ìœ¨
        - ë³´í†µ 85-95% ìˆ˜ì¤€ì—ì„œ ì ì ˆí•œ ì°¨ì› ìˆ˜ë¥¼ ê²°ì •
        
        ### ğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš© ì‚¬ë¡€
        
        **ê³ ê° ë¶„ì„ì—ì„œì˜ PCA í™œìš©**:
        - **ê³ ê° íŠ¹ì„±ì˜ í•µì‹¬ ìš”ì¸ ë°œê²¬**: ìˆ˜ì‹­ ê°œ ë³€ìˆ˜ë¥¼ 2-3ê°œ í•µì‹¬ ìš”ì¸ìœ¼ë¡œ ì••ì¶•
        - **ì‹œê°í™” ê°œì„ **: 3ì°¨ì› ì´ìƒ ë°ì´í„°ë¥¼ 2D í‰ë©´ì—ì„œ ì§ê´€ì ìœ¼ë¡œ í‘œí˜„
        - **ë…¸ì´ì¦ˆ ì œê±°**: ì¤‘ìš”í•˜ì§€ ì•Šì€ ë³€ë™ì„ ê±¸ëŸ¬ë‚´ì–´ í•µì‹¬ íŒ¨í„´ì— ì§‘ì¤‘
        - **ì €ì¥ ê³µê°„ ì ˆì•½**: ë°ì´í„° ì••ì¶•ì„ í†µí•œ íš¨ìœ¨ì  ì €ì¥ ë° ì²˜ë¦¬
        """)
    
    # ê³ ê° ë°ì´í„°ì— PCA ì ìš©
    st.subheader("ğŸ”¬ ê³ ê° ë°ì´í„° ì£¼ì„±ë¶„ ë¶„ì„")
    st.write("ê³ ê°ì˜ ì—°ë ¹, ì†Œë“, ì§€ì¶œì ìˆ˜ ë°ì´í„°ì— PCAë¥¼ ì ìš©í•˜ì—¬ ìˆ¨ê²¨ì§„ íŒ¨í„´ì„ ë°œê²¬í•´ë³´ê² ìŠµë‹ˆë‹¤.")
    
    # ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
    features = data[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]
    feature_names = ['ì—°ë ¹', 'ì—°ê°„ì†Œë“(k$)', 'ì§€ì¶œì ìˆ˜']
    
    # ë°ì´í„° ì •ê·œí™” (PCAëŠ” ë³€ìˆ˜ì˜ ìŠ¤ì¼€ì¼ì— ë¯¼ê°í•˜ë¯€ë¡œ í•„ìˆ˜)
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    
    st.write("**1ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ**")
    st.info("PCAëŠ” ë³€ìˆ˜ì˜ ìŠ¤ì¼€ì¼ì— ë§¤ìš° ë¯¼ê°í•˜ë¯€ë¡œ, ëª¨ë“  ë³€ìˆ˜ë¥¼ í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ì •ê·œí™”í–ˆìŠµë‹ˆë‹¤.")
    
    # PCA ì ìš©
    # ëª¨ë“  ì£¼ì„±ë¶„ ê³„ì‚° (ìµœëŒ€ 3ê°œ - ì›ë˜ ë³€ìˆ˜ ê°œìˆ˜ì™€ ê°™ìŒ)
    pca_full = PCA()
    pca_components = pca_full.fit_transform(scaled_features)
    
    # ì£¼ì„±ë¶„ë³„ ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨
    explained_variance_ratio = pca_full.explained_variance_ratio_
    cumulative_variance = np.cumsum(explained_variance_ratio)
    
    st.write("**2ë‹¨ê³„: ì£¼ì„±ë¶„ ë¶„ì„ ê²°ê³¼**")
    
    # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
    pca_results = pd.DataFrame({
        'ì£¼ì„±ë¶„': [f'PC{i+1}' for i in range(len(explained_variance_ratio))],
        'ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨': explained_variance_ratio,
        'ëˆ„ì  ì„¤ëª… ë¹„ìœ¨': cumulative_variance,
        'ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨(%)': explained_variance_ratio * 100,
        'ëˆ„ì  ì„¤ëª… ë¹„ìœ¨(%)': cumulative_variance * 100
    })
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ì£¼ì„±ë¶„ë³„ ê¸°ì—¬ë„:**")
        # ì†Œìˆ˜ì  3ìë¦¬ê¹Œì§€ í‘œì‹œí•˜ë˜ ë°±ë¶„ìœ¨ì€ 1ìë¦¬ê¹Œì§€
        display_results = pca_results[['ì£¼ì„±ë¶„', 'ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨(%)', 'ëˆ„ì  ì„¤ëª… ë¹„ìœ¨(%)']].copy()
        display_results['ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨(%)'] = display_results['ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨(%)'].round(1)
        display_results['ëˆ„ì  ì„¤ëª… ë¹„ìœ¨(%)'] = display_results['ëˆ„ì  ì„¤ëª… ë¹„ìœ¨(%)'].round(1)
        st.dataframe(display_results, use_container_width=True)
        
        # ì£¼ìš” ë°œê²¬ì‚¬í•­ ìš”ì•½
        pc1_ratio = explained_variance_ratio[0] * 100
        pc2_ratio = explained_variance_ratio[1] * 100
        pc12_cumulative = cumulative_variance[1] * 100
        
        st.success(f"""
        **ğŸ“ˆ ì£¼ìš” ë°œê²¬ì‚¬í•­:**
        - PC1ì´ ì „ì²´ ë³€ë™ì˜ {pc1_ratio:.1f}%ë¥¼ ì„¤ëª…
        - PC2ê°€ ì¶”ê°€ë¡œ {pc2_ratio:.1f}%ë¥¼ ì„¤ëª…
        - PC1+PC2ë¡œ {pc12_cumulative:.1f}%ì˜ ì •ë³´ ë³´ì¡´
        """)
    
    with col2:
        # ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨ ì‹œê°í™”
        fig = go.Figure()
        
        # ê°œë³„ ê¸°ì—¬ë„ ë§‰ëŒ€ ê·¸ë˜í”„
        fig.add_trace(go.Bar(
            x=[f'PC{i+1}' for i in range(len(explained_variance_ratio))],
            y=explained_variance_ratio * 100,
            name='ê°œë³„ ê¸°ì—¬ë„',
            marker_color='lightblue'
        ))
        
        # ëˆ„ì  ê¸°ì—¬ë„ ì„  ê·¸ë˜í”„
        fig.add_trace(go.Scatter(
            x=[f'PC{i+1}' for i in range(len(cumulative_variance))],
            y=cumulative_variance * 100,
            mode='lines+markers',
            name='ëˆ„ì  ê¸°ì—¬ë„',
            line=dict(color='red', width=3),
            marker=dict(size=8),
            yaxis='y2'
        ))
        
        # 85% ê¸°ì¤€ì„  ì¶”ê°€
        fig.add_hline(y=85, line_dash="dash", line_color="gray", 
                     annotation_text="85% ê¸°ì¤€ì„ ", yref='y2')
        
        fig.update_layout(
            title="ì£¼ì„±ë¶„ë³„ ì„¤ëª…ë ¥ ë¶„ì„",
            xaxis_title="ì£¼ì„±ë¶„",
            yaxis=dict(title="ê°œë³„ ê¸°ì—¬ë„ (%)", side="left"),
            yaxis2=dict(title="ëˆ„ì  ê¸°ì—¬ë„ (%)", side="right", overlaying="y"),
            legend=dict(x=0.7, y=0.95)
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # ì£¼ì„±ë¶„ í•´ì„
    st.subheader("ğŸ” ì£¼ì„±ë¶„ êµ¬ì„± ìš”ì†Œ ë¶„ì„")
    st.write("ê° ì£¼ì„±ë¶„ì´ ì›ë˜ ë³€ìˆ˜ë“¤(ì—°ë ¹, ì†Œë“, ì§€ì¶œì ìˆ˜)ê³¼ ì–´ë–¤ ê´€ê³„ì¸ì§€ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.")
    
    # ì£¼ì„±ë¶„ ê³„ìˆ˜ (ë¡œë”©) ë¶„ì„
    components_df = pd.DataFrame(
        pca_full.components_.T,
        columns=[f'PC{i+1}' for i in range(pca_full.n_components_)],
        index=feature_names
    )
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ì£¼ì„±ë¶„ êµ¬ì„± ê³„ìˆ˜ (Component Loadings):**")
        # ê³„ìˆ˜ í…Œì´ë¸” í‘œì‹œ (ìƒ‰ìƒìœ¼ë¡œ ê°•ë„ í‘œí˜„)
        styled_components = components_df.style.background_gradient(
            cmap='RdBu_r', axis=None
        ).format('{:.3f}')
        st.dataframe(styled_components, use_container_width=True)
        
        # í•´ì„ ê°€ì´ë“œ
        st.info("""
        **í•´ì„ ë°©ë²•:**
        - ì–‘ìˆ˜(+): í•´ë‹¹ ë³€ìˆ˜ê°€ ì¦ê°€í•˜ë©´ ì£¼ì„±ë¶„ ê°’ë„ ì¦ê°€
        - ìŒìˆ˜(-): í•´ë‹¹ ë³€ìˆ˜ê°€ ì¦ê°€í•˜ë©´ ì£¼ì„±ë¶„ ê°’ì€ ê°ì†Œ
        - ì ˆëŒ“ê°’ì´ í´ìˆ˜ë¡: í•´ë‹¹ ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ì´ í¼
        """)
    
    with col2:
        # ì£¼ì„±ë¶„ êµ¬ì„± íˆíŠ¸ë§µ
        fig = px.imshow(
            components_df.T,
            labels=dict(x="ì›ë˜ ë³€ìˆ˜", y="ì£¼ì„±ë¶„", color="ê³„ìˆ˜"),
            x=feature_names,
            y=[f'PC{i+1}' for i in range(pca_full.n_components_)],
            color_continuous_scale='RdBu_r',
            aspect="auto",
            title="ì£¼ì„±ë¶„ êµ¬ì„± íˆíŠ¸ë§µ"
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # ì£¼ì„±ë¶„ í•´ì„ ìƒì„± (ë™ì )
    st.write("**ğŸ¯ ì£¼ì„±ë¶„ ì˜ë¯¸ í•´ì„:**")
    
    # PC1 í•´ì„
    pc1_coeffs = components_df['PC1']
    max_pc1_var = pc1_coeffs.abs().idxmax()
    pc1_direction = "ë†’ì€" if pc1_coeffs[max_pc1_var] > 0 else "ë‚®ì€"
    
    # PC2 í•´ì„  
    pc2_coeffs = components_df['PC2']
    max_pc2_var = pc2_coeffs.abs().idxmax()
    pc2_direction = "ë†’ì€" if pc2_coeffs[max_pc2_var] > 0 else "ë‚®ì€"
    
    st.write(f"""
    - **PC1 ({explained_variance_ratio[0]*100:.1f}% ì„¤ëª…)**: {max_pc1_var} ì¤‘ì‹¬ì˜ ì¶•ìœ¼ë¡œ, {pc1_direction} {max_pc1_var}ë¥¼ ê°€ì§„ ê³ ê°ë“¤ì„ êµ¬ë¶„í•©ë‹ˆë‹¤.
    - **PC2 ({explained_variance_ratio[1]*100:.1f}% ì„¤ëª…)**: {max_pc2_var} ì¤‘ì‹¬ì˜ ì¶•ìœ¼ë¡œ, {pc2_direction} {max_pc2_var}ë¥¼ ê°€ì§„ ê³ ê°ë“¤ì„ êµ¬ë¶„í•©ë‹ˆë‹¤.
    """)
    
    # 2D PCA ì‹œê°í™”
    st.subheader("ğŸ“Š ì£¼ì„±ë¶„ ê³µê°„ì—ì„œì˜ ê³ ê° ë¶„í¬")
    
    # 2D PCA ê²°ê³¼ë¥¼ DataFrameì— ì¶”ê°€
    pca_2d = PCA(n_components=2)
    pca_2d_result = pca_2d.fit_transform(scaled_features)
    
    data_pca = data.copy()
    data_pca['PC1'] = pca_2d_result[:, 0]
    data_pca['PC2'] = pca_2d_result[:, 1]
    
    # ì„±ë³„ë¡œ êµ¬ë¶„í•œ PCA ì‹œê°í™”
    fig = px.scatter(
        data_pca, 
        x='PC1', 
        y='PC2',
        color='Gender',
        title='ì£¼ì„±ë¶„ ê³µê°„ì—ì„œì˜ ê³ ê° ë¶„í¬',
        hover_data=['Age', 'Annual Income (k$)', 'Spending Score (1-100)'],
        labels={
            'PC1': f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% ì„¤ëª…)',
            'PC2': f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% ì„¤ëª…)'
        }
    )
    fig.update_traces(marker=dict(size=8, opacity=0.7))
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)
    
    # ì›ë˜ ë³€ìˆ˜ë“¤ì˜ ë²¡í„° í‘œì‹œ (ì„ íƒì )
    show_vectors = st.checkbox("ì›ë˜ ë³€ìˆ˜ë“¤ì˜ ë°©í–¥ ë²¡í„° í‘œì‹œ", value=False)
    
    if show_vectors:
        # Biplot ìƒì„±
        fig_biplot = go.Figure()
        
        # ë°ì´í„° í¬ì¸íŠ¸
        fig_biplot.add_trace(go.Scatter(
            x=data_pca['PC1'],
            y=data_pca['PC2'],
            mode='markers',
            marker=dict(size=6, opacity=0.6),
            name='ê³ ê° ë°ì´í„°',
            hovertemplate='PC1: %{x:.2f}<br>PC2: %{y:.2f}<extra></extra>'
        ))
        
        # ë³€ìˆ˜ ë²¡í„° ì¶”ê°€
        scale_factor = 3  # ë²¡í„° í¬ê¸° ì¡°ì •
        for i, feature in enumerate(feature_names):
            fig_biplot.add_trace(go.Scatter(
                x=[0, pca_2d.components_[0, i] * scale_factor],
                y=[0, pca_2d.components_[1, i] * scale_factor],
                mode='lines+markers',
                line=dict(color='red', width=2),
                marker=dict(size=8),
                name=f'{feature} ë²¡í„°',
                showlegend=True
            ))
            
            # ë³€ìˆ˜ëª… ë¼ë²¨ ì¶”ê°€
            fig_biplot.add_annotation(
                x=pca_2d.components_[0, i] * scale_factor * 1.1,
                y=pca_2d.components_[1, i] * scale_factor * 1.1,
                text=feature,
                showarrow=False,
                font=dict(size=12, color='red')
            )
        
        fig_biplot.update_layout(
            title='PCA Biplot: ê³ ê° ë¶„í¬ì™€ ë³€ìˆ˜ ë°©í–¥',
            xaxis_title=f'PC1 ({pca_2d.explained_variance_ratio_[0]*100:.1f}% ì„¤ëª…)',
            yaxis_title=f'PC2 ({pca_2d.explained_variance_ratio_[1]*100:.1f}% ì„¤ëª…)',
            height=600
        )
        
        st.plotly_chart(fig_biplot, use_container_width=True)
        
        st.info("""
        **Biplot í•´ì„ ê°€ì´ë“œ:**
        - ë¹¨ê°„ í™”ì‚´í‘œëŠ” ì›ë˜ ë³€ìˆ˜ë“¤ì´ ì£¼ì„±ë¶„ ê³µê°„ì—ì„œ í–¥í•˜ëŠ” ë°©í–¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
        - í™”ì‚´í‘œê°€ ê¸¸ìˆ˜ë¡ í•´ë‹¹ ë³€ìˆ˜ê°€ ì£¼ì„±ë¶„ì— ë” ë§ì´ ê¸°ì—¬í•©ë‹ˆë‹¤
        - í™”ì‚´í‘œë“¤ ì‚¬ì´ì˜ ê°ë„ê°€ ì‘ì„ìˆ˜ë¡ ë³€ìˆ˜ë“¤ì´ ë¹„ìŠ·í•œ íŒ¨í„´ì„ ê°€ì§‘ë‹ˆë‹¤
        - ë°ì´í„° í¬ì¸íŠ¸ê°€ í™”ì‚´í‘œ ë°©í–¥ì— ìˆì„ìˆ˜ë¡ í•´ë‹¹ ë³€ìˆ˜ ê°’ì´ ë†’ìŠµë‹ˆë‹¤
        """)
    
    # í´ëŸ¬ìŠ¤í„°ë§ê³¼ PCA ë¹„êµ (ì„ íƒì )
    st.subheader("ğŸ”„ PCAì™€ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¹„êµ")
    st.write("PCA ê³µê°„ì—ì„œ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•˜ë©´ ì–´ë–¤ ê²°ê³¼ê°€ ë‚˜ì˜¬ê¹Œìš”?")
    
    if st.button("PCA ê³µê°„ì—ì„œ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰"):
        # Session Stateì—ì„œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°
        n_clusters = st.session_state.get('selected_clusters', 5)
        
        # PCA ê³µê°„ì—ì„œ í´ëŸ¬ìŠ¤í„°ë§
        kmeans_pca = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters_pca = kmeans_pca.fit_predict(pca_2d_result)
        
        # ì›ë˜ ê³µê°„ì—ì„œ í´ëŸ¬ìŠ¤í„°ë§
        kmeans_original = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        clusters_original = kmeans_original.fit_predict(scaled_features)
        
        # ê²°ê³¼ ë¹„êµ
        data_comparison = data_pca.copy()
        data_comparison['PCA_Cluster'] = clusters_pca
        data_comparison['Original_Cluster'] = clusters_original
        
        col1, col2 = st.columns(2)
        
        with col1:
            # PCA ê³µê°„ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼
            fig1 = px.scatter(
                data_comparison,
                x='PC1',
                y='PC2',
                color='PCA_Cluster',
                title='PCA ê³µê°„ì—ì„œì˜ í´ëŸ¬ìŠ¤í„°ë§',
                color_discrete_sequence=px.colors.qualitative.Set1
            )
            st.plotly_chart(fig1, use_container_width=True)
            
        with col2:
            # ì›ë˜ ê³µê°„ í´ëŸ¬ìŠ¤í„°ë§ì„ PCA ê³µê°„ì— íˆ¬ì˜
            fig2 = px.scatter(
                data_comparison,
                x='PC1',
                y='PC2',
                color='Original_Cluster',
                title='ì›ë˜ ê³µê°„ í´ëŸ¬ìŠ¤í„°ë§ì˜ PCA íˆ¬ì˜',
                color_discrete_sequence=px.colors.qualitative.Set2
            )
            st.plotly_chart(fig2, use_container_width=True)
        
        # í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ë¹„êµ ë¶„ì„
        from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score
        
        ari_score = adjusted_rand_score(clusters_original, clusters_pca)
        nmi_score = normalized_mutual_info_score(clusters_original, clusters_pca)
        
        st.write("**í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìœ ì‚¬ë„ ë¶„ì„:**")
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                label="Adjusted Rand Index (ARI)",
                value=f"{ari_score:.3f}",
                help="1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ê°€ ìœ ì‚¬í•¨"
            )
        
        with col2:
            st.metric(
                label="Normalized Mutual Information (NMI)",
                value=f"{nmi_score:.3f}",
                help="1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ í´ëŸ¬ìŠ¤í„°ë§ì´ ê°™ì€ ì •ë³´ë¥¼ ê³µìœ í•¨"
            )
        
        if ari_score > 0.7:
            st.success("ğŸ‰ PCA ê³µê°„ê³¼ ì›ë˜ ê³µê°„ì˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ê°€ ë§¤ìš° ìœ ì‚¬í•©ë‹ˆë‹¤!")
        elif ari_score > 0.5:
            st.info("ğŸ“Š PCA ê³µê°„ê³¼ ì›ë˜ ê³µê°„ì˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ê°€ ì–´ëŠ ì •ë„ ìœ ì‚¬í•©ë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ PCA ê³µê°„ê³¼ ì›ë˜ ê³µê°„ì˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ê°€ ë‹¤ë¦…ë‹ˆë‹¤. ì°¨ì› ì¶•ì†Œë¡œ ì¸í•œ ì •ë³´ ì†ì‹¤ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ë§ˆë¬´ë¦¬ ì¸ì‚¬ì´íŠ¸
    with st.expander("ğŸ’¡ ì£¼ì„±ë¶„ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ ë° í™œìš© ë°©ì•ˆ"):
        st.markdown(f"""
        ### ğŸ¯ ì´ë²ˆ ë¶„ì„ì—ì„œ ì–»ì€ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:
        
        **ì°¨ì› ì¶•ì†Œ íš¨ê³¼:**
        - 3ì°¨ì› ê³ ê° ë°ì´í„°ë¥¼ 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ë©´ì„œ {cumulative_variance[1]*100:.1f}%ì˜ ì •ë³´ë¥¼ ë³´ì¡´í–ˆìŠµë‹ˆë‹¤
        - ì²« ë²ˆì§¸ ì£¼ì„±ë¶„ì´ {explained_variance_ratio[0]*100:.1f}%ì˜ ê³ ê° íŠ¹ì„± ë³€ë™ì„ ì„¤ëª…í•©ë‹ˆë‹¤
        
        **ê³ ê° ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ íŒ¨í„´:**
        - ê³ ê°ë“¤ì˜ ì£¼ìš” êµ¬ë¶„ ì¶•ì€ '{max_pc1_var}'ì™€ '{max_pc2_var}'ì…ë‹ˆë‹¤
        - ì´ëŠ” ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ ì‹œ í•µì‹¬ ê³ ë ¤ì‚¬í•­ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        
        ### ğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš© ë°©ì•ˆ:
        
        **ë§ˆì¼€íŒ… ì„¸ë¶„í™”:**
        - PCA ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³ ê°ì„ 2ì°¨ì› ë§¤íŠ¸ë¦­ìŠ¤ë¡œ êµ¬ë¶„ ê°€ëŠ¥
        - ê° ì‚¬ë¶„ë©´ë³„ë¡œ ì°¨ë³„í™”ëœ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½
        
        **ë°ì´í„° ì••ì¶• ë° íš¨ìœ¨ì„±:**
        - ê³ ê° í”„ë¡œí•„ì„ 2-3ê°œ ì£¼ì„±ë¶„ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ì €ì¥ ê³µê°„ ì ˆì•½
        - ì‹¤ì‹œê°„ ë¶„ì„ ì‹œ ì²˜ë¦¬ ì†ë„ í–¥ìƒ
        
        **ì‹ ê·œ ê³ ê° ë¶„ë¥˜:**
        - ìƒˆë¡œìš´ ê³ ê°ì˜ ì£¼ì„±ë¶„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì¦‰ì‹œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜ ê°€ëŠ¥
        - ìë™í™”ëœ ê³ ê° ì˜¨ë³´ë”© í”„ë¡œì„¸ìŠ¤ êµ¬ì¶•
        
        ### ğŸ“ˆ ì¶”ê°€ ë¶„ì„ ì œì•ˆ:
        
        **ì‹œê³„ì—´ ë¶„ì„:**
        - ì‹œê°„ì— ë”°ë¥¸ ê³ ê°ì˜ ì£¼ì„±ë¶„ ë³€í™” ì¶”ì 
        - ê³ ê° ìƒì• ì£¼ê¸° ëª¨ë¸ë§
        
        **ì˜ˆì¸¡ ëª¨ë¸ë§:**
        - ì£¼ì„±ë¶„ì„ íŠ¹ì„±ìœ¼ë¡œ í™œìš©í•œ êµ¬ë§¤ ì˜ˆì¸¡ ëª¨ë¸
        - ì´íƒˆ ê³ ê° ì¡°ê¸° ê°ì§€ ì‹œìŠ¤í…œ
        """)
    
    st.success("âœ… ì£¼ì„±ë¶„ ë¶„ì„ì„ í†µí•´ ê³ ê° ë°ì´í„°ì˜ í•µì‹¬ êµ¬ì¡°ë¥¼ íŒŒì•…í–ˆìŠµë‹ˆë‹¤!")

elif menu == "ê³ ê° ì˜ˆì¸¡":
    st.header("ğŸ”® ìƒˆë¡œìš´ ê³ ê° í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡")
    
    # Session Stateì—ì„œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°
    if 'selected_clusters' not in st.session_state:
        st.session_state.selected_clusters = 5  # ê¸°ë³¸ê°’
    
    selected_k = st.session_state.selected_clusters
    
    # í˜„ì¬ ì„¤ì • í‘œì‹œ
    st.info(f"ğŸ¯ í˜„ì¬ ì„ íƒëœ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜: **{selected_k}ê°œ** (í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ í˜ì´ì§€ì—ì„œ ì„¤ì •ë¨)")
    
    # ì„ íƒëœ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    clusters, kmeans, scaler, silhouette_avg = perform_clustering(data, selected_k)
    
    # ë™ì  í´ëŸ¬ìŠ¤í„° ë¶„ì„
    data_with_clusters = data.copy()
    data_with_clusters['Cluster'] = clusters
    cluster_profiles = analyze_cluster_characteristics(data_with_clusters, selected_k)
    
    st.subheader("ê³ ê° ì •ë³´ ì…ë ¥")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        input_age = st.number_input("ì—°ë ¹", min_value=18, max_value=80, value=30)
    
    with col2:
        input_income = st.number_input("ì—°ê°„ ì†Œë“ (ì²œ ë‹¬ëŸ¬)", min_value=15, max_value=150, value=50)
    
    with col3:
        input_spending = st.number_input("ì§€ì¶œ ì ìˆ˜ (1-100)", min_value=1, max_value=100, value=50)
    
    if st.button("í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡í•˜ê¸°", type="primary"):
        # ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬
        input_data = np.array([[input_age, input_income, input_spending]])
        input_scaled = scaler.transform(input_data)
        
        # ì˜ˆì¸¡
        predicted_cluster = kmeans.predict(input_scaled)[0]
        
        # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì ê¹Œì§€ì˜ ê±°ë¦¬
        distances = kmeans.transform(input_scaled)[0]
        confidence = 1 / (1 + distances[predicted_cluster])
        
        # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ë™ì  ë¼ë²¨ ì°¾ê¸°
        predicted_profile = next((p for p in cluster_profiles if p['cluster_id'] == predicted_cluster), None)
        cluster_label = predicted_profile['label'] if predicted_profile else f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}"
        
        # ê²°ê³¼ í‘œì‹œ
        st.success(f"ğŸ¯ ì˜ˆì¸¡ëœ í´ëŸ¬ìŠ¤í„°: **{predicted_cluster}ë²ˆ ({cluster_label})**")
        st.info(f"ğŸ“Š ì˜ˆì¸¡ ì‹ ë¢°ë„: **{confidence:.2%}**")
        
        # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ íŠ¹ì„± í‘œì‹œ
        cluster_info = data_with_clusters[data_with_clusters['Cluster'] == predicted_cluster]
        
        st.subheader(f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}ì˜ íŠ¹ì„± ({selected_k}ê°œ í´ëŸ¬ìŠ¤í„° ê¸°ì¤€)")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            avg_age = cluster_info['Age'].mean()
            st.metric("í‰ê·  ì—°ë ¹", f"{avg_age:.1f}ì„¸")
        
        with col2:
            avg_income = cluster_info['Annual Income (k$)'].mean()
            st.metric("í‰ê·  ì†Œë“", f"${avg_income:.1f}k")
        
        with col3:
            avg_spending = cluster_info['Spending Score (1-100)'].mean()
            st.metric("í‰ê·  ì§€ì¶œì ìˆ˜", f"{avg_spending:.1f}")
        
        # ì˜ˆì¸¡ëœ í´ëŸ¬ìŠ¤í„°ì˜ ìƒì„¸ íŠ¹ì„±
        if predicted_profile:
            st.subheader("ì˜ˆì¸¡ëœ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ íŠ¹ì„±")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ê³ ê° ìœ í˜•**: {predicted_profile['customer_type']}")
                st.write(f"**ì†Œë“ ìˆ˜ì¤€**: {predicted_profile['income_level']}")
                st.write(f"**ì§€ì¶œ ì„±í–¥**: {predicted_profile['spending_level']}")
                st.write(f"**ì—°ë ¹ ê·¸ë£¹**: {predicted_profile['age_group']}")
            
            with col2:
                st.write(f"**í´ëŸ¬ìŠ¤í„° í¬ê¸°**: {predicted_profile['size']}ëª…")
                st.write(f"**ì†Œë“ í‘œì¤€í¸ì°¨**: ${predicted_profile['std_income']:.1f}k")
                st.write(f"**ì§€ì¶œ í‘œì¤€í¸ì°¨**: {predicted_profile['std_spending']:.1f}")
        
        # ìœ ì‚¬í•œ ê³ ê°ë“¤ í‘œì‹œ
        st.subheader("ìœ ì‚¬í•œ ê³ ê° í”„ë¡œí•„")
        similar_customers = cluster_info.sample(min(5, len(cluster_info)))
        st.dataframe(similar_customers[['Age', 'Annual Income (k$)', 'Spending Score (1-100)', 'Gender']])

elif menu == "ë§ˆì¼€íŒ… ì „ëµ":
    st.header("ğŸ“ˆ í´ëŸ¬ìŠ¤í„°ë³„ ë§ˆì¼€íŒ… ì „ëµ")
    
    # Session Stateì—ì„œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°
    if 'selected_clusters' not in st.session_state:
        st.session_state.selected_clusters = 5  # ê¸°ë³¸ê°’
    
    selected_k = st.session_state.selected_clusters
    
    # í˜„ì¬ ì„¤ì • í‘œì‹œ
    st.info(f"ğŸ¯ í˜„ì¬ ì„ íƒëœ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜: **{selected_k}ê°œ** (í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ í˜ì´ì§€ì—ì„œ ì„¤ì •ë¨)")
    
    # ì„ íƒëœ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    clusters, kmeans, scaler, silhouette_avg = perform_clustering(data, selected_k)
    data_with_clusters = data.copy()
    data_with_clusters['Cluster'] = clusters
    
    # ë™ì  í´ëŸ¬ìŠ¤í„° ë¶„ì„
    cluster_profiles_list = analyze_cluster_characteristics(data_with_clusters, selected_k)
    
    # í´ëŸ¬ìŠ¤í„°ë³„ íŠ¹ì„± ë¶„ì„ (ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
    cluster_profiles = {}
    for profile in cluster_profiles_list:
        cluster_id = profile['cluster_id']
        cluster_data = data_with_clusters[data_with_clusters['Cluster'] == cluster_id]
        cluster_profiles[cluster_id] = {
            'size': profile['size'],
            'avg_age': profile['avg_age'],
            'avg_income': profile['avg_income'],
            'avg_spending': profile['avg_spending'],
            'gender_ratio': cluster_data['Gender'].value_counts(normalize=True).to_dict()
        }
    
    st.subheader("í´ëŸ¬ìŠ¤í„°ë³„ ë§ˆì¼€íŒ… ì „ëµ ê°œìš”")
    
    for profile in cluster_profiles_list:
        cluster_id = profile['cluster_id']
        strategy = get_dynamic_marketing_strategy(cluster_id, cluster_profiles[cluster_id], cluster_profiles)
        
        with st.expander(f"ğŸ¯ í´ëŸ¬ìŠ¤í„° {cluster_id}: {profile['label']} ({profile['size']}ëª…)"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ê³ ê° í”„ë¡œí•„ ë¶„ì„:**")
                st.write(f"- í‰ê·  ì—°ë ¹: {profile['avg_age']:.1f}ì„¸ ({profile['age_group']})")
                st.write(f"- í‰ê·  ì†Œë“: ${profile['avg_income']:.1f}k ({profile['income_level']})")
                st.write(f"- í‰ê·  ì§€ì¶œì ìˆ˜: {profile['avg_spending']:.1f} ({profile['spending_level']})")
                st.write(f"- ê³ ê° ìˆ˜: {profile['size']}ëª…")
                st.write(f"- ê³ ê° ìœ í˜•: {profile['customer_type']}")
                
                st.write("**ìƒëŒ€ì  ìœ„ì¹˜:**")
                st.write(f"- ì†Œë“ ìˆœìœ„: ìƒìœ„ {100-float(strategy['percentiles']['income'][:-1]):.0f}%")
                st.write(f"- ì§€ì¶œ ìˆœìœ„: ìƒìœ„ {100-float(strategy['percentiles']['spending'][:-1]):.0f}%")
            
            with col2:
                st.write("**ë§ì¶¤ ë§ˆì¼€íŒ… ì „ëµ:**")
                st.write(f"- ì„¸ê·¸ë¨¼íŠ¸: {strategy['segment']}")
                st.write(f"- ìš°ì„ ìˆœìœ„: {strategy['priority']}")
                st.write("**ì „ëµ ì„¸ë¶€ì‚¬í•­:**")
                
                # ì „ëµì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
                strategy_items = strategy['strategy'].split('; ')
                for i, item in enumerate(strategy_items, 1):
                    st.write(f"  {i}. {item}")
                    
                # íŠ¹ë³„ ê¶Œì¥ì‚¬í•­
                if profile['customer_type'] == "í”„ë¦¬ë¯¸ì—„":
                    st.success("ğŸ’ **ìµœìš°ì„  ê´€ë¦¬ ëŒ€ìƒ**: ë§¤ì¶œ ê¸°ì—¬ë„ê°€ ê°€ì¥ ë†’ì€ í•µì‹¬ ê³ ê°ì¸µ")
                elif profile['customer_type'] == "ì ê·¹ì†Œë¹„":
                    st.warning("âš ï¸ **ì£¼ì˜ í•„ìš”**: ê³¼ì†Œë¹„ ê²½í–¥, ì‹ ìš© ê´€ë¦¬ ì§€ì› í•„ìš”")
                elif profile['customer_type'] == "ë³´ìˆ˜ì ":
                    st.info("ğŸ¯ **ì ì¬ë ¥ ë†’ìŒ**: ì¶”ê°€ ì†Œë¹„ ìœ ë„ ê°€ëŠ¥í•œ ë³´ìˆ˜ì  ê³ ì†Œë“ì¸µ")
    
    # ì „ì²´ ìš”ì•½ ëŒ€ì‹œë³´ë“œ
    st.subheader("ğŸ“Š ë§ˆì¼€íŒ… ëŒ€ì‹œë³´ë“œ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_customers = len(data)
        st.metric("ì´ ê³ ê° ìˆ˜", f"{total_customers:,}ëª…")
    
    with col2:
        avg_income = data['Annual Income (k$)'].mean()
        st.metric("í‰ê·  ì†Œë“", f"${avg_income:.1f}k")
    
    with col3:
        avg_spending = data['Spending Score (1-100)'].mean()
        st.metric("í‰ê·  ì§€ì¶œì ìˆ˜", f"{avg_spending:.1f}")
    
    with col4:
        high_value_customers = len(data_with_clusters[
            (data_with_clusters['Annual Income (k$)'] > 70) & 
            (data_with_clusters['Spending Score (1-100)'] > 70)
        ])
        st.metric("í”„ë¦¬ë¯¸ì—„ ê³ ê°", f"{high_value_customers}ëª…")

# í‘¸í„°
st.markdown("---")
st.markdown("""
**ê°œë°œ ì •ë³´:** ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ K-means í´ëŸ¬ìŠ¤í„°ë§ì„ í™œìš©í•œ ê³ ê° ì„¸ë¶„í™” ë¶„ì„ ë„êµ¬ì…ë‹ˆë‹¤.  
**ë°ì´í„°:** Mall Customer Segmentation Dataset  
**ê¸°ìˆ  ìŠ¤íƒ:** Python, Streamlit, Scikit-learn, Plotly
""")