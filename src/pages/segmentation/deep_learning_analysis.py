"""
ë”¥ëŸ¬ë‹ ë¶„ì„ í˜ì´ì§€

ê¸°ì¡´ customer_segmentation_app.pyì˜ "ë”¥ëŸ¬ë‹ ë¶„ì„" ë©”ë‰´ ë‚´ìš©ì„ ëª¨ë“ˆí™”
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import adjusted_rand_score
from core.segmentation.data_processing import CustomerDataProcessor
from core.segmentation.clustering import ClusterAnalyzer
from core.segmentation.models import DeepLearningModels, TENSORFLOW_AVAILABLE

# TensorFlow ê´€ë ¨ import (ì´ë¯¸ deep_learning_modelsì—ì„œ ì²˜ë¦¬ë¨)
if TENSORFLOW_AVAILABLE:
    from tensorflow import keras


def show_deep_learning_analysis_page():
    """ë”¥ëŸ¬ë‹ ë¶„ì„ í˜ì´ì§€ë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜"""
    st.header("ğŸ§  ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ê³ ê° ë¶„ì„")
    
    # ë”¥ëŸ¬ë‹ ë©”ë‰´ì— ì§„ì…í•  ë•Œë§ˆë‹¤ Keras ì„¸ì…˜ì„ ì´ˆê¸°í™”
    if TENSORFLOW_AVAILABLE:
        keras.backend.clear_session()

    # TensorFlow ì„¤ì¹˜ í™•ì¸
    if not TENSORFLOW_AVAILABLE:
        st.error("""
        ğŸš¨ **TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!**
        
        ë”¥ëŸ¬ë‹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ TensorFlowë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
        í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”:
        
        ```bash
        pip install tensorflow
        ```
        
        ì„¤ì¹˜ í›„ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.
        """)
        st.stop()

    # ë”¥ëŸ¬ë‹ ì´ë¡  ì„¤ëª… ì„¹ì…˜
    with st.expander("ğŸ¤” ì™œ ê³ ê° ë¶„ì„ì— ë”¥ëŸ¬ë‹ì„ ì‚¬ìš©í• ê¹Œìš”?", expanded=True):
        st.markdown("""
        ### ğŸ¯ ë¹„ì§€ë„ í•™ìŠµì—ì„œ ì§€ë„ í•™ìŠµìœ¼ë¡œì˜ ì „í™˜
        
        ì§€ê¸ˆê¹Œì§€ ìš°ë¦¬ëŠ” **ë¹„ì§€ë„ í•™ìŠµ**ì¸ í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•´ì„œ ê³ ê°ì„ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.
        ì´ì œ ì´ í´ëŸ¬ìŠ¤í„° ê²°ê³¼ë¥¼ **"ì •ë‹µ ë¼ë²¨"**ë¡œ í™œìš©í•˜ì—¬ **ì§€ë„ í•™ìŠµ** ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        **ì™œ ì´ëŸ° ì „í™˜ì´ í•„ìš”í• ê¹Œìš”?**
        - í´ëŸ¬ìŠ¤í„°ë§: ê¸°ì¡´ ê³ ê°ì„ ë¶„ì„í•˜ì—¬ íŒ¨í„´ ë°œê²¬
        - ë”¥ëŸ¬ë‹ ë¶„ë¥˜: ìƒˆë¡œìš´ ê³ ê°ì´ ì–´ë–¤ ê·¸ë£¹ì— ì†í• ì§€ **ì¦‰ì‹œ ì˜ˆì¸¡**
        
        **ì‹¤ë¬´ì  ê°€ì¹˜:**
        ë§ˆì¹˜ ìˆ™ë ¨ëœ ì˜ì—…ì‚¬ì›ì´ ê³ ê°ì„ ë³´ìë§ˆì ì–´ë–¤ ìœ í˜•ì¸ì§€ íŒë‹¨í•˜ëŠ” ê²ƒì²˜ëŸ¼,
        ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ ìƒˆë¡œìš´ ê³ ê°ì˜ íŠ¹ì„±ì„ ì…ë ¥ë°›ì•„ ì¦‰ì‹œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        ### ğŸ§  ë”¥ëŸ¬ë‹ì´ ì „í†µì  ë°©ë²•ë³´ë‹¤ ë‚˜ì€ ì 
        
        **ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ:**
        - ì „í†µì  ë°©ë²•: ë³€ìˆ˜ë“¤ ê°„ì˜ **ì„ í˜•ì  ê´€ê³„**ë§Œ í¬ì°©
        - ë”¥ëŸ¬ë‹: ë³µì¡í•˜ê³  **ë¹„ì„ í˜•ì ì¸ ê´€ê³„**ê¹Œì§€ í•™ìŠµ ê°€ëŠ¥
        
        **ìë™ íŠ¹ì„± ì¶”ì¶œ:**
        - ì „í†µì  ë°©ë²•: ì‚¬ëŒì´ ì§ì ‘ ì¤‘ìš”í•œ íŠ¹ì„±ì„ ì„ íƒ
        - ë”¥ëŸ¬ë‹: ë°ì´í„°ì—ì„œ **ìˆ¨ê²¨ì§„ íŒ¨í„´ì„ ìë™ìœ¼ë¡œ ë°œê²¬**
        
        ### ğŸ”¬ ë”¥ëŸ¬ë‹ ì ‘ê·¼ë²• ì¢…ë¥˜
        
        **1. ë¶„ë¥˜ ëª¨ë¸ (Classification)**
        - í´ëŸ¬ìŠ¤í„° ê²°ê³¼ë¥¼ ì •ë‹µìœ¼ë¡œ ì‚¬ìš©
        - ìƒˆë¡œìš´ ê³ ê° â†’ ì–´ë–¤ ì„¸ê·¸ë¨¼íŠ¸ì— ì†í• ì§€ ì˜ˆì¸¡
        - ì˜¤ëŠ˜ êµ¬í˜„í•  ì£¼ìš” ë°©ë²•
        
        **2. ì˜¤í† ì¸ì½”ë” (Autoencoder)**
        - ì°¨ì› ì¶•ì†Œì˜ ë¹„ì„ í˜• ë²„ì „ (PCAì˜ ì—…ê·¸ë ˆì´ë“œ)
        - ì…ë ¥ â†’ ì••ì¶• â†’ ë³µì› ê³¼ì •ì„ í†µí•´ í•µì‹¬ íŠ¹ì„± í•™ìŠµ
        - ë” ë³µì¡í•œ ë°ì´í„° êµ¬ì¡° í¬ì°© ê°€ëŠ¥
        """)

    # ë°ì´í„° ì¤€ë¹„ ë° í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
    st.subheader("ğŸ“Š 1ë‹¨ê³„: ê¸°ë³¸ ë°ì´í„° ì¤€ë¹„")

    # ë°ì´í„° ë¡œë“œ
    data_processor = CustomerDataProcessor()
    data = data_processor.load_data()
    
    # Session Stateì—ì„œ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ ê°€ì ¸ì˜¤ê¸°
    n_clusters = st.session_state.get("selected_clusters", 5)
    st.info(f"í˜„ì¬ ì„¤ì •ëœ í´ëŸ¬ìŠ¤í„° ê°œìˆ˜: {n_clusters}ê°œ")

    # íŠ¹ì„± ì¤€ë¹„ ë° ì •ê·œí™”
    features = data[["Age", "Annual Income (k$)", "Spending Score (1-100)"]]
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)

    # í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰í•˜ì—¬ ë¼ë²¨ ìƒì„±
    cluster_analyzer = ClusterAnalyzer()
    clusters, kmeans, _, silhouette_avg = cluster_analyzer.perform_clustering(data, n_clusters)

    st.success(f"âœ… {len(data)}ëª…ì˜ ê³ ê°ì„ {n_clusters}ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ë¶„ë¥˜ ì™„ë£Œ!")

    # í´ëŸ¬ìŠ¤í„° ë¶„í¬ í™•ì¸
    col1, col2 = st.columns(2)
    with col1:
        cluster_counts = pd.Series(clusters).value_counts().sort_index()
        st.write("**í´ëŸ¬ìŠ¤í„°ë³„ ê³ ê° ìˆ˜:**")
        for i, count in cluster_counts.items():
            st.write(f"- í´ëŸ¬ìŠ¤í„° {i}: {count}ëª…")

    with col2:
        fig = px.pie(
            values=cluster_counts.values,
            names=cluster_counts.index,
            title="í´ëŸ¬ìŠ¤í„° ë¶„í¬",
        )
        st.plotly_chart(fig, use_container_width=True)

    # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì˜µì…˜ ì„ íƒ
    st.subheader("ğŸ§  2ë‹¨ê³„: ë”¥ëŸ¬ë‹ ëª¨ë¸ ì„ íƒ")

    model_type = st.selectbox(
        "ì–´ë–¤ ë”¥ëŸ¬ë‹ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        ["ë¶„ë¥˜ ëª¨ë¸ (Classification)", "ì˜¤í† ì¸ì½”ë” (Autoencoder)", "ë‘ ëª¨ë¸ ë¹„êµ"],
    )

    # ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    dl_models = DeepLearningModels()

    if model_type in ["ë¶„ë¥˜ ëª¨ë¸ (Classification)", "ë‘ ëª¨ë¸ ë¹„êµ"]:
        st.subheader("ğŸ¯ ë¶„ë¥˜ ëª¨ë¸ êµ¬ì¶•")

        with st.expander("ë¶„ë¥˜ ëª¨ë¸ì´ í•˜ëŠ” ì¼", expanded=False):
            st.markdown("""
            **ë¶„ë¥˜ ëª¨ë¸ì˜ ë™ì‘ ì›ë¦¬:**
            
            1. **ì…ë ¥**: ìƒˆë¡œìš´ ê³ ê°ì˜ (ë‚˜ì´, ì†Œë“, ì§€ì¶œì ìˆ˜)
            2. **ì²˜ë¦¬**: ì—¬ëŸ¬ ì¸µì˜ ì‹ ê²½ë§ì„ í†µí•´ íŒ¨í„´ ë¶„ì„
            3. **ì¶œë ¥**: ê° í´ëŸ¬ìŠ¤í„°ì— ì†í•  í™•ë¥ 
            
            **ì˜ˆì‹œ:**
            - ì…ë ¥: (35ì„¸, 70k$, 80ì )
            - ì¶œë ¥: [í´ëŸ¬ìŠ¤í„°0: 5%, í´ëŸ¬ìŠ¤í„°1: 85%, í´ëŸ¬ìŠ¤í„°2: 10%, ...]
            - ê²°ë¡ : í´ëŸ¬ìŠ¤í„°1ì— ì†í•  ê°€ëŠ¥ì„±ì´ ê°€ì¥ ë†’ìŒ
            """)

        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            scaled_features,
            clusters,
            test_size=0.2,
            random_state=42,
            stratify=clusters,
        )

        st.write(f"**ë°ì´í„° ë¶„í•  ì™„ë£Œ:** í›ˆë ¨ìš© {len(X_train)}ëª…, í…ŒìŠ¤íŠ¸ìš© {len(X_test)}ëª…")

        # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„¤ì •
        st.write("**ğŸ—ï¸ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ ì„¤ê³„:**")

        col1, col2 = st.columns(2)
        with col1:
            hidden_units = st.slider("ì€ë‹‰ì¸µ ë‰´ëŸ° ìˆ˜", min_value=8, max_value=128, value=64, step=8)
            dropout_rate = st.slider("ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨", min_value=0.0, max_value=0.5, value=0.2, step=0.1)

        with col2:
            learning_rate = st.selectbox("í•™ìŠµë¥ ", [0.001, 0.01, 0.1], index=0)
            epochs = st.slider("í•™ìŠµ ì—í¬í¬", min_value=20, max_value=200, value=100, step=20)

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        _initialize_model_session_state()

        # ëª¨ë¸ í›ˆë ¨ ë²„íŠ¼ê³¼ ìƒíƒœ í‘œì‹œ
        if not st.session_state.model_trained:
            train_button_clicked = st.button("ğŸš€ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘", type="primary")
        else:
            st.success("âœ… ëª¨ë¸ì´ ì´ë¯¸ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
            if st.button("ğŸ”„ ëª¨ë¸ ë‹¤ì‹œ í›ˆë ¨í•˜ê¸°"):
                _reset_model_session_state()
                st.rerun()
            train_button_clicked = False

        # ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
        if train_button_clicked:
            _train_classification_model(
                dl_models, X_train, y_train, X_test, y_test, 
                n_clusters, hidden_units, dropout_rate, learning_rate, epochs
            )

        # ëª¨ë¸ì´ í›ˆë ¨ëœ ê²½ìš°ì—ë§Œ ê²°ê³¼ í‘œì‹œ
        if st.session_state.model_trained and st.session_state.dl_model is not None:
            _display_classification_results(n_clusters)

    if model_type in ["ì˜¤í† ì¸ì½”ë” (Autoencoder)", "ë‘ ëª¨ë¸ ë¹„êµ"]:
        st.subheader("ğŸ”„ ì˜¤í† ì¸ì½”ë”ë¥¼ í™œìš©í•œ ì°¨ì› ì¶•ì†Œ")

        with st.expander("ì˜¤í† ì¸ì½”ë”ê°€ í•˜ëŠ” ì¼", expanded=False):
            st.markdown("""
            **ì˜¤í† ì¸ì½”ë”ì˜ ë™ì‘ ì›ë¦¬:**
            
            1. **ì¸ì½”ë”**: ì…ë ¥ ë°ì´í„°ë¥¼ ë” ì‘ì€ ì°¨ì›ìœ¼ë¡œ ì••ì¶•
            2. **ì ì¬ ê³µê°„**: ì••ì¶•ëœ í•µì‹¬ ì •ë³´ë§Œ ë³´ì¡´
            3. **ë””ì½”ë”**: ì••ì¶•ëœ ì •ë³´ë¡œë¶€í„° ì›ë³¸ ì¬êµ¬ì„±
            
            **PCA vs ì˜¤í† ì¸ì½”ë”:**
            - PCA: ì„ í˜• ë³€í™˜ë§Œ ê°€ëŠ¥
            - ì˜¤í† ì¸ì½”ë”: ë¹„ì„ í˜• ë³€í™˜ìœ¼ë¡œ ë” ë³µì¡í•œ íŒ¨í„´ í¬ì°©
            
            **í™œìš© ëª©ì :**
            - ë°ì´í„° ì••ì¶•
            - ë…¸ì´ì¦ˆ ì œê±°  
            - ì´ìƒì¹˜ íƒì§€
            - ë” ë‚˜ì€ ì‹œê°í™”
            """)

        # ì˜¤í† ì¸ì½”ë” ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        _initialize_autoencoder_session_state()

        # ì˜¤í† ì¸ì½”ë” ì„¤ì •
        encoding_dim = st.slider("ì••ì¶• ì°¨ì› ìˆ˜", min_value=2, max_value=10, value=2)
        st.session_state.encoding_dim = encoding_dim

        # ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ë²„íŠ¼ê³¼ ìƒíƒœ ê´€ë¦¬
        if not st.session_state.autoencoder_trained:
            autoencoder_button_clicked = st.button("ğŸ”„ ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì‹œì‘")
        else:
            st.success("âœ… ì˜¤í† ì¸ì½”ë”ê°€ ì´ë¯¸ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
            if st.button("ğŸ”„ ì˜¤í† ì¸ì½”ë” ë‹¤ì‹œ í›ˆë ¨í•˜ê¸°"):
                _reset_autoencoder_session_state()
                st.rerun()
            autoencoder_button_clicked = False

        # ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì‹¤í–‰
        if autoencoder_button_clicked:
            _train_autoencoder_model(dl_models, scaled_features, encoding_dim)

        # ì˜¤í† ì¸ì½”ë”ê°€ í›ˆë ¨ëœ ê²½ìš°ì—ë§Œ ê²°ê³¼ í‘œì‹œ
        if st.session_state.autoencoder_trained:
            _display_autoencoder_results(encoding_dim)

    # "ë‘ ëª¨ë¸ ë¹„êµ" ì „ìš© ì„¹ì…˜
    if model_type == "ë‘ ëª¨ë¸ ë¹„êµ":
        _show_model_comparison()

    # ë”¥ëŸ¬ë‹ í™œìš© ê°€ì´ë“œ
    with st.expander("ğŸ’¡ ë”¥ëŸ¬ë‹ ê²°ê³¼ í™œìš© ê°€ì´ë“œ"):
        st.markdown("""
        ### ğŸ¯ ì–¸ì œ ë”¥ëŸ¬ë‹ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œìš”?
        
        **ë”¥ëŸ¬ë‹ì´ ìœ ë¦¬í•œ ê²½ìš°:**
        - ëŒ€ëŸ‰ì˜ ê³ ê° ë°ì´í„° (ìˆ˜ì²œ ëª… ì´ìƒ)
        - ë³µì¡í•œ ê³ ê° í–‰ë™ íŒ¨í„´
        - ì‹¤ì‹œê°„ ê³ ê° ë¶„ë¥˜ê°€ í•„ìš”í•œ ê²½ìš°
        - ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„ê°€ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤
        
        **ì „í†µì  ë°©ë²•ì´ ë‚˜ì€ ê²½ìš°:**
        - ì†Œê·œëª¨ ë°ì´í„° (ìˆ˜ë°± ëª… ì´í•˜)
        - í•´ì„ ê°€ëŠ¥ì„±ì´ ì¤‘ìš”í•œ ê²½ìš°
        - ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì´ í•„ìš”í•œ ê²½ìš°
        - ì»´í“¨íŒ… ìì›ì´ ì œí•œì ì¸ í™˜ê²½
        
        ### ğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ í™œìš© ë°©ì•ˆ
        
        **ì‹¤ì‹œê°„ ê³ ê° ë¶„ë¥˜ ì‹œìŠ¤í…œ:**
        - ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ì—ì„œ ì¦‰ì‹œ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ íŒŒì•…
        - ë§ì¶¤í˜• ìƒí’ˆ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬ì¶•
        - ê°œì¸í™”ëœ ë§ˆì¼€íŒ… ë©”ì‹œì§€ ìë™ ìƒì„±
        
        **ê³ ê° ì—¬ì • ì˜ˆì¸¡:**
        - ê³ ê°ì˜ ë‹¤ìŒ í–‰ë™ íŒ¨í„´ ì˜ˆì¸¡
        - ì´íƒˆ ìœ„í—˜ ê³ ê° ì¡°ê¸° ê°ì§€
        - ìƒì•  ê°€ì¹˜ ì˜ˆì¸¡ ëª¨ë¸ë§
        """)

    st.success("ğŸ§  ë”¥ëŸ¬ë‹ì„ í†µí•œ ê³ ê° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


def _initialize_model_session_state():
    """ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ê³¼ ê´€ë ¨ëœ ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”"""
    session_keys = [
        'model_trained', 'dl_model', 'dl_scaler', 'dl_history',
        'dl_evaluation_results', 'dl_X_test', 'dl_y_test'
    ]
    default_values = [False, None, None, None, None, None, None]
    
    for key, default in zip(session_keys, default_values):
        if key not in st.session_state:
            st.session_state[key] = default


def _reset_model_session_state():
    """ë¶„ë¥˜ ëª¨ë¸ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    keys_to_reset = [
        'model_trained', 'dl_model', 'dl_scaler', 'dl_history',
        'dl_evaluation_results', 'dl_X_test', 'dl_y_test'
    ]
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]


def _initialize_autoencoder_session_state():
    """ì˜¤í† ì¸ì½”ë”ì™€ ê´€ë ¨ëœ ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”"""
    session_keys = [
        'autoencoder_trained', 'autoencoder_model', 'encoder_model',
        'encoded_data', 'reconstruction_error', 'pca_result_ae', 
        'pca_variance_ratio_ae', 'encoding_dim_value'
    ]
    default_values = [False, None, None, None, None, None, None, 2]
    
    for key, default in zip(session_keys, default_values):
        if key not in st.session_state:
            st.session_state[key] = default


def _reset_autoencoder_session_state():
    """ì˜¤í† ì¸ì½”ë” ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    keys_to_reset = [
        'autoencoder_trained', 'autoencoder_model', 'encoder_model',
        'encoded_data', 'reconstruction_error', 'pca_result_ae', 
        'pca_variance_ratio_ae'
    ]
    for key in keys_to_reset:
        if key in st.session_state:
            del st.session_state[key]


def _train_classification_model(dl_models, X_train, y_train, X_test, y_test, 
                               n_clusters, hidden_units, dropout_rate, learning_rate, epochs):
    """ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰"""
    # 1ë‹¨ê³„: ëª¨ë¸ ìƒì„±
    st.write("**1ï¸âƒ£ ì‹ ê²½ë§ ëª¨ë¸ ìƒì„± ì¤‘...**")
    
    with st.spinner("ëª¨ë¸ ì•„í‚¤í…ì²˜ êµ¬ì„± ì¤‘..."):
        model, create_error = dl_models.create_safe_classification_model(
            input_dim=3,
            n_clusters=n_clusters,
            hidden_units=hidden_units,
            dropout_rate=dropout_rate,
            learning_rate=learning_rate
        )
    
    if create_error:
        st.error(f"âŒ {create_error}")
        st.info("í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
        st.stop()
    
    st.success("âœ… ì‹ ê²½ë§ ëª¨ë¸ ìƒì„± ì™„ë£Œ!")
    
    # 2ë‹¨ê³„: ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ë³´ í‘œì‹œ
    st.write("**2ï¸âƒ£ ì‹ ê²½ë§ êµ¬ì¡° í™•ì¸**")
    dl_models.display_model_architecture_info(hidden_units, dropout_rate, n_clusters)
    
    # 3ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨
    st.write("**3ï¸âƒ£ ì‹ ê²½ë§ í›ˆë ¨ ì‹œì‘**")
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    status_text.text("ğŸƒâ€â™‚ï¸ ì‹ ê²½ë§ í›ˆë ¨ ì¤€ë¹„ ì¤‘...")
    
    history, train_error = dl_models.train_model_with_progress(
        model, X_train, y_train, X_test, y_test, epochs, progress_bar, status_text
    )
    
    if train_error:
        st.error(f"âŒ {train_error}")
        st.info("ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
        st.stop()
    
    status_text.text("âœ… ì‹ ê²½ë§ í›ˆë ¨ ì™„ë£Œ!")
    progress_bar.progress(1.0)
    st.success("ğŸ‰ ëª¨ë¸ í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # 4ë‹¨ê³„: ëª¨ë¸ í‰ê°€
    st.write("**4ï¸âƒ£ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ê²°ê³¼ ë¶„ì„**")
    
    evaluation_results = dl_models.evaluate_and_display_results(
        model, X_test, y_test, history, n_clusters
    )
    
    if evaluation_results is None:
        st.warning("ëª¨ë¸ í‰ê°€ ê³¼ì •ì—ì„œ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.stop()
    
    # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.model_trained = True
    st.session_state.dl_model = model
    st.session_state.dl_scaler = StandardScaler().fit(X_train)  # ìƒˆë¡œìš´ scaler ìƒì„±
    st.session_state.dl_history = history
    st.session_state.dl_evaluation_results = evaluation_results
    st.session_state.dl_X_test = X_test
    st.session_state.dl_y_test = y_test
    
    st.info("ğŸ”„ ëª¨ë¸ê³¼ ê²°ê³¼ê°€ ì„¸ì…˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def _display_classification_results(n_clusters):
    """ë¶„ë¥˜ ëª¨ë¸ ê²°ê³¼ í‘œì‹œ"""
    # ì„¸ì…˜ì—ì„œ ë°ì´í„° ë³µì›
    model = st.session_state.dl_model
    scaler = st.session_state.dl_scaler
    history = st.session_state.dl_history
    evaluation_results = st.session_state.dl_evaluation_results
    X_test = st.session_state.dl_X_test
    y_test = st.session_state.dl_y_test
    
    y_pred_classes = evaluation_results["predictions"]
    
    st.write("**ğŸ“Š í›ˆë ¨ëœ ëª¨ë¸ ê²°ê³¼ ìš”ì•½**")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("í…ŒìŠ¤íŠ¸ ì •í™•ë„", f"{evaluation_results['test_accuracy']:.3f}")
    with col2:
        st.metric("í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„", f"{evaluation_results['confidence']:.3f}")
    with col3:
        st.metric("í›ˆë ¨ ì—í¬í¬ ìˆ˜", len(history.history["loss"]))
    
    # í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
    cm = confusion_matrix(y_test, y_pred_classes)
    fig = px.imshow(
        cm,
        labels=dict(x="ì˜ˆì¸¡ í´ëŸ¬ìŠ¤í„°", y="ì‹¤ì œ í´ëŸ¬ìŠ¤í„°", color="ê³ ê° ìˆ˜"),
        x=[f"í´ëŸ¬ìŠ¤í„° {i}" for i in range(n_clusters)],
        y=[f"í´ëŸ¬ìŠ¤í„° {i}" for i in range(n_clusters)],
        title="í˜¼ë™ í–‰ë ¬ (Confusion Matrix)",
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # í´ëŸ¬ìŠ¤í„°ë³„ ì„±ëŠ¥ ë¶„ì„
    st.write("**ğŸ¯ í´ëŸ¬ìŠ¤í„°ë³„ ì˜ˆì¸¡ ì„±ëŠ¥:**")
    
    report = classification_report(y_test, y_pred_classes, output_dict=True)
    performance_data = []
    for cluster_id in range(n_clusters):
        if str(cluster_id) in report:
            cluster_info = report[str(cluster_id)]
            performance_data.append({
                "í´ëŸ¬ìŠ¤í„°": f"í´ëŸ¬ìŠ¤í„° {cluster_id}",
                "ì •ë°€ë„": f"{cluster_info['precision']:.3f}",
                "ì¬í˜„ìœ¨": f"{cluster_info['recall']:.3f}",
                "F1-ì ìˆ˜": f"{cluster_info['f1-score']:.3f}",
                "ì§€ì› ìˆ˜": cluster_info["support"],
            })
    
    performance_df = pd.DataFrame(performance_data)
    st.dataframe(performance_df, use_container_width=True)
    
    # ìƒˆë¡œìš´ ê³ ê° ì˜ˆì¸¡ ê¸°ëŠ¥
    st.subheader("ğŸ”® ìƒˆë¡œìš´ ê³ ê° ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        test_age = st.number_input("í…ŒìŠ¤íŠ¸ ê³ ê° ì—°ë ¹", min_value=18, max_value=80, value=35)
    with col2:
        test_income = st.number_input("ì—°ê°„ ì†Œë“ (k$)", min_value=15, max_value=150, value=60)
    with col3:
        test_spending = st.number_input("ì§€ì¶œ ì ìˆ˜", min_value=1, max_value=100, value=70)
    
    if st.button("ğŸ¯ ë”¥ëŸ¬ë‹ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡"):
        try:
            # ìƒˆë¡œìš´ ê³ ê° ë°ì´í„° ì „ì²˜ë¦¬
            new_customer = np.array([[test_age, test_income, test_spending]])
            new_customer_scaled = scaler.transform(new_customer)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            prediction_probs = model.predict(new_customer_scaled, verbose=0)[0]
            predicted_cluster = np.argmax(prediction_probs)
            
            st.success(f"ğŸ¯ ì˜ˆì¸¡ëœ í´ëŸ¬ìŠ¤í„°: **í´ëŸ¬ìŠ¤í„° {predicted_cluster}**")
            
            # ê° í´ëŸ¬ìŠ¤í„°ë³„ í™•ë¥  í‘œì‹œ
            st.write("**ê° í´ëŸ¬ìŠ¤í„°ë³„ ì†Œì† í™•ë¥ :**")
            prob_data = pd.DataFrame({
                "í´ëŸ¬ìŠ¤í„°": [f"í´ëŸ¬ìŠ¤í„° {i}" for i in range(n_clusters)],
                "í™•ë¥ ": [f"{prob:.1%}" for prob in prediction_probs],
            })
            st.dataframe(prob_data, use_container_width=True)
            
            # í™•ë¥  ì‹œê°í™”
            fig = px.bar(
                x=[f"í´ëŸ¬ìŠ¤í„° {i}" for i in range(n_clusters)],
                y=prediction_probs,
                title="í´ëŸ¬ìŠ¤í„°ë³„ ì†Œì† í™•ë¥ ",
                labels={"x": "í´ëŸ¬ìŠ¤í„°", "y": "í™•ë¥ "}
            )
            st.plotly_chart(fig, use_container_width=True)
            
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.info("ëª¨ë¸ì„ ë‹¤ì‹œ í›ˆë ¨í•´ë³´ì„¸ìš”.")


def _train_autoencoder_model(dl_models, scaled_features, encoding_dim):
    """ì˜¤í† ì¸ì½”ë” ëª¨ë¸ í›ˆë ¨"""
    st.write(f"**ğŸ”„ {encoding_dim}ì°¨ì› ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì‹œì‘**")
    
    try:
        # ì˜¤í† ì¸ì½”ë” ìƒì„±
        autoencoder, encoder, create_error = dl_models.create_autoencoder(
            input_dim=3, encoding_dim=encoding_dim
        )
        
        if create_error:
            st.error(f"âŒ {create_error}")
            return
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("ğŸ”„ ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì¤‘...")
        
        # í›ˆë ¨ ì‹¤í–‰
        history, train_error = dl_models.train_autoencoder(
            autoencoder, scaled_features, progress_bar=progress_bar, status_text=status_text
        )
        
        if train_error:
            st.error(f"âŒ {train_error}")
            return
        
        # ê²°ê³¼ ê³„ì‚°
        encoded_data = encoder.predict(scaled_features, verbose=0)
        reconstructed = autoencoder.predict(scaled_features, verbose=0)
        reconstruction_error = np.mean(np.square(scaled_features - reconstructed))
        
        # PCA ë¹„êµë¥¼ ìœ„í•œ ê³„ì‚°
        pca = PCA(n_components=encoding_dim)
        pca_result = pca.fit_transform(scaled_features)
        pca_variance_ratio = np.sum(pca.explained_variance_ratio_)
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.autoencoder_trained = True
        st.session_state.autoencoder_model = autoencoder
        st.session_state.encoder_model = encoder
        st.session_state.encoded_data = encoded_data
        st.session_state.reconstruction_error = reconstruction_error
        st.session_state.pca_result = pca_result
        st.session_state.pca_variance_ratio = pca_variance_ratio
        
        # ì™„ë£Œ í‘œì‹œ
        status_text.text("âœ… ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì™„ë£Œ!")
        progress_bar.progress(1.0)
        st.success("ğŸ‰ ì˜¤í† ì¸ì½”ë” í›ˆë ¨ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        st.error(f"âŒ ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


def _display_autoencoder_results(encoding_dim):
    """ì˜¤í† ì¸ì½”ë” ê²°ê³¼ í‘œì‹œ"""
    # ì„¸ì…˜ì—ì„œ ë°ì´í„° ë³µì›
    autoencoder = st.session_state.autoencoder_model
    encoder = st.session_state.encoder_model
    encoded_data = st.session_state.encoded_data
    reconstruction_error = st.session_state.reconstruction_error
    pca_result = st.session_state.pca_result
    pca_variance_ratio = st.session_state.pca_variance_ratio
    
    st.metric("ì¬êµ¬ì„± ì˜¤ì°¨ (MSE)", f"{reconstruction_error:.4f}")
    
    # ì˜¤í† ì¸ì½”ë” vs PCA ë¹„êµ
    st.subheader("ğŸ” ì˜¤í† ì¸ì½”ë” vs PCA ë¹„êµ")
    
    # ë°ì´í„° ë¡œë“œ (ì‹œê°í™”ìš©)
    data_processor = CustomerDataProcessor()
    data = data_processor.load_data()
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ì˜¤í† ì¸ì½”ë” ê²°ê³¼
        fig1 = px.scatter(
            x=encoded_data[:, 0],
            y=encoded_data[:, 1],
            color=data["Gender"],
            title=f"ì˜¤í† ì¸ì½”ë” ê²°ê³¼ ({encoding_dim}D)",
            labels={"x": "ì¸ì½”ë”© ì°¨ì› 1", "y": "ì¸ì½”ë”© ì°¨ì› 2"}
        )
        st.plotly_chart(fig1, use_container_width=True)
    
    with col2:
        # PCA ê²°ê³¼
        fig2 = px.scatter(
            x=pca_result[:, 0],
            y=pca_result[:, 1],
            color=data["Gender"],
            title=f"PCA ê²°ê³¼ ({encoding_dim}D)",
            labels={"x": "PC1", "y": "PC2"}
        )
        st.plotly_chart(fig2, use_container_width=True)
    
    # ë¹„êµ ì§€í‘œ
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì˜¤í† ì¸ì½”ë” ì¬êµ¬ì„± ì˜¤ì°¨", f"{reconstruction_error:.4f}")
    with col2:
        st.metric("PCA ì„¤ëª… ë¶„ì‚° ë¹„ìœ¨", f"{pca_variance_ratio:.3f}")


def _show_model_comparison():
    """ë‘ ëª¨ë¸ ë¹„êµ ì„¹ì…˜"""
    st.markdown("---")
    st.subheader("ğŸ”€ ë¶„ë¥˜ ëª¨ë¸ vs ì˜¤í† ì¸ì½”ë” ì¢…í•© ë¹„êµ")
    
    # ë‘ ëª¨ë¸ì˜ í›ˆë ¨ ìƒíƒœ í™•ì¸
    classification_trained = st.session_state.get('model_trained', False)
    autoencoder_trained = st.session_state.get('autoencoder_trained', False)
    
    if not classification_trained and not autoencoder_trained:
        st.warning("ğŸ”„ **ë‘ ëª¨ë¸ ëª¨ë‘ í›ˆë ¨ì´ í•„ìš”í•©ë‹ˆë‹¤.**")
        st.info("ìœ„ì˜ 'ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì‹œì‘'ê³¼ 'ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì‹œì‘' ë²„íŠ¼ì„ ê°ê° í´ë¦­í•˜ì—¬ ë‘ ëª¨ë¸ì„ ëª¨ë‘ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
    elif not classification_trained:
        st.warning("ğŸ”„ **ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ì´ í•„ìš”í•©ë‹ˆë‹¤.**")
    elif not autoencoder_trained:
        st.warning("ğŸ”„ **ì˜¤í† ì¸ì½”ë” í›ˆë ¨ì´ í•„ìš”í•©ë‹ˆë‹¤.**")
    else:
        st.success("âœ… ë‘ ëª¨ë¸ì´ ëª¨ë‘ í›ˆë ¨ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì¢…í•© ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        
        # ë¹„êµ ë¶„ì„ ì‹¤í–‰
        classification_results = st.session_state.get('dl_evaluation_results', {})
        autoencoder_results = {
            'reconstruction_error': st.session_state.get('reconstruction_error', 0),
            'encoded_data': st.session_state.get('encoded_data', None),
            'autoencoder_model': st.session_state.get('autoencoder_model', None)
        }
        
        # ì„±ëŠ¥ ì§€í‘œ ë¹„êµ ëŒ€ì‹œë³´ë“œ
        st.subheader("ğŸ“Š ì„±ëŠ¥ ì§€í‘œ ì¢…í•© ë¹„êµ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="ë¶„ë¥˜ ëª¨ë¸ ì •í™•ë„",
                value=f"{classification_results.get('test_accuracy', 0):.3f}",
                help="ìƒˆë¡œìš´ ê³ ê°ì„ ì˜¬ë°”ë¥¸ í´ëŸ¬ìŠ¤í„°ë¡œ ë¶„ë¥˜í•˜ëŠ” ì •í™•ë„"
            )
        
        with col2:
            st.metric(
                label="ë¶„ë¥˜ ëª¨ë¸ ì‹ ë¢°ë„",
                value=f"{classification_results.get('confidence', 0):.3f}",
                help="ì˜ˆì¸¡ì— ëŒ€í•œ í‰ê·  ì‹ ë¢°ë„ (í™•ë¥ )"
            )
        
        with col3:
            st.metric(
                label="ì˜¤í† ì¸ì½”ë” ì¬êµ¬ì„± ì˜¤ì°¨",
                value=f"{autoencoder_results.get('reconstruction_error', 0):.4f}",
                help="ì›ë³¸ ë°ì´í„°ë¥¼ ì–¼ë§ˆë‚˜ ì •í™•íˆ ì¬êµ¬ì„±í•˜ëŠ”ì§€ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)"
            )
        
        with col4:
            # ì¢…í•© ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
            classification_score = classification_results.get('test_accuracy', 0) * 100
            recon_error = autoencoder_results.get('reconstruction_error', 1)
            autoencoder_score = max(0, (1 - min(recon_error, 1)) * 100)
            overall_score = (classification_score + autoencoder_score) / 2
            
            st.metric(
                label="ì¢…í•© ì„±ëŠ¥ ì ìˆ˜",
                value=f"{overall_score:.1f}/100",
                help="ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¢…í•©í•œ ì ìˆ˜"
            )
        
        # ìƒì„¸ ë¹„êµ ë¶„ì„í‘œ
        st.subheader("ğŸ“‹ ìƒì„¸ ë¹„êµ ë¶„ì„")
        
        comparison_data = {
            "ë¹„êµ í•­ëª©": [
                "ì£¼ìš” ëª©ì ", "í•™ìŠµ ë°©ì‹", "ì¶œë ¥ ê²°ê³¼", "ìƒˆ ê³ ê° ì˜ˆì¸¡", 
                "ë°ì´í„° ì••ì¶•", "ì´ìƒì¹˜ ê°ì§€", "í•´ì„ ê°€ëŠ¥ì„±", "ì‹¤ìš©ì„±"
            ],
            "ë¶„ë¥˜ ëª¨ë¸": [
                "ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ ì˜ˆì¸¡", "ì§€ë„ í•™ìŠµ", "í´ëŸ¬ìŠ¤í„° í™•ë¥ ", "ì¦‰ì‹œ ê°€ëŠ¥",
                "ë¶ˆê°€ëŠ¥", "ì œí•œì ", "ë†’ìŒ", "ë§¤ìš° ë†’ìŒ"
            ],
            "ì˜¤í† ì¸ì½”ë”": [
                "ë°ì´í„° ì••ì¶• ë° ì¬êµ¬ì„±", "ë¹„ì§€ë„ í•™ìŠµ", "ì••ì¶•ëœ íŠ¹ì„±", "ê°„ì ‘ì ",
                "ê°€ëŠ¥", "ìš°ìˆ˜", "ë‚®ìŒ", "ë†’ìŒ"
            ],
            "ìš°ìˆ˜í•œ ëª¨ë¸": [
                "ë¶„ë¥˜ ëª¨ë¸", "ê°ê° ì¥ì ", "ë¶„ë¥˜ ëª¨ë¸", "ë¶„ë¥˜ ëª¨ë¸",
                "ì˜¤í† ì¸ì½”ë”", "ì˜¤í† ì¸ì½”ë”", "ë¶„ë¥˜ ëª¨ë¸", "ë¶„ë¥˜ ëª¨ë¸"
            ]
        }
        
        comparison_df = pd.DataFrame(comparison_data)
        st.dataframe(comparison_df, use_container_width=True)
        
        # ìµœì¢… ì¶”ì²œ
        if classification_results.get('test_accuracy', 0) > 0.8:
            primary_recommendation = "ë¶„ë¥˜ ëª¨ë¸"
            reason = "ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„"
        elif autoencoder_results.get('reconstruction_error', 1) < 0.1:
            primary_recommendation = "ì˜¤í† ì¸ì½”ë”" 
            reason = "ìš°ìˆ˜í•œ ë°ì´í„° ì¬êµ¬ì„± ì„±ëŠ¥"
        else:
            primary_recommendation = "í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼"
            reason = "ë‘ ëª¨ë¸ ëª¨ë‘ ê°œì„  ì—¬ì§€"
        
        st.success(f"""
        **ğŸ¯ í˜„ì¬ ë°ì´í„°ì— ëŒ€í•œ ìµœì¢… ì¶”ì²œ: {primary_recommendation}**
        
        **ì¶”ì²œ ì´ìœ **: {reason}
        
        **ì‹¤í–‰ ê³„íš**:
        1. **ì¦‰ì‹œ ì‹¤í–‰**: ì„±ëŠ¥ì´ ìš°ìˆ˜í•œ ëª¨ë¸ì„ í”„ë¡œë•ì…˜ í™˜ê²½ì— ìš°ì„  ì ìš©
        2. **1ì£¼ì¼ ë‚´**: A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ì‹¤ì œ ì„±ëŠ¥ ê²€ì¦
        3. **1ê°œì›” ë‚´**: ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ë° ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        4. **3ê°œì›” ë‚´**: ì¶”ê°€ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í›ˆë ¨ ë° í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²• ë„ì…
        """)
