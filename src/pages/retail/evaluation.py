"""
Online Retail ëª¨ë¸ í‰ê°€ í˜ì´ì§€

ëª¨ë¸ í‰ê°€ ë° í•´ì„ì„ ë‹´ë‹¹í•˜ëŠ” Streamlit í˜ì´ì§€
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

from retail_analysis.model_trainer import RetailModelTrainer
from retail_analysis.visualizer import RetailVisualizer
from scipy import stats
import warnings

warnings.filterwarnings("ignore")


def show_evaluation_page():
    """ëª¨ë¸ í‰ê°€ ë° í•´ì„ í˜ì´ì§€"""
    
    st.header("6ï¸âƒ£ ëª¨ë¸ í‰ê°€ & í•´ì„")
    
    # ì´ì „ ë‹¨ê³„ ì™„ë£Œ í™•ì¸
    if not st.session_state.get('retail_model_trained', False):
        st.warning("âš ï¸ ë¨¼ì € 5ë‹¨ê³„ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
        return
    
    st.markdown("""
    ### ğŸ“– í•™ìŠµ ëª©í‘œ
    - ëª¨ë¸ ì„±ëŠ¥ì˜ ì¢…í•©ì  í‰ê°€ ë°©ë²• í•™ìŠµ
    - ì”ì°¨ ë¶„ì„ì„ í†µí•œ ëª¨ë¸ ì§„ë‹¨
    - ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ ëª¨ë¸ í•´ì„ ë° í™œìš© ë°©ì•ˆ ë„ì¶œ
    """)
    
    training_results = st.session_state.retail_training_results
    
    # ì¢…í•© ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
    if not st.session_state.get('retail_model_evaluated', False):
        if st.button("ğŸ“Š ì¢…í•© ëª¨ë¸ í‰ê°€ ì‹¤í–‰", type="primary"):
            with st.spinner("ëª¨ë¸ì„ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    trainer = st.session_state.retail_model_trainer
                    evaluation_results = trainer.evaluate_model()
                    
                    # í‰ê°€ ê²°ê³¼ ì €ì¥
                    st.session_state.retail_evaluation_results = evaluation_results
                    st.session_state.retail_model_evaluated = True
                    
                    st.success("âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ!")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"âŒ ëª¨ë¸ í‰ê°€ ì‹¤íŒ¨: {str(e)}")
    
    # í‰ê°€ ê²°ê³¼ í‘œì‹œ
    if st.session_state.get('retail_model_evaluated', False):
        evaluation_results = st.session_state.retail_evaluation_results
        
        st.success("âœ… ëª¨ë¸ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ì¢…í•© ì„±ëŠ¥ ì§€í‘œ í…Œì´ë¸”
        st.subheader("ğŸ“Š ì¢…í•© ì„±ëŠ¥ í‰ê°€")
        
        metrics_df = pd.DataFrame({
            'ì§€í‘œ': ['RÂ² Score', 'MAE (Â£)', 'RMSE (Â£)', 'ìƒëŒ€ì˜¤ì°¨ (%)'],
            'í›ˆë ¨ ì„±ëŠ¥': [
                f"{evaluation_results['r2_train']:.4f}",
                f"{evaluation_results['mae_train']:.2f}",
                f"{evaluation_results['rmse_train']:.2f}",
                f"{(evaluation_results['mae_train'] / training_results['y_train'].mean()) * 100:.2f}"
            ],
            'í…ŒìŠ¤íŠ¸ ì„±ëŠ¥': [
                f"{evaluation_results['r2_test']:.4f}",
                f"{evaluation_results['mae_test']:.2f}",
                f"{evaluation_results['rmse_test']:.2f}",
                f"{evaluation_results['relative_error']:.2f}"
            ],
            'ì°¨ì´': [
                f"{evaluation_results['r2_test'] - evaluation_results['r2_train']:.4f}",
                f"{evaluation_results['mae_test'] - evaluation_results['mae_train']:.2f}",
                f"{evaluation_results['rmse_test'] - evaluation_results['rmse_train']:.2f}",
                f"{evaluation_results['relative_error'] - (evaluation_results['mae_train'] / training_results['y_train'].mean()) * 100:.2f}"
            ]
        })
        
        st.dataframe(metrics_df, use_container_width=True)
        
        # ì„±ëŠ¥ í•´ì„
        st.subheader("ğŸ’¡ ì„±ëŠ¥ í•´ì„")
        
        test_r2 = evaluation_results['r2_test']
        performance_gap = evaluation_results['performance_gap']
        relative_error = evaluation_results['relative_error']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ¯ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€:**")
            if test_r2 >= 0.8:
                st.success(f"ğŸ‰ **ìš°ìˆ˜í•œ ì„±ëŠ¥**: RÂ² = {test_r2:.3f}")
                performance_level = "ìš°ìˆ˜"
            elif test_r2 >= 0.6:
                st.info(f"ğŸ‘ **ì–‘í˜¸í•œ ì„±ëŠ¥**: RÂ² = {test_r2:.3f}")
                performance_level = "ì–‘í˜¸"
            else:
                st.warning(f"âš ï¸ **ê°œì„  í•„ìš”**: RÂ² = {test_r2:.3f}")
                performance_level = "ê°œì„  í•„ìš”"
        
        with col2:
            st.markdown("**ğŸ” ê³¼ì í•© ë¶„ì„:**")
            if performance_gap <= 0.05:
                st.success("âœ… **ê³¼ì í•© ì—†ìŒ**")
                overfitting_status = "ì—†ìŒ"
            else:
                st.warning("âš ï¸ **ê³¼ì í•© ë°œìƒ**")
                overfitting_status = "ìˆìŒ"
        
        # ì¢…í•© ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™”
        st.subheader("ğŸ“ˆ ì¢…í•© ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™”")
        
        try:
            performance_fig = RetailVisualizer.create_model_performance_plots(evaluation_results)
            st.plotly_chart(performance_fig, use_container_width=True)
        except Exception as e:
            st.warning(f"ì„±ëŠ¥ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # ëŒ€ì•ˆ ì‹œê°í™”
            col1, col2 = st.columns(2)
            
            with col1:
                # ì˜ˆì¸¡ vs ì‹¤ì œê°’ ì‚°ì ë„
                y_test = training_results['y_test']
                y_test_pred = training_results['y_test_pred']
                
                fig_pred = px.scatter(
                    x=y_test, y=y_test_pred,
                    title="ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’",
                    labels={'x': 'ì‹¤ì œê°’ (Â£)', 'y': 'ì˜ˆì¸¡ê°’ (Â£)'}
                )
                
                # ì™„ë²½í•œ ì˜ˆì¸¡ì„  ì¶”ê°€
                min_val = min(y_test.min(), y_test_pred.min())
                max_val = max(y_test.max(), y_test_pred.max())
                fig_pred.add_trace(go.Scatter(
                    x=[min_val, max_val], y=[min_val, max_val],
                    mode='lines', name='ì™„ë²½í•œ ì˜ˆì¸¡', line=dict(color='red', dash='dash')
                ))
                st.plotly_chart(fig_pred, use_container_width=True)
            
            with col2:
                # ì”ì°¨ íˆìŠ¤í† ê·¸ë¨
                residuals = evaluation_results['residuals']
                fig_residuals = px.histogram(
                    x=residuals,
                    title="ì”ì°¨ ë¶„í¬",
                    labels={'x': 'ì”ì°¨ (Â£)'}
                )
                st.plotly_chart(fig_residuals, use_container_width=True)
        
        # ì”ì°¨ ë¶„ì„
        st.subheader("ğŸ” ì”ì°¨ ë¶„ì„")
        
        residuals = evaluation_results['residuals']
        y_test_pred = training_results['y_test_pred']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ì”ì°¨ vs ì˜ˆì¸¡ê°’
            fig_residuals_pred = px.scatter(
                x=y_test_pred, y=residuals,
                title="ì”ì°¨ vs ì˜ˆì¸¡ê°’",
                labels={'x': 'ì˜ˆì¸¡ê°’ (Â£)', 'y': 'ì”ì°¨ (Â£)'}
            )
            # ê¸°ì¤€ì„  ì¶”ê°€
            fig_residuals_pred.add_trace(go.Scatter(
                x=[y_test_pred.min(), y_test_pred.max()], y=[0, 0],
                mode='lines', name='ê¸°ì¤€ì„ ', line=dict(color='red', dash='dash')
            ))
            st.plotly_chart(fig_residuals_pred, use_container_width=True)
        
        with col2:
            # Q-Q í”Œë¡¯ (ì •ê·œì„± ê²€ì •)
            fig_qq = go.Figure()
            
            # ìƒ˜í”Œ í¬ê¸° ì œí•œ (ê³„ì‚° íš¨ìœ¨ì„±ì„ ìœ„í•´)
            sample_residuals = residuals[:min(5000, len(residuals))]
            qq_data = stats.probplot(sample_residuals, dist="norm")
            
            fig_qq.add_trace(go.Scatter(
                x=qq_data[0][0], y=qq_data[0][1],
                mode='markers', name='ì”ì°¨'
            ))
            fig_qq.add_trace(go.Scatter(
                x=qq_data[0][0], y=qq_data[1][0] + qq_data[1][1] * qq_data[0][0],
                mode='lines', name='ê¸°ì¤€ì„ ', line=dict(color='red', dash='dash')
            ))
            fig_qq.update_layout(
                title="Q-Q í”Œë¡¯ (ì •ê·œì„± ê²€ì •)", 
                xaxis_title="ì´ë¡ ì  ë¶„ìœ„ìˆ˜", 
                yaxis_title="í‘œë³¸ ë¶„ìœ„ìˆ˜"
            )
            st.plotly_chart(fig_qq, use_container_width=True)
        
        # ëª¨ë¸ ê°€ì • ê²€ì • ê²°ê³¼
        st.subheader("ğŸ§ª ëª¨ë¸ ê°€ì • ê²€ì •")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # ì •ê·œì„± ê²€ì •
            normality_test = evaluation_results['normality_test']
            st.markdown("**ì •ê·œì„± ê²€ì • (Shapiro-Wilk)**")
            st.write(f"í†µê³„ëŸ‰: {normality_test['shapiro_stat']:.4f}")
            st.write(f"p-value: {normality_test['shapiro_p_value']:.6f}")
            
            if normality_test['is_normal']:
                st.success("âœ… ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„")
            else:
                st.warning("âš ï¸ ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠìŒ")
        
        with col2:
            # ë“±ë¶„ì‚°ì„± ê²€ì •
            hetero_test = evaluation_results['heteroscedasticity_test']
            st.markdown("**ë“±ë¶„ì‚°ì„± ê²€ì •**")
            st.write(f"ìƒê´€ê³„ìˆ˜: {hetero_test['correlation']:.4f}")
            
            if hetero_test['is_homoscedastic']:
                st.success("âœ… ë“±ë¶„ì‚°ì„± ê°€ì • ë§Œì¡±")
            else:
                st.warning("âš ï¸ ì´ë¶„ì‚°ì„± ì¡´ì¬")
        
        with col3:
            # ì”ì°¨ í†µê³„
            st.markdown("**ì”ì°¨ í†µê³„**")
            st.write(f"í‰ê· : {evaluation_results['residuals_mean']:.4f}")
            st.write(f"í‘œì¤€í¸ì°¨: {evaluation_results['residuals_std']:.2f}")
            
            if abs(evaluation_results['residuals_mean']) < 0.1:
                st.success("âœ… ì”ì°¨ í‰ê· ì´ 0ì— ê°€ê¹Œì›€")
            else:
                st.warning("âš ï¸ ì”ì°¨ì— í¸í–¥ ì¡´ì¬")
        
        # ëª¨ë¸ ê°€ì • ê²€ì • í•´ì„
        with st.expander("ğŸ“– ëª¨ë¸ ê°€ì • ê²€ì • í•´ì„"):
            st.markdown("""
            **ì„ í˜•íšŒê·€ì˜ ì£¼ìš” ê°€ì •ë“¤:**
            
            1. **ì„ í˜•ì„±**: ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„
            2. **ì •ê·œì„±**: ì”ì°¨ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¦„
            3. **ë“±ë¶„ì‚°ì„±**: ì”ì°¨ì˜ ë¶„ì‚°ì´ ì¼ì •í•¨
            4. **ë…ë¦½ì„±**: ì”ì°¨ë“¤ì´ ì„œë¡œ ë…ë¦½ì ì„
            
            **ê°€ì • ìœ„ë°˜ ì‹œ ëŒ€ì²˜ ë°©ì•ˆ:**
            - **ì •ê·œì„± ìœ„ë°˜**: ë³€ìˆ˜ ë³€í™˜, ë¹„ëª¨ìˆ˜ì  ë°©ë²• ê³ ë ¤
            - **ë“±ë¶„ì‚°ì„± ìœ„ë°˜**: ê°€ì¤‘íšŒê·€, ë¡œë²„ìŠ¤íŠ¸ í‘œì¤€ì˜¤ì°¨ ì‚¬ìš©
            - **ì„ í˜•ì„± ìœ„ë°˜**: ë‹¤í•­ íšŒê·€, ë¹„ì„ í˜• ëª¨ë¸ ê³ ë ¤
            """)
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„
        st.subheader("ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì  í•´ì„")
        
        # ëª¨ë¸ í•´ì„ ì •ë³´
        interpretation = evaluation_results.get('interpretation', {})
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ¯ ì˜ˆì¸¡ ì •í™•ë„:**")
            if relative_error <= 15:
                st.success("ğŸ¯ **ê³ ì •ë°€ë„ ì˜ˆì¸¡ ê°€ëŠ¥**")
                st.write("ê°œì¸í™”ëœ ë§ˆì¼€íŒ… ì „ëµ ìˆ˜ë¦½ ê°€ëŠ¥")
                accuracy_level = "ê³ ì •ë°€ë„"
            elif relative_error <= 25:
                st.info("ğŸ‘ **ì„¸ê·¸ë¨¼íŠ¸ë³„ ì „ëµ ìˆ˜ë¦½**")
                st.write("ê³ ê°êµ°ë³„ ì°¨ë³„í™” ì „ëµ ê¶Œì¥")
                accuracy_level = "ì¤‘ê°„ ì •ë°€ë„"
            else:
                st.warning("âš ï¸ **ì „ë°˜ì  íŠ¸ë Œë“œ íŒŒì•…**")
                st.write("ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ëª¨ë¸ ê°œì„  í•„ìš”")
                accuracy_level = "ë‚®ì€ ì •ë°€ë„"
        
        with col2:
            st.markdown("**ğŸ“ˆ í™œìš© ë°©ì•ˆ:**")
            st.write("â€¢ ê³ ê°ë³„ ì˜ˆìƒ êµ¬ë§¤ ê¸ˆì•¡ ì˜ˆì¸¡")
            st.write("â€¢ ë§ˆì¼€íŒ… ì˜ˆì‚° ë°°ë¶„ ìµœì í™”")
            st.write("â€¢ ê³ ê° ê°€ì¹˜ ê¸°ë°˜ ì„¸ë¶„í™”")
            st.write("â€¢ ì´íƒˆ ìœ„í—˜ ê³ ê° ì‹ë³„")
        
        # íŠ¹ì„± ì¤‘ìš”ë„ í•´ì„
        st.subheader("ğŸ¯ íŠ¹ì„± ì¤‘ìš”ë„ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„")
        
        feature_importance = evaluation_results['feature_importance']
        
        if 'error' not in feature_importance:
            # ìƒìœ„ ì˜í–¥ íŠ¹ì„±ë“¤
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ğŸ“ˆ ê¸ì •ì  ì˜í–¥ íŠ¹ì„± (Top 5)**")
                positive_features = feature_importance['positive_impact_features'][:5]
                for i, feature in enumerate(positive_features, 1):
                    st.write(f"{i}. **{feature['feature']}**: +{feature['coefficient']:.3f}")
                    st.caption(get_feature_business_meaning(feature['feature'], 'positive'))
            
            with col2:
                st.markdown("**ğŸ“‰ ë¶€ì •ì  ì˜í–¥ íŠ¹ì„± (Top 5)**")
                negative_features = feature_importance['negative_impact_features'][:5]
                for i, feature in enumerate(negative_features, 1):
                    st.write(f"{i}. **{feature['feature']}**: {feature['coefficient']:.3f}")
                    st.caption(get_feature_business_meaning(feature['feature'], 'negative'))
        
        # ëª¨ë¸ ê°œì„  ì œì•ˆ
        st.subheader("ğŸš€ ëª¨ë¸ ê°œì„  ì œì•ˆ")
        
        improvement_suggestions = interpretation.get('improvement_suggestions', [])
        
        if improvement_suggestions:
            st.markdown("**í˜„ì¬ ëª¨ë¸ì˜ ê°œì„  í¬ì¸íŠ¸:**")
            for suggestion in improvement_suggestions:
                st.warning(f"â€¢ {suggestion}")
        
        # ì¶”ê°€ ê°œì„  ì œì•ˆ
        additional_suggestions = []
        
        if test_r2 < 0.6:
            additional_suggestions.append("ë¹„ì„ í˜• ëª¨ë¸ (ëœë¤í¬ë ˆìŠ¤íŠ¸, XGBoost) ê³ ë ¤")
        
        if relative_error > 20:
            additional_suggestions.append("ì¶”ê°€ íŠ¹ì„± ê³µí•™ ë° ì™¸ë¶€ ë°ì´í„° í™œìš©")
        
        if overfitting_status == "ìˆìŒ":
            additional_suggestions.append("ì •ê·œí™” ê¸°ë²• (Ridge, Lasso) ì ìš©")
        
        if additional_suggestions:
            st.markdown("**ì¶”ê°€ ê°œì„  ì œì•ˆ:**")
            for suggestion in additional_suggestions:
                st.info(f"â€¢ {suggestion}")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ
        st.subheader("ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ")
        
        try:
            target_data = st.session_state.retail_target_data
            insights_fig = RetailVisualizer.create_business_insights_dashboard(target_data, evaluation_results)
            st.plotly_chart(insights_fig, use_container_width=True)
        except Exception as e:
            st.warning(f"ì¸ì‚¬ì´íŠ¸ ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # í•™ìŠµ ì™„ë£Œ ì¶•í•˜
        st.markdown("---")
        st.subheader("ğŸ“ í•™ìŠµ ì—¬ì • ì™„ë£Œ!")
        
        target_months = st.session_state.retail_target_months
        completion_summary = f"""
        **ğŸ‰ ì¶•í•˜í•©ë‹ˆë‹¤! Online Retail ë¶„ì„ í”„ë¡œì íŠ¸ë¥¼ ì™„ì£¼í•˜ì…¨ìŠµë‹ˆë‹¤!**
        
        **ğŸ“Š ìµœì¢… ëª¨ë¸ ì„±ëŠ¥:**
        - RÂ² Score: {test_r2:.3f} ({performance_level})
        - ì˜ˆì¸¡ ì˜¤ì°¨: {relative_error:.1f}% ({accuracy_level})
        - ê³¼ì í•© ì—¬ë¶€: {overfitting_status}
        - ì˜ˆì¸¡ ê¸°ê°„: {target_months}ê°œì›”
        
        **ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ:**
        1. ğŸ”„ **ê³ ê¸‰ ëª¨ë¸ ì‹œë„**: ëœë¤í¬ë ˆìŠ¤íŠ¸, XGBoost ë“±ìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ 
        2. ğŸ“Š **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ í™•ì¥**: ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±, ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì¶”ê°€
        3. ğŸ¯ **ë¶„ë¥˜ ë¬¸ì œ ë„ì „**: ê³ ê° ì´íƒˆ ì˜ˆì¸¡, ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¥˜ ë“±
        4. ğŸ’¼ **ë¹„ì¦ˆë‹ˆìŠ¤ ì ìš©**: ì‹¤ì œ ë§ˆì¼€íŒ… ìº í˜ì¸ì— ëª¨ë¸ ì ìš©
        
        **ğŸ¯ í•™ìŠµ ì„±ê³¼:**
        - ì‹¤ë¬´ê¸‰ ë°ì´í„° ì „ì²˜ë¦¬ ê²½í—˜
        - ì²´ê³„ì ì¸ íŠ¹ì„± ê³µí•™ ê³¼ì • ìŠµë“
        - ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì´í•´
        - ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œì˜ ëª¨ë¸ í•´ì„ ëŠ¥ë ¥ í–¥ìƒ
        """
        
        st.success(completion_summary)
        st.balloons()
        
        # í”„ë¡œì íŠ¸ ìš”ì•½ ë‹¤ìš´ë¡œë“œ
        with st.expander("ğŸ“‹ í”„ë¡œì íŠ¸ ìš”ì•½ ë³´ê³ ì„œ"):
            trainer = st.session_state.retail_model_trainer
            model_summary = trainer.get_model_summary()
            
            project_summary = f"""
# Online Retail ë¶„ì„ í”„ë¡œì íŠ¸ ìš”ì•½

## ğŸ“Š ë°ì´í„° ê°œìš”
- ì›ë³¸ ë°ì´í„°: {len(st.session_state.retail_raw_data):,}ê°œ ë ˆì½”ë“œ
- ì •ì œ í›„ ë°ì´í„°: {len(st.session_state.retail_cleaned_data):,}ê°œ ë ˆì½”ë“œ
- ë¶„ì„ ëŒ€ìƒ ê³ ê°: {len(st.session_state.retail_customer_features):,}ëª…

## ğŸ¯ ëª¨ë¸ ì„±ëŠ¥
- RÂ² Score: {test_r2:.3f}
- MAE: {evaluation_results['mae_test']:.2f}Â£
- RMSE: {evaluation_results['rmse_test']:.2f}Â£
- ìƒëŒ€ ì˜¤ì°¨: {relative_error:.1f}%

## ğŸ”§ ëª¨ë¸ ì„¤ì •
- í…ŒìŠ¤íŠ¸ ë¹„ìœ¨: {training_results['test_size']:.1%}
- ì •ê·œí™”: {'ì ìš©' if training_results['scale_features'] else 'ë¯¸ì ìš©'}
- ëœë¤ ì‹œë“œ: {training_results['random_state']}

## ğŸ’¡ ì£¼ìš” íŠ¹ì„± (ìƒìœ„ 5ê°œ)
{chr(10).join([f"- {f['feature']}: {f['coefficient']:.3f}" for f in feature_importance['top_10_features'][:5]])}

## ğŸ“ˆ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„
- ì˜ˆì¸¡ ì •í™•ë„: {accuracy_level}
- ê³¼ì í•© ì—¬ë¶€: {overfitting_status}
- í™œìš© ê°€ëŠ¥ì„±: {'ë†’ìŒ' if test_r2 >= 0.6 else 'ë³´í†µ'}

## ğŸš€ ê°œì„  ì œì•ˆ
{chr(10).join([f"- {s}" for s in improvement_suggestions + additional_suggestions])}
"""
            st.text_area("í”„ë¡œì íŠ¸ ìš”ì•½", project_summary, height=500)
    
    else:
        st.info("ğŸ’¡ 'ì¢…í•© ëª¨ë¸ í‰ê°€ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì‹œì‘í•´ì£¼ì„¸ìš”.")


def get_feature_business_meaning(feature_name, impact_type):
    """íŠ¹ì„±ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ ë°˜í™˜"""
    
    meanings = {
        'total_amount': {
            'positive': 'ê³¼ê±° êµ¬ë§¤ ê¸ˆì•¡ì´ ë†’ì„ìˆ˜ë¡ ë¯¸ë˜ êµ¬ë§¤ ê°€ëŠ¥ì„± ì¦ê°€',
            'negative': 'ê³¼ê±° êµ¬ë§¤ ê¸ˆì•¡ ëŒ€ë¹„ ë¯¸ë˜ êµ¬ë§¤ ê°ì†Œ ì˜ˆìƒ'
        },
        'frequency': {
            'positive': 'êµ¬ë§¤ ë¹ˆë„ê°€ ë†’ì„ìˆ˜ë¡ ì§€ì†ì  êµ¬ë§¤ ê¸°ëŒ€',
            'negative': 'ë†’ì€ êµ¬ë§¤ ë¹ˆë„ê°€ ì˜¤íˆë ¤ ê°ì†Œ ìš”ì¸ìœ¼ë¡œ ì‘ìš©'
        },
        'recency_days': {
            'positive': 'ì˜¤ë˜ëœ ê³ ê°ì¼ìˆ˜ë¡ ì¬êµ¬ë§¤ ê°€ëŠ¥ì„± ì¦ê°€',
            'negative': 'ìµœê·¼ êµ¬ë§¤ ê³ ê°ì¼ìˆ˜ë¡ ì¬êµ¬ë§¤ ê°€ëŠ¥ì„± ë†’ìŒ'
        },
        'monetary': {
            'positive': 'ë†’ì€ êµ¬ë§¤ë ¥ì„ ê°€ì§„ ê³ ê°ì˜ ì§€ì†ì  êµ¬ë§¤',
            'negative': 'ê³¼ë„í•œ ê³¼ê±° êµ¬ë§¤ë¡œ ì¸í•œ êµ¬ë§¤ë ¥ ì†Œì§„'
        },
        'unique_products': {
            'positive': 'ë‹¤ì–‘í•œ ìƒí’ˆ êµ¬ë§¤ ê³ ê°ì˜ ì§€ì†ì  ê´€ì‹¬',
            'negative': 'ë„ˆë¬´ ë§ì€ ìƒí’ˆ êµ¬ë§¤ë¡œ ì¸í•œ í¬í™” ìƒíƒœ'
        }
    }
    
    return meanings.get(feature_name, {}).get(impact_type, 'ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ ë¶„ì„ í•„ìš”')


def get_evaluation_status():
    """í‰ê°€ ìƒíƒœ ë°˜í™˜"""
    status = {
        'model_evaluated': st.session_state.get('retail_model_evaluated', False),
        'r2_score': 0.0,
        'relative_error': 0.0,
        'overfitting_risk': 'Unknown',
        'business_applicability': 'Unknown'
    }
    
    if status['model_evaluated']:
        evaluation_results = st.session_state.retail_evaluation_results
        status.update({
            'r2_score': evaluation_results['r2_test'],
            'relative_error': evaluation_results['relative_error'],
            'overfitting_risk': 'Low' if evaluation_results['performance_gap'] <= 0.05 else 'High',
            'business_applicability': evaluation_results.get('interpretation', {}).get('business_applicability', 'Unknown')
        })
    
    return status
