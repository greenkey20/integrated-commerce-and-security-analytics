"""
CICIDS2017 ë³´ì•ˆ ì´ìƒ íƒì§€ ë¶„ì„ í˜ì´ì§€

ì‹¤ì œ CICIDS2017 ë°ì´í„°ì…‹ì„ í™œìš©í•œ ë„¤íŠ¸ì›Œí¬ ì´ìƒ íƒì§€ ë¶„ì„ í˜ì´ì§€
ê¸°ì¡´ customer_segmentationê³¼ ë™ì¼í•œ êµ¬ì¡°ë¡œ êµ¬í˜„
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import warnings
warnings.filterwarnings('ignore')

# ì „ì—­ pandas ë³„ì¹­ ë³´ì¥
if 'pd' not in globals():
    import pandas as pd

# TensorFlow ê´€ë ¨ import (ê°•í™”ëœ ì„¤ì¹˜ ì²´í¬)
try:
    import tensorflow as tf
    from tensorflow import keras
    TENSORFLOW_AVAILABLE = True
    TF_VERSION = tf.__version__
except ImportError:
    TENSORFLOW_AVAILABLE = False
    TF_VERSION = None
    # TensorFlow ì„¤ì¹˜ ì‹œë„
    try:
        import subprocess
        import sys
        # ì¡°ìš©íˆ ì„¤ì¹˜ ì‹œë„ (ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•ŠìŒ)
        result = subprocess.run([sys.executable, '-m', 'pip', 'install', 'tensorflow'], 
                              capture_output=True, text=True, timeout=60)
        if result.returncode == 0:
            import tensorflow as tf
            from tensorflow import keras
            TENSORFLOW_AVAILABLE = True
            TF_VERSION = tf.__version__
    except:
        pass

def show_security_analysis_page():
    """CICIDS2017 ë³´ì•ˆ ì´ìƒ íƒì§€ ë¶„ì„ í˜ì´ì§€"""
    st.header("ğŸ”’ CICIDS2017 ë„¤íŠ¸ì›Œí¬ ì´ìƒ íƒì§€ ë¶„ì„")
    
    # ë³´ì•ˆ ë¶„ì„ ì†Œê°œ
    with st.expander("ğŸ¤” ì™œ ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ ë¶„ì„ì´ ì¤‘ìš”í• ê¹Œìš”?", expanded=True):
        st.markdown("""
        ### ğŸ¯ ì‹¤ë¬´ì—ì„œì˜ ë³´ì•ˆ ì´ìƒ íƒì§€
        
        **ê¸ˆìœµê¶Œ SIì—ì„œ í•µì‹¬ ì—…ë¬´:**
        - **ì‹¤ì‹œê°„ ì‚¬ê¸° ê±°ë˜ íƒì§€**: ê³ ê°ì˜ ì´ìƒ ê±°ë˜ íŒ¨í„´ ì¦‰ì‹œ ê°ì§€
        - **ë‚´ë¶€ì ìœ„í˜‘ ëª¨ë‹ˆí„°ë§**: ì§ì›ì˜ ë¹„ì •ìƒì  ì‹œìŠ¤í…œ ì ‘ê·¼ íƒì§€
        - **DDoS ê³µê²© ëŒ€ì‘**: ëŒ€ëŸ‰ ê±°ë˜ ìš”ì²­ì˜ ì •ìƒ/ê³µê²© ì—¬ë¶€ íŒë³„
        
        **CICIDS2017 ë°ì´í„°ì…‹ì˜ íŠ¹ë³„í•¨:**
        - **ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½**: ìºë‚˜ë‹¤ ì‚¬ì´ë²„ë³´ì•ˆ ì—°êµ¬ì†Œì—ì„œ 5ì¼ê°„ ì‹¤ì œ ìˆ˜ì§‘
        - **ìµœì‹  ê³µê²© íŒ¨í„´**: 2017ë…„ ë‹¹ì‹œ ìµœì‹  ê³µê²© ê¸°ë²•ë“¤ í¬í•¨
        - **280ë§Œ+ ì‹¤ì œ íŠ¸ë˜í”½**: 25ëª…ì˜ ì‹¤ì œ ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ ê¸°ë°˜
        
        ### ğŸ§  ê¸°ì¡´ ê³ ê° ë¶„ì„ê³¼ì˜ ì°¨ì´ì 
        
        **ê³ ê° ì„¸ë¶„í™” vs ë³´ì•ˆ íƒì§€:**
        - ê³ ê° ë¶„ì„: ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì„ ìœ„í•œ **ê¸°íšŒ ë°œê²¬**
        - ë³´ì•ˆ ë¶„ì„: ìœ„í—˜ì„ **ì‚¬ì „ì— ì°¨ë‹¨**í•˜ì—¬ ì†ì‹¤ ë°©ì§€
        
        **ë°ì´í„° íŠ¹ì„±ì˜ ì°¨ì´:**
        - ê³ ê° ë°ì´í„°: ë‚˜ì´, ì†Œë“, ì†Œë¹„ (3ê°œ íŠ¹ì„±)
        - ë„¤íŠ¸ì›Œí¬ ë°ì´í„°: íŒ¨í‚· í¬ê¸°, í”Œë¡œìš° ì§€ì†ì‹œê°„, í”„ë¡œí† ì½œ ë“± (78ê°œ íŠ¹ì„±)
        """)

    # ë©”ë‰´ ì„ íƒ
    analysis_menu = st.selectbox(
        "ë¶„ì„ ë‹¨ê³„ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        [
            "ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ",
            "ğŸ” ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íƒìƒ‰ì  ë¶„ì„", 
            "âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„",
            "ğŸ§ª ë²„íŠ¼ ë™ì‘ í…ŒìŠ¤íŠ¸",  # ìƒˆë¡œ ì¶”ê°€
            "ğŸ§  ë”¥ëŸ¬ë‹ ì´ìƒ íƒì§€ ëª¨ë¸",
            "ğŸ“Š ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸",
            "ğŸ¯ ì¢…í•© ì„±ëŠ¥ í‰ê°€"
        ]
    )

    if analysis_menu == "ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ":
        show_data_download_section()
    elif analysis_menu == "ğŸ” ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íƒìƒ‰ì  ë¶„ì„":
        show_exploratory_analysis_section()
    elif analysis_menu == "âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„":
        show_attack_pattern_analysis()
    elif analysis_menu == "ğŸ§ª ë²„íŠ¼ ë™ì‘ í…ŒìŠ¤íŠ¸":
        test_button_functionality()  # ìƒˆë¡œ ì¶”ê°€
    elif analysis_menu == "ğŸ§  ë”¥ëŸ¬ë‹ ì´ìƒ íƒì§€ ëª¨ë¸":
        show_deep_learning_detection()
    elif analysis_menu == "ğŸ“Š ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸":
        show_real_time_prediction()
    elif analysis_menu == "ğŸ¯ ì¢…í•© ì„±ëŠ¥ í‰ê°€":
        show_comprehensive_evaluation()


def show_data_download_section():
    """ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ì„¹ì…˜"""
    # í™•ì‹¤í•œ pandas import ë³´ì¥
    import pandas as pd
    import numpy as np
    
    st.subheader("ğŸ“¥ CICIDS2017 ë°ì´í„°ì…‹ ì¤€ë¹„")
    
    # ğŸ” ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
    with st.expander("ğŸ”§ í˜„ì¬ ì„¸ì…˜ ìƒíƒœ ë””ë²„ê¹…"):
        st.write("**ì„¸ì…˜ ìƒíƒœ í‚¤ë“¤:**", list(st.session_state.keys()))
        
        if 'cicids_data' in st.session_state:
            data = st.session_state.cicids_data
            st.write(f"**í˜„ì¬ ë°ì´í„° í¬ê¸°:** {len(data)}")
            if 'Label' in data.columns:
                attack_count = (data['Label'] != 'BENIGN').sum()
                attack_ratio = attack_count / len(data) * 100
                st.write(f"**í˜„ì¬ ê³µê²© ë°ì´í„°:** {attack_count}ê°œ ({attack_ratio:.1f}%)")
            else:
                st.write("**ë¼ë²¨ ì»¬ëŸ¼ ì—†ìŒ**")
        else:
            st.write("**cicids_data ì—†ìŒ**")
            
        enhanced_flag = st.session_state.get('enhanced_data_generated', False)
        st.write(f"**í–¥ìƒëœ ë°ì´í„° í”Œë˜ê·¸:** {enhanced_flag}")
        
        # ğŸš¨ ê°•ì œ ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
        st.markdown("---")
        st.write("**ğŸš¨ ë¬¸ì œ í•´ê²°ìš© ê°•ì œ ì´ˆê¸°í™”:**")
        if st.button("ğŸ’¥ ëª¨ë“  ì„¸ì…˜ ë°ì´í„° ì‚­ì œ", key="clear_session_button"):
            # ê´€ë ¨ ì„¸ì…˜ í‚¤ë“¤ ëª¨ë‘ ì‚­ì œ
            keys_to_delete = ['cicids_data', 'enhanced_data_generated', 'file_load_attempted']
            for key in keys_to_delete:
                if key in st.session_state:
                    del st.session_state[key]
            st.success("âœ… ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ! ì´ì œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
            # ìƒˆë¡œê³ ì¹¨ ì‹œë„ (ë²„ì „ í˜¸í™˜ì„±)
            try:
                st.rerun()
            except AttributeError:
                st.info("ğŸ”„ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤! ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨(F5)ì„ í•˜ì„¸ìš”.")
            except Exception:
                st.info("ğŸ”„ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤! ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨(F5)ì„ í•˜ì„¸ìš”.")
    
    st.info("""
    **ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë°©ë²•:**
    
    **ì˜µì…˜ 1: ê³µì‹ ì†ŒìŠ¤ (ê¶Œì¥)**
    1. https://www.unb.ca/cic/datasets/ids-2017.html ë°©ë¬¸
    2. "MachineLearningCSV.zip" ë‹¤ìš´ë¡œë“œ (ì•½ 2.8GB)
    3. ì••ì¶• í•´ì œ í›„ CSV íŒŒì¼ë“¤ì„ `data/cicids2017/` í´ë”ì— ì €ì¥
    
    **ì˜µì…˜ 2: Kaggle (í¸ë¦¬í•¨)**
    1. https://www.kaggle.com/datasets/dhoogla/cicids2017 ë°©ë¬¸
    2. "Download" í´ë¦­í•˜ì—¬ ë‹¤ìš´ë¡œë“œ
    3. ì••ì¶• í•´ì œ í›„ CSV íŒŒì¼ë“¤ì„ `data/cicids2017/` í´ë”ì— ì €ì¥
    
    **ì˜ˆìƒ íŒŒì¼ êµ¬ì¡°:**
    ```
    data/cicids2017/
    â”œâ”€â”€ Monday-WorkingHours.pcap_ISCX.csv      (ì •ìƒ íŠ¸ë˜í”½)
    â”œâ”€â”€ Tuesday-WorkingHours.pcap_ISCX.csv     (ë¸Œë£¨íŠ¸í¬ìŠ¤)
    â”œâ”€â”€ Wednesday-workingHours.pcap_ISCX.csv   (DoS/DDoS)
    â”œâ”€â”€ Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv
    â”œâ”€â”€ Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv
    â”œâ”€â”€ Friday-WorkingHours-Morning.pcap_ISCX.csv
    â”œâ”€â”€ Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv
    â””â”€â”€ Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv
    ```
    """)
    
    # ğŸ” ì„¸ì…˜ ìƒíƒœ ìš°ì„  í™•ì¸
    if 'cicids_data' in st.session_state and st.session_state.get('enhanced_data_generated', False):
        # ì´ë¯¸ í–¥ìƒëœ ë°ì´í„°ê°€ ìƒì„±ë˜ì–´ ìˆëŠ” ê²½ìš°
        data = st.session_state.cicids_data
        total_count = len(data)
        attack_count = (data['Label'] != 'BENIGN').sum()
        attack_ratio = attack_count / total_count * 100
        
        st.success(f"âœ… í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ì´ë¯¸ ì¤€ë¹„ë¨! ì´ {total_count:,}ê°œ (ê³µê²© {attack_count:,}ê°œ, {attack_ratio:.1f}%)")
        
        # ë¼ë²¨ ë¶„í¬ í‘œì‹œ
        label_counts = data['Label'].value_counts()
        import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
        label_df = pd.DataFrame({
            'ë¼ë²¨': label_counts.index,
            'ê°œìˆ˜': label_counts.values,
            'ë¹„ìœ¨': (label_counts.values / total_count * 100).round(2)
        })
        st.dataframe(label_df, use_container_width=True)
        
        st.info("ğŸš€ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")
        return
    
    # ğŸš¨ ê°•ì œë¡œ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ìš°ì„  (íŒŒì¼ ë¡œë“œ ë¬¸ì œ ìš°íšŒ)
    st.warning("âš ï¸ ì‹¤ì œ íŒŒì¼ ë¡œë“œ ì‹œ ë°ì´í„° ë¬¸ì œê°€ ì§€ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
    st.info("ğŸ’¡ ì•ˆì •ì ì¸ ë¶„ì„ì„ ìœ„í•´ í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")
    
    # ğŸ† ì¦‰ì‹œ ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ê°€ì¥ ìƒë‹¨ ë°°ì¹˜)
    st.markdown("### ğŸš€ ê¶Œì¥: ì¦‰ì‹œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
    
    emergency_button = st.button("ğŸ† í–¥ìƒëœ ê³µê²© ë°ì´í„° 60% ì¦‰ì‹œ ìƒì„±", key="priority_emergency_button")
    if emergency_button:
        st.write("ğŸš¨ ê¸´ê¸‰ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹œì‘!")
        
        # ì§ì ‘ ë°ì´í„° ìƒì„± ë° ì €ì¥ (ëª¨ë“  í•¨ìˆ˜ í˜¸ì¶œ ìš°íšŒ)
        import numpy as np
        import pandas as pd
        np.random.seed(42)
        
        # ê°„ë‹¨í•œ ê³µê²© ë°ì´í„° ìƒì„± â†’ í™•ì¥ëœ ë°ì´í„°ë¡œ ë³€ê²½
        emergency_data = {
            # ê¸°ë³¸ í”Œë¡œìš° íŠ¹ì„±
            'Flow_Duration': list(np.random.exponential(100000, 4000)) + list(np.random.exponential(10000, 3000)) + list(np.random.exponential(150000, 1500)) + list(np.random.exponential(30000, 1000)) + list(np.random.exponential(5000, 500)),
            'Total_Fwd_Packets': list(np.random.poisson(15, 4000)) + list(np.random.poisson(200, 3000)) + list(np.random.poisson(30, 1500)) + list(np.random.poisson(80, 1000)) + list(np.random.poisson(10, 500)),
            'Total_Backward_Packets': list(np.random.poisson(12, 4000)) + list(np.random.poisson(5, 3000)) + list(np.random.poisson(25, 1500)) + list(np.random.poisson(8, 1000)) + list(np.random.poisson(2, 500)),
            
            # íŒ¨í‚· ê¸¸ì´ íŠ¹ì„±
            'Total_Length_of_Fwd_Packets': list(np.random.normal(800, 300, 4000)) + list(np.random.normal(10000, 2000, 3000)) + list(np.random.normal(3000, 800, 1500)) + list(np.random.normal(2000, 500, 1000)) + list(np.random.normal(400, 150, 500)),
            'Total_Length_of_Bwd_Packets': list(np.random.normal(600, 200, 4000)) + list(np.random.normal(200, 100, 3000)) + list(np.random.normal(1500, 400, 1500)) + list(np.random.normal(400, 150, 1000)) + list(np.random.normal(100, 50, 500)),
            
            'Fwd_Packet_Length_Max': list(np.random.normal(1200, 400, 4000)) + list(np.random.normal(1500, 100, 3000)) + list(np.random.normal(1400, 200, 1500)) + list(np.random.normal(800, 200, 1000)) + list(np.random.normal(200, 60, 500)),
            'Fwd_Packet_Length_Min': list(np.random.normal(60, 20, 4000)) + list(np.random.normal(64, 10, 3000)) + list(np.random.normal(200, 50, 1500)) + list(np.random.normal(40, 15, 1000)) + list(np.random.normal(40, 10, 500)),
            'Fwd_Packet_Length_Mean': list(np.random.normal(400, 150, 4000)) + list(np.random.normal(80, 20, 3000)) + list(np.random.normal(500, 100, 1500)) + list(np.random.normal(80, 30, 1000)) + list(np.random.normal(60, 20, 500)),
            
            'Bwd_Packet_Length_Max': list(np.random.normal(1000, 300, 4000)) + list(np.random.normal(150, 50, 3000)) + list(np.random.normal(800, 150, 1500)) + list(np.random.normal(300, 100, 1000)) + list(np.random.normal(100, 30, 500)),
            'Bwd_Packet_Length_Min': list(np.random.normal(50, 15, 4000)) + list(np.random.normal(40, 10, 3000)) + list(np.random.normal(100, 30, 1500)) + list(np.random.normal(30, 10, 1000)) + list(np.random.normal(20, 5, 500)),
            'Bwd_Packet_Length_Mean': list(np.random.normal(300, 100, 4000)) + list(np.random.normal(60, 20, 3000)) + list(np.random.normal(250, 80, 1500)) + list(np.random.normal(60, 20, 1000)) + list(np.random.normal(40, 15, 500)),
            
            # í”Œë¡œìš° ì†ë„ íŠ¹ì„±
            'Flow_Bytes/s': list(np.random.normal(2000, 1000, 4000)) + list(np.random.normal(50000, 15000, 3000)) + list(np.random.normal(4000, 1500, 1500)) + list(np.random.normal(8000, 2000, 1000)) + list(np.random.normal(1000, 300, 500)),
            'Flow_Packets/s': list(np.random.normal(20, 10, 4000)) + list(np.random.normal(500, 150, 3000)) + list(np.random.normal(25, 10, 1500)) + list(np.random.normal(80, 20, 1000)) + list(np.random.normal(30, 10, 500)),
            
            # IAT (Inter-Arrival Time) íŠ¹ì„±
            'Flow_IAT_Mean': list(np.random.exponential(50000, 4000)) + list(np.random.exponential(1000, 3000)) + list(np.random.exponential(30000, 1500)) + list(np.random.exponential(3000, 1000)) + list(np.random.exponential(8000, 500)),
            'Flow_IAT_Std': list(np.random.exponential(25000, 4000)) + list(np.random.exponential(500, 3000)) + list(np.random.exponential(15000, 1500)) + list(np.random.exponential(1500, 1000)) + list(np.random.exponential(4000, 500)),
            
            'Fwd_IAT_Total': list(np.random.exponential(200000, 4000)) + list(np.random.exponential(5000, 3000)) + list(np.random.exponential(100000, 1500)) + list(np.random.exponential(15000, 1000)) + list(np.random.exponential(3000, 500)),
            'Fwd_IAT_Mean': list(np.random.exponential(20000, 4000)) + list(np.random.exponential(50, 3000)) + list(np.random.exponential(8000, 1500)) + list(np.random.exponential(300, 1000)) + list(np.random.exponential(800, 500)),
            
            'Bwd_IAT_Total': list(np.random.exponential(150000, 4000)) + list(np.random.exponential(20000, 3000)) + list(np.random.exponential(80000, 1500)) + list(np.random.exponential(25000, 1000)) + list(np.random.exponential(8000, 500)),
            'Bwd_IAT_Mean': list(np.random.exponential(15000, 4000)) + list(np.random.exponential(2000, 3000)) + list(np.random.exponential(6000, 1500)) + list(np.random.exponential(2500, 1000)) + list(np.random.exponential(4000, 500)),
            
            # ë¼ë²¨ (ë‹¤ì–‘í•œ ê³µê²© ìœ í˜•)
            'Label': (['BENIGN'] * 4000 + 
                     ['DDoS'] * 3000 + 
                     ['Web Attack'] * 1500 + 
                     ['Brute Force'] * 1000 + 
                     ['PortScan'] * 500)
        }
        
        emergency_df = pd.DataFrame(emergency_data)
        emergency_df = emergency_df.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # ğŸš¨ ê°•ì œë¡œ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆ ë°ì´í„° ì €ì¥
        if 'cicids_data' in st.session_state:
            del st.session_state.cicids_data
        
        st.session_state.cicids_data = emergency_df
        st.session_state.enhanced_data_generated = True
        
        # ê²€ì¦
        attacks = (emergency_df['Label'] != 'BENIGN').sum()
        ratio = attacks / len(emergency_df) * 100
        
        st.success(f"âœ… ê°•ì œ ë°ì´í„° ìƒì„± ì„±ê³µ! ê³µê²© {attacks}ê°œ ({ratio:.1f}%)")
        st.balloons()
        
        # ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ
        label_counts = emergency_df['Label'].value_counts()
        result_df = pd.DataFrame({
            'ë¼ë²¨': label_counts.index,
            'ê°œìˆ˜': label_counts.values,
            'ë¹„ìœ¨': (label_counts.values / len(emergency_df) * 100).round(2)
        })
        st.dataframe(result_df, use_container_width=True)
        
        st.success("ğŸ‰ ì„±ê³µ! ì´ì œ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì„¸ìš”!")
        
        # ìƒˆë¡œê³ ì¹¨ ì‹œë„ (ë²„ì „ í˜¸í™˜ì„±)
        try:
            st.rerun()
        except AttributeError:
            st.info("ğŸ”„ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤! ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨(F5)ì„ í•˜ê±°ë‚˜ ë‹¤ë¥¸ ë©”ë‰´ë¡œ ì´ë™í›„ ë‹¤ì‹œ ëŒì•„ì˜¤ì„¸ìš”.")
        except Exception:
            st.info("ğŸ”„ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤! ë¸Œë¼ìš°ì € ìƒˆë¡œê³ ì¹¨(F5)ì„ í•˜ê±°ë‚˜ ë‹¤ë¥¸ ë©”ë‰´ë¡œ ì´ë™í›„ ë‹¤ì‹œ ëŒì•„ì˜¤ì„¸ìš”.")
        
        return  # ì—¬ê¸°ì„œ í•¨ìˆ˜ ì¢…ë£Œ (íŒŒì¼ ë¡œë“œ ë¶€ë¶„ ì™„ì „ ìš°íšŒ)
    
    st.markdown("---")
    st.markdown("### ğŸ“ ì‹¤ì œ íŒŒì¼ ë¡œë“œ (ì°¸ê³ ìš©)")
    st.info("ì‹¤ì œ íŒŒì¼ì´ ìˆì–´ë„ Monday íŒŒì¼ì€ ê³µê²© ë°ì´í„°ê°€ 0%ì…ë‹ˆë‹¤. ìœ„ì˜ ìƒ˜í”Œ ë°ì´í„° ìƒì„±ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    
    # íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„  
    data_status = check_cicids_data_availability()
    
    if data_status["available"]:
        st.success(f"âœ… CICIDS2017 ë°ì´í„° ë°œê²¬! ì´ {len(data_status['files'])}ê°œ íŒŒì¼")
        
        # íŒŒì¼ë³„ ì •ë³´ í‘œì‹œ
        file_info = []
        for file_path in data_status['files']:
            try:
                import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
                df = pd.read_csv(file_path, nrows=5)  # ìƒ˜í”Œë§Œ ë¡œë“œ
                file_info.append({
                    "íŒŒì¼ëª…": file_path.split('/')[-1],
                    "ì˜ˆìƒ ë ˆì½”ë“œ ìˆ˜": "í™•ì¸ ì¤‘...",
                    "ì»¬ëŸ¼ ìˆ˜": len(df.columns),
                    "ì£¼ìš” ë¼ë²¨": ", ".join(df['Label'].unique()[:3]) if 'Label' in df.columns else "ë¼ë²¨ ì—†ìŒ"
                })
            except Exception as e:
                file_info.append({
                    "íŒŒì¼ëª…": file_path.split('/')[-1], 
                    "ìƒíƒœ": f"ì˜¤ë¥˜: {str(e)[:50]}...",
                    "ì»¬ëŸ¼ ìˆ˜": "N/A",
                    "ì£¼ìš” ë¼ë²¨": "N/A"
                })
        
        # ì—¬ê¸°ì„œ pandas ëª…ì‹œì  import ì¶”ê°€
        import pandas as pd
        st.dataframe(pd.DataFrame(file_info), use_container_width=True)
        
        if st.button("ğŸš€ ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„ ì‹œì‘"):
            load_and_analyze_cicids_data(data_status['files'])
            
    else:
        st.warning("âš ï¸ CICIDS2017 ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì˜µì…˜
        # ğŸ† ë””ë²„ê¹…ìš© ê°•ì œ ë°ì´í„° ìƒì„± ë²„íŠ¼
        st.markdown("### ğŸš¨ ê¸´ê¸‰ ë¬¸ì œ í•´ê²°ìš©")
        
        emergency_button = st.button("ğŸ”¥ ê¸´ê¸‰ ê³µê²© ë°ì´í„° ìƒì„±", key="emergency_data_button")
        if emergency_button:
            st.write("ğŸš¨ ê¸´ê¸‰ ë²„íŠ¼ í´ë¦­ ê°ì§€!")
            
            # ì§ì ‘ ë°ì´í„° ìƒì„± ë° ì €ì¥ (í•¨ìˆ˜ í˜¸ì¶œ ì—†ì´)
            import numpy as np
            import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
            np.random.seed(42)
            
            # ê°„ë‹¨í•œ ê³µê²© ë°ì´í„° ìƒì„±
            emergency_data = {
                'Flow_Duration': list(np.random.exponential(100000, 4000)) + list(np.random.exponential(10000, 6000)),
                'Total_Fwd_Packets': list(np.random.poisson(15, 4000)) + list(np.random.poisson(200, 6000)),
                'Flow_Bytes/s': list(np.random.normal(2000, 1000, 4000)) + list(np.random.normal(50000, 15000, 6000)),
                'Label': ['BENIGN'] * 4000 + ['DDoS'] * 6000
            }
            import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
            emergency_df = pd.DataFrame(emergency_data)
            emergency_df = emergency_df.sample(frac=1, random_state=42).reset_index(drop=True)
            
            # ì„¸ì…˜ì— ì§ì ‘ ì €ì¥
            st.session_state.cicids_data = emergency_df
            st.session_state.enhanced_data_generated = True
            
            # ê²€ì¦
            attacks = (emergency_df['Label'] != 'BENIGN').sum()
            ratio = attacks / len(emergency_df) * 100
            
            st.success(f"âœ… ê¸´ê¸‰ ë°ì´í„° ìƒì„± ì„±ê³µ! ê³µê²© {attacks}ê°œ ({ratio:.1f}%)")
            st.balloons()
            
            try:
                st.rerun()
            except:
                st.experimental_rerun()


def check_cicids_data_availability():
    """CICIDS2017 ë°ì´í„° íŒŒì¼ ì¡´ì¬ í™•ì¸"""
    import os
    import glob
    
    data_dir = "/Users/greenpianorabbit/Documents/Development/customer-segmentation/data/cicids2017"
    
    # ê°€ëŠ¥í•œ íŒŒì¼ íŒ¨í„´ë“¤
    patterns = [
        "*.csv",
        "*ISCX.csv", 
        "*cicids*.csv",
        "*CIC*.csv"
    ]
    
    files = []
    for pattern in patterns:
        files.extend(glob.glob(os.path.join(data_dir, pattern)))
    
    return {
        "available": len(files) > 0,
        "files": files,
        "count": len(files)
    }


def generate_cicids_sample_data():
    """CICIDS2017 ìŠ¤íƒ€ì¼ ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    np.random.seed(42)
    
    # ì£¼ìš” ë„¤íŠ¸ì›Œí¬ íŠ¹ì„±ë“¤ ì‹œë®¬ë ˆì´ì…˜
    n_samples = 10000
    
    # ì •ìƒ íŠ¸ë˜í”½ (70%)
    normal_samples = int(n_samples * 0.7)
    normal_data = {
        'Flow_Duration': np.random.exponential(100000, normal_samples),
        'Total_Fwd_Packets': np.random.poisson(15, normal_samples),
        'Total_Backward_Packets': np.random.poisson(12, normal_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(800, 300, normal_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(600, 200, normal_samples),
        'Fwd_Packet_Length_Max': np.random.normal(1200, 400, normal_samples),
        'Fwd_Packet_Length_Min': np.random.normal(60, 20, normal_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(400, 150, normal_samples),
        'Bwd_Packet_Length_Max': np.random.normal(1000, 300, normal_samples),
        'Bwd_Packet_Length_Min': np.random.normal(50, 15, normal_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(300, 100, normal_samples),
        'Flow_Bytes/s': np.random.normal(2000, 1000, normal_samples),
        'Flow_Packets/s': np.random.normal(20, 10, normal_samples),
        'Flow_IAT_Mean': np.random.exponential(50000, normal_samples),
        'Flow_IAT_Std': np.random.exponential(25000, normal_samples),
        'Fwd_IAT_Total': np.random.exponential(200000, normal_samples),
        'Fwd_IAT_Mean': np.random.exponential(20000, normal_samples),
        'Bwd_IAT_Total': np.random.exponential(150000, normal_samples),
        'Bwd_IAT_Mean': np.random.exponential(15000, normal_samples),
        'Label': ['BENIGN'] * normal_samples
    }
    
    # DDoS ê³µê²© (15%)
    ddos_samples = int(n_samples * 0.15)
    ddos_data = {
        'Flow_Duration': np.random.exponential(10000, ddos_samples),  # ì§§ì€ ì§€ì†ì‹œê°„
        'Total_Fwd_Packets': np.random.poisson(200, ddos_samples),   # ëŒ€ëŸ‰ íŒ¨í‚·
        'Total_Backward_Packets': np.random.poisson(5, ddos_samples),# ì ì€ ì‘ë‹µ
        'Total_Length_of_Fwd_Packets': np.random.normal(10000, 2000, ddos_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(200, 100, ddos_samples),
        'Fwd_Packet_Length_Max': np.random.normal(1500, 100, ddos_samples),
        'Fwd_Packet_Length_Min': np.random.normal(64, 10, ddos_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(80, 20, ddos_samples),
        'Bwd_Packet_Length_Max': np.random.normal(150, 50, ddos_samples),
        'Bwd_Packet_Length_Min': np.random.normal(40, 10, ddos_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(60, 20, ddos_samples),
        'Flow_Bytes/s': np.random.normal(50000, 15000, ddos_samples), # ë§¤ìš° ë†’ì€ ë°”ì´íŠ¸ìœ¨
        'Flow_Packets/s': np.random.normal(500, 150, ddos_samples),   # ë§¤ìš° ë†’ì€ íŒ¨í‚·ìœ¨
        'Flow_IAT_Mean': np.random.exponential(1000, ddos_samples),   # ë§¤ìš° ì§§ì€ ê°„ê²©
        'Flow_IAT_Std': np.random.exponential(500, ddos_samples),
        'Fwd_IAT_Total': np.random.exponential(5000, ddos_samples),
        'Fwd_IAT_Mean': np.random.exponential(50, ddos_samples),
        'Bwd_IAT_Total': np.random.exponential(20000, ddos_samples),
        'Bwd_IAT_Mean': np.random.exponential(2000, ddos_samples),
        'Label': ['DDoS'] * ddos_samples
    }
    
    # ì›¹ ê³µê²© (8%)
    web_attack_samples = int(n_samples * 0.08)
    web_attack_data = {
        'Flow_Duration': np.random.exponential(150000, web_attack_samples),
        'Total_Fwd_Packets': np.random.poisson(30, web_attack_samples),
        'Total_Backward_Packets': np.random.poisson(25, web_attack_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(3000, 800, web_attack_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(1500, 400, web_attack_samples),
        'Fwd_Packet_Length_Max': np.random.normal(1400, 200, web_attack_samples),
        'Fwd_Packet_Length_Min': np.random.normal(200, 50, web_attack_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(500, 100, web_attack_samples),
        'Bwd_Packet_Length_Max': np.random.normal(800, 150, web_attack_samples),
        'Bwd_Packet_Length_Min': np.random.normal(100, 30, web_attack_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(250, 80, web_attack_samples),
        'Flow_Bytes/s': np.random.normal(4000, 1500, web_attack_samples),
        'Flow_Packets/s': np.random.normal(25, 10, web_attack_samples),
        'Flow_IAT_Mean': np.random.exponential(30000, web_attack_samples),
        'Flow_IAT_Std': np.random.exponential(15000, web_attack_samples),
        'Fwd_IAT_Total': np.random.exponential(100000, web_attack_samples),
        'Fwd_IAT_Mean': np.random.exponential(8000, web_attack_samples),
        'Bwd_IAT_Total': np.random.exponential(80000, web_attack_samples),
        'Bwd_IAT_Mean': np.random.exponential(6000, web_attack_samples),
        'Label': ['Web Attack'] * web_attack_samples
    }
    
    # ë¸Œë£¨íŠ¸í¬ìŠ¤ (4%)
    brute_force_samples = int(n_samples * 0.04)
    brute_force_data = {
        'Flow_Duration': np.random.exponential(30000, brute_force_samples),
        'Total_Fwd_Packets': np.random.poisson(80, brute_force_samples),
        'Total_Backward_Packets': np.random.poisson(8, brute_force_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(2000, 500, brute_force_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(400, 150, brute_force_samples),
        'Fwd_Packet_Length_Max': np.random.normal(800, 200, brute_force_samples),
        'Fwd_Packet_Length_Min': np.random.normal(40, 15, brute_force_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(80, 30, brute_force_samples),
        'Bwd_Packet_Length_Max': np.random.normal(300, 100, brute_force_samples),
        'Bwd_Packet_Length_Min': np.random.normal(30, 10, brute_force_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(60, 20, brute_force_samples),
        'Flow_Bytes/s': np.random.normal(8000, 2000, brute_force_samples),
        'Flow_Packets/s': np.random.normal(80, 20, brute_force_samples),
        'Flow_IAT_Mean': np.random.exponential(3000, brute_force_samples),
        'Flow_IAT_Std': np.random.exponential(1500, brute_force_samples),
        'Fwd_IAT_Total': np.random.exponential(15000, brute_force_samples),
        'Fwd_IAT_Mean': np.random.exponential(300, brute_force_samples),
        'Bwd_IAT_Total': np.random.exponential(25000, brute_force_samples),
        'Bwd_IAT_Mean': np.random.exponential(2500, brute_force_samples),
        'Label': ['Brute Force'] * brute_force_samples
    }
    
    # í¬íŠ¸ìŠ¤ìº” (3%)
    port_scan_samples = n_samples - normal_samples - ddos_samples - web_attack_samples - brute_force_samples
    port_scan_data = {
        'Flow_Duration': np.random.exponential(5000, port_scan_samples),
        'Total_Fwd_Packets': np.random.poisson(10, port_scan_samples),
        'Total_Backward_Packets': np.random.poisson(2, port_scan_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(400, 150, port_scan_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(100, 50, port_scan_samples),
        'Fwd_Packet_Length_Max': np.random.normal(200, 60, port_scan_samples),
        'Fwd_Packet_Length_Min': np.random.normal(40, 10, port_scan_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(60, 20, port_scan_samples),
        'Bwd_Packet_Length_Max': np.random.normal(100, 30, port_scan_samples),
        'Bwd_Packet_Length_Min': np.random.normal(20, 5, port_scan_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(40, 15, port_scan_samples),
        'Flow_Bytes/s': np.random.normal(1000, 300, port_scan_samples),
        'Flow_Packets/s': np.random.normal(30, 10, port_scan_samples),
        'Flow_IAT_Mean': np.random.exponential(8000, port_scan_samples),
        'Flow_IAT_Std': np.random.exponential(4000, port_scan_samples),
        'Fwd_IAT_Total': np.random.exponential(3000, port_scan_samples),
        'Fwd_IAT_Mean': np.random.exponential(800, port_scan_samples),
        'Bwd_IAT_Total': np.random.exponential(8000, port_scan_samples),
        'Bwd_IAT_Mean': np.random.exponential(4000, port_scan_samples),
        'Label': ['PortScan'] * port_scan_samples
    }
    
    # ëª¨ë“  ë°ì´í„° ê²°í•©
    all_data = {}
    for key in normal_data.keys():
        all_data[key] = (
            list(normal_data[key]) + 
            list(ddos_data[key]) + 
            list(web_attack_data[key]) + 
            list(brute_force_data[key]) + 
            list(port_scan_data[key])
        )
    
    df = pd.DataFrame(all_data)
    
    # ë°ì´í„° ì •ë¦¬
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    df[numeric_columns] = df[numeric_columns].abs()
    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)
    
    # ë””ë²„ê¹… ë¡œê·¸ - ìµœì¢… ê²°ê³¼
    if hasattr(st, 'write'):
        attack_count = (df['Label'] != 'BENIGN').sum()
        attack_ratio = attack_count / len(df) * 100
        st.write(f"ğŸ” ë°ì´í„° ìƒì„± ì™„ë£Œ: ì´ {len(df)}ê°œ, ê³µê²© {attack_count}ê°œ ({attack_ratio:.1f}%)")
    
    return df


def show_exploratory_analysis_section():
    """ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íƒìƒ‰ì  ë¶„ì„"""
    st.subheader("ğŸ” ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íŒ¨í„´ ë¶„ì„")
    
    # ë°ì´í„° ë¡œë“œ í™•ì¸
    if 'cicids_data' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
        return
    
    data = st.session_state.cicids_data
    st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ë ˆì½”ë“œ, {len(data.columns)}ê°œ íŠ¹ì„±")
    
    # ê¸°ë³¸ í†µê³„
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì´ íŠ¸ë˜í”½ ìˆ˜", f"{len(data):,}")
    with col2:
        normal_count = (data['Label'] == 'BENIGN').sum()
        st.metric("ì •ìƒ íŠ¸ë˜í”½", f"{normal_count:,}")
    with col3:
        attack_count = len(data) - normal_count
        st.metric("ê³µê²© íŠ¸ë˜í”½", f"{attack_count:,}")
    with col4:
        attack_ratio = attack_count / len(data) * 100
        st.metric("ê³µê²© ë¹„ìœ¨", f"{attack_ratio:.1f}%")
    
    # ê³µê²© ìœ í˜•ë³„ ë¶„í¬
    st.subheader("ğŸ“Š ê³µê²© ìœ í˜•ë³„ ë¶„í¬")
    
    label_counts = data['Label'].value_counts()
    
    col1, col2 = st.columns(2)
    
    with col1:
        # íŒŒì´ ì°¨íŠ¸
        fig = px.pie(
            values=label_counts.values,
            names=label_counts.index,
            title="ê³µê²© ìœ í˜•ë³„ ë¶„í¬",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ë§‰ëŒ€ ì°¨íŠ¸ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        fig = px.bar(
            x=label_counts.index,
            y=label_counts.values,
            title="ê³µê²© ìœ í˜•ë³„ ê°œìˆ˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)",
            log_y=True,
            color=label_counts.values,
            color_continuous_scale='Viridis'
        )
        fig.update_layout(xaxis_title="ê³µê²© ìœ í˜•", yaxis_title="ê°œìˆ˜ (ë¡œê·¸)")
        st.plotly_chart(fig, use_container_width=True)
    
    # ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ë¶„í¬ ë¶„ì„
    st.subheader("ğŸ“ˆ ì£¼ìš” ë„¤íŠ¸ì›Œí¬ íŠ¹ì„± ë¶„í¬")
    
    # ë¶„ì„í•  íŠ¹ì„± ì„ íƒ
    numeric_features = [col for col in data.columns if col != 'Label' and data[col].dtype in ['int64', 'float64']]
    selected_features = st.multiselect(
        "ë¶„ì„í•  íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”:",
        numeric_features,
        default=numeric_features[:4]  # ì²˜ìŒ 4ê°œ ê¸°ë³¸ ì„ íƒ
    )
    
    if selected_features:
        # ì •ìƒ vs ê³µê²© íŠ¸ë˜í”½ ë¹„êµ
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=selected_features[:4],
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        for i, feature in enumerate(selected_features[:4]):
            row = i // 2 + 1
            col = i % 2 + 1
            
            # ì •ìƒ íŠ¸ë˜í”½ ë¶„í¬
            normal_data_subset = data[data['Label'] == 'BENIGN'][feature]
            attack_data_subset = data[data['Label'] != 'BENIGN'][feature]
            
            fig.add_histogram(
                x=normal_data_subset, 
                name=f'{feature} - ì •ìƒ',
                row=row, col=col,
                opacity=0.7,
                nbinsx=50
            )
            fig.add_histogram(
                x=attack_data_subset,
                name=f'{feature} - ê³µê²©', 
                row=row, col=col,
                opacity=0.7,
                nbinsx=50
            )
        
        fig.update_layout(height=600, title_text="ì •ìƒ vs ê³µê²© íŠ¸ë˜í”½ íŠ¹ì„± ë¶„í¬")
        st.plotly_chart(fig, use_container_width=True)
    
    # ìƒê´€ê´€ê³„ ë¶„ì„
    st.subheader("ğŸ”— íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ ë¶„ì„")
    
    if len(selected_features) >= 2:
        # ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚°
        corr_matrix = data[selected_features].corr()
        
        # íˆíŠ¸ë§µìœ¼ë¡œ ì‹œê°í™”
        fig = px.imshow(
            corr_matrix,
            title="íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ",
            color_continuous_scale='RdBu',
            aspect="auto"
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
        
        # ë†’ì€ ìƒê´€ê´€ê³„ íŠ¹ì„± ìŒ ì°¾ê¸°
        high_corr_pairs = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:  # ë†’ì€ ìƒê´€ê´€ê³„ ì„ê³„ê°’
                    high_corr_pairs.append({
                        'íŠ¹ì„± 1': corr_matrix.columns[i],
                        'íŠ¹ì„± 2': corr_matrix.columns[j],
                        'ìƒê´€ê³„ìˆ˜': round(corr_val, 3)
                    })
        
        if high_corr_pairs:
            st.write("**ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì´ëŠ” íŠ¹ì„± ìŒë“¤:**")
            st.dataframe(pd.DataFrame(high_corr_pairs), use_container_width=True)
        else:
            st.info("ì„ íƒëœ íŠ¹ì„±ë“¤ ê°„ì— ê°•í•œ ìƒê´€ê´€ê³„(|r| > 0.7)ëŠ” ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def show_attack_pattern_analysis():
    """ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„"""
    st.subheader("âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„")
    
    if 'cicids_data' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        # ì¦‰ì‹œ ë°ì´í„° ìƒì„± ì˜µì…˜ ì œê³µ
        if st.button("ğŸ† ì¦‰ì‹œ í›ˆë ¨ìš© ë°ì´í„° ìƒì„±", key="instant_data_generation"):
            generate_and_save_enhanced_data()
        return
    
    data = st.session_state.cicids_data
    
    # ê³µê²© ë°ì´í„° ë¹„ìœ¨ ì²´í¬
    total_count = len(data)
    attack_count = (data['Label'] != 'BENIGN').sum()
    attack_ratio = attack_count / total_count * 100
    
    # ê³µê²© ë°ì´í„°ê°€ ì—¬ì „íˆ ë‚®ì€ ê²½ìš° ë¹ ë¥¸ í•´ê²°ì±… ì œê³µ
    if attack_ratio < 5:
        st.error(f"âŒ ê³µê²© ë°ì´í„° ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤ ({attack_ratio:.1f}%)")
        st.info("ğŸ’¡ ì˜ë¯¸ìˆëŠ” ê³µê²© ë¶„ì„ì„ ìœ„í•´ í–¥ìƒëœ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        
        if st.button("ğŸ† ì¦‰ì‹œ ê³µê²© ë°ì´í„° 60% ìƒì„±", key="fix_attack_data"):
            generate_and_save_enhanced_data()
        else:
            return
    
    # ê³µê²© ìœ í˜•ë³„ ìƒì„¸ ë¶„ì„
    attack_types = [label for label in data['Label'].unique() if label != 'BENIGN']
    
    if len(attack_types) == 0:
        st.error("âŒ ê³µê²© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ 'ê³µê²© ë°ì´í„° 60% ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        return
        
    selected_attack = st.selectbox("ë¶„ì„í•  ê³µê²© ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”:", ['ì „ì²´ ê³µê²©'] + attack_types)
    
    if selected_attack == 'ì „ì²´ ê³µê²©':
        attack_data = data[data['Label'] != 'BENIGN']
        attack_title = "ì „ì²´ ê³µê²©"
    else:
        attack_data = data[data['Label'] == selected_attack]
        attack_title = selected_attack
    
    normal_data = data[data['Label'] == 'BENIGN']
    
    st.info(f"**{attack_title}** ë¶„ì„ ì¤‘ - ê³µê²©: {len(attack_data)}ê°œ, ì •ìƒ: {len(normal_data)}ê°œ")
    
    # ì£¼ìš” ì°¨ë³„í™” íŠ¹ì„± ì°¾ê¸°
    st.subheader(f"ğŸ“Š {attack_title}ì˜ íŠ¹ì„±ì  íŒ¨í„´")
    
    numeric_features = [col for col in data.columns if col != 'Label' and data[col].dtype in ['int64', 'float64']]
    
    # ê° íŠ¹ì„±ë³„ë¡œ ì •ìƒê³¼ ê³µê²©ì˜ í‰ê· ê°’ ë¹„êµ
    feature_comparison = []
    for feature in numeric_features:
        normal_mean = normal_data[feature].mean()
        attack_mean = attack_data[feature].mean()
        
        if normal_mean != 0:
            ratio = attack_mean / normal_mean
            difference = abs(attack_mean - normal_mean)
            
            feature_comparison.append({
                'íŠ¹ì„±': feature,
                'ì •ìƒ í‰ê· ': round(normal_mean, 2),
                'ê³µê²© í‰ê· ': round(attack_mean, 2),
                'ë¹„ìœ¨ (ê³µê²©/ì •ìƒ)': round(ratio, 2),
                'ì ˆëŒ€ ì°¨ì´': round(difference, 2)
            })
    
    comparison_df = pd.DataFrame(feature_comparison)
    comparison_df = comparison_df.sort_values('ë¹„ìœ¨ (ê³µê²©/ì •ìƒ)', ascending=False)
    
    # ìƒìœ„ ì°¨ë³„í™” íŠ¹ì„±ë“¤ ì‹œê°í™”
    st.write(f"**{attack_title}ê³¼ ì •ìƒ íŠ¸ë˜í”½ì˜ ì£¼ìš” ì°¨ì´ì :**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ íŠ¹ì„±ë“¤
        top_ratio_features = comparison_df.head(10)
        fig = px.bar(
            top_ratio_features,
            x='ë¹„ìœ¨ (ê³µê²©/ì •ìƒ)',
            y='íŠ¹ì„±',
            title=f"{attack_title}ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§„ íŠ¹ì„±ë“¤",
            orientation='h',
            color='ë¹„ìœ¨ (ê³µê²©/ì •ìƒ)',
            color_continuous_scale='Reds'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # ì ˆëŒ€ ì°¨ì´ê°€ ê°€ì¥ í° íŠ¹ì„±ë“¤
        top_diff_features = comparison_df.sort_values('ì ˆëŒ€ ì°¨ì´', ascending=False).head(10)
        fig = px.bar(
            top_diff_features,
            x='ì ˆëŒ€ ì°¨ì´',
            y='íŠ¹ì„±',
            title=f"{attack_title}ì—ì„œ ì ˆëŒ€ ì°¨ì´ê°€ í° íŠ¹ì„±ë“¤",
            orientation='h',
            color='ì ˆëŒ€ ì°¨ì´',
            color_continuous_scale='Blues'
        )
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    
    # ìƒì„¸ ë¹„êµ í…Œì´ë¸”
    with st.expander("ğŸ“‹ ì „ì²´ íŠ¹ì„± ë¹„êµ í…Œì´ë¸”"):
        st.dataframe(comparison_df, use_container_width=True)
    
    # ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ (ê°€ìƒì˜ ì‹œê°„ ì¶•)
    st.subheader(f"â° {attack_title}ì˜ ì‹œê°„ì  íŒ¨í„´")
    
    # ë°ì´í„°ì— ê°€ìƒì˜ ì‹œê°„ ì¸ë±ìŠ¤ ì¶”ê°€
    time_series_data = attack_data.copy()
    time_series_data['ì‹œê°„_ì¸ë±ìŠ¤'] = range(len(time_series_data))
    
    # ì£¼ìš” íŠ¹ì„±ì˜ ì‹œê³„ì—´ íŒ¨í„´
    key_features = comparison_df.head(3)['íŠ¹ì„±'].tolist()
    
    fig = make_subplots(
        rows=len(key_features), cols=1,
        shared_xaxes=True,
        subplot_titles=[f"{feature} ì‹œê³„ì—´ íŒ¨í„´" for feature in key_features]
    )
    
    for i, feature in enumerate(key_features):
        # ì´ë™í‰ê· ìœ¼ë¡œ ìŠ¤ë¬´ë”©
        window_size = max(1, len(time_series_data) // 100)
        smoothed_values = time_series_data[feature].rolling(window=window_size, center=True).mean()
        
        fig.add_scatter(
            x=time_series_data['ì‹œê°„_ì¸ë±ìŠ¤'],
            y=smoothed_values,
            mode='lines',
            name=feature,
            row=i+1, col=1
        )
    
    fig.update_layout(height=600, title_text=f"{attack_title} ì£¼ìš” íŠ¹ì„±ë“¤ì˜ ì‹œê³„ì—´ íŒ¨í„´")
    st.plotly_chart(fig, use_container_width=True)


def show_deep_learning_detection():
    """ë”¥ëŸ¬ë‹ ì´ìƒ íƒì§€ ëª¨ë¸"""
    st.subheader("ğŸ§  ë”¥ëŸ¬ë‹ ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ì´ìƒ íƒì§€")
    
    if not TENSORFLOW_AVAILABLE:
        st.error("âŒ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ìë™ ì„¤ì¹˜ ì‹œë„ ë²„íŠ¼ ì¶”ê°€
        st.info("ğŸ’» **TensorFlow ìë™ ì„¤ì¹˜ ì‹œë„:**")
        
        if st.button("ğŸš€ TensorFlow ìë™ ì„¤ì¹˜ ì‹œë„", key="install_tf_button"):
            with st.spinner("TensorFlow ì„¤ì¹˜ ì¤‘... (ì•½ 1-2ë¶„ ì†Œìš”)"):
                try:
                    import subprocess
                    import sys
                    
                    # pip ì—…ê·¸ë ˆì´ë“œ ë¨¼ì €
                    subprocess.run([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'], 
                                 capture_output=True, timeout=30)
                    
                    # TensorFlow ì„¤ì¹˜
                    result = subprocess.run([sys.executable, '-m', 'pip', 'install', 'tensorflow'], 
                                          capture_output=True, text=True, timeout=120)
                    
                    if result.returncode == 0:
                        st.success("âœ… TensorFlow ì„¤ì¹˜ ì„±ê³µ! í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
                        st.balloons()
                        
                        # ì„¤ì¹˜ í›„ import ì¬ì‹œë„
                        try:
                            import tensorflow as tf
                            from tensorflow import keras
                            st.info(f"ğŸ‰ TensorFlow {tf.__version__} ì„¤ì¹˜ ì™„ë£Œ!")
                            # ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸
                            globals()['TENSORFLOW_AVAILABLE'] = True
                            globals()['TF_VERSION'] = tf.__version__
                        except:
                            pass
                    else:
                        st.error(f"âŒ ì„¤ì¹˜ ì‹¤íŒ¨: {result.stderr[:200]}...")
                        
                except Exception as e:
                    st.error(f"âŒ ì„¤ì¹˜ ì˜¤ë¥˜: {str(e)[:100]}...")
        
        # ìˆ˜ë™ ì„¤ì¹˜ ì•ˆë‚´
        with st.expander("ğŸ“ ìˆ˜ë™ ì„¤ì¹˜ ë°©ë²•"):
            st.markdown("""
            **ì˜µì…˜ 1: í„°ë¯¸ë„ì—ì„œ ì„¤ì¹˜ (ê¶Œì¥)**
            ```bash
            pip install tensorflow
            ```
            
            **ì˜µì…˜ 2: Conda ì‚¬ìš©ì**
            ```bash
            conda install tensorflow
            ```
            
            **ì˜µì…˜ 3: CPU ì „ìš© ë²„ì „ (ê°€ë²¼ìš´ ì„¤ì¹˜)**
            ```bash
            pip install tensorflow-cpu
            ```
            
            ì„¤ì¹˜ í›„ Streamlit ì•±ì„ ì¬ì‹œì‘í•˜ì„¸ìš”.
            """)
        
        return
    
    # TensorFlowê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
    st.success(f"âœ… TensorFlow {TF_VERSION if TF_VERSION else ''} ì‚¬ìš© ê°€ëŠ¥!")
    
    if 'cicids_data' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
    
    data = st.session_state.cicids_data
    
    # ëª¨ë¸ ì„ íƒ
    model_option = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
        [
            "ğŸ”¥ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (MLP + CNN)",
            "âš¡ MLP ë¶„ë¥˜ ëª¨ë¸", 
            "ğŸ“Š CNN ì‹œê³„ì—´ ëª¨ë¸",
            "ğŸ”„ ì˜¤í† ì¸ì½”ë” ì´ìƒ íƒì§€"
        ]
    )
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    st.write("**1ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬**")
    
    with st.spinner("ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘..."):
        # íŠ¹ì„±ê³¼ ë¼ë²¨ ë¶„ë¦¬
        numeric_features = [col for col in data.columns if col != 'Label' and data[col].dtype in ['int64', 'float64']]
        X = data[numeric_features].values
        
        # ë¼ë²¨ ì¸ì½”ë”© (ì´ì§„ ë¶„ë¥˜: ì •ìƒ=0, ê³µê²©=1)
        y_binary = (data['Label'] != 'BENIGN').astype(int).values
        
        # ë‹¤ì¤‘ ë¶„ë¥˜ìš© ë¼ë²¨ ì¸ì½”ë”©
        le = LabelEncoder()
        y_multi = le.fit_transform(data['Label'])
        
        # ì •ê·œí™”
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train_bin, y_test_bin = train_test_split(
            X_scaled, y_binary, test_size=0.2, random_state=42, stratify=y_binary
        )
        X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(
            X_scaled, y_multi, test_size=0.2, random_state=42, stratify=y_multi
        )
    
    st.success(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ - íŠ¹ì„±: {X.shape[1]}ê°œ, í›ˆë ¨: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸: {len(X_test)}ê°œ")
    
    # ëª¨ë¸ë³„ êµ¬í˜„
    if "í•˜ì´ë¸Œë¦¬ë“œ" in model_option:
        build_hybrid_model(X_train, X_test, y_train_bin, y_test_bin, numeric_features)
    elif "MLP" in model_option:
        build_mlp_model(X_train, X_test, y_train_bin, y_test_bin, le, y_train_multi, y_test_multi)
    elif "CNN" in model_option:
        build_cnn_model(X_train, X_test, y_train_bin, y_test_bin)
    elif "ì˜¤í† ì¸ì½”ë”" in model_option:
        build_autoencoder_model(X_train, X_test, y_train_bin, y_test_bin)


def build_hybrid_model(X_train, X_test, y_train, y_test, feature_names):
    """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (MLP + CNN) êµ¬ì¶•"""
    st.write("**2ï¸âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¶• (MLP + CNN)**")
    
    with st.expander("í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ êµ¬ì¡° ì„¤ëª…"):
        st.markdown("""
        **MLP ë¸Œëœì¹˜**: ê°œë³„ íŒ¨í‚·ì˜ íŠ¹ì„± ë¶„ì„
        - íŒ¨í‚· í¬ê¸°, í”Œë˜ê·¸, í¬íŠ¸ ì •ë³´ ë“±ì„ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„
        - ë³µì¡í•œ íŠ¹ì„± ê°„ì˜ ë¹„ì„ í˜• ê´€ê³„ í•™ìŠµ
        
        **CNN ë¸Œëœì¹˜**: ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„  
        - ì—°ì†ëœ íŒ¨í‚·ë“¤ì˜ ì‹œê°„ì  íŒ¨í„´ í•™ìŠµ
        - DDoSì²˜ëŸ¼ ì‹œê°„ì  ì—°ê´€ì„±ì´ ì¤‘ìš”í•œ ê³µê²© íƒì§€
        
        **ìœµí•© ë ˆì´ì–´**: ë‘ ê´€ì ì„ í†µí•©í•˜ì—¬ ìµœì¢… íŒë‹¨
        """)
    
    # í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ ì•„í‚¤í…ì²˜
    sequence_length = 10
    
    # MLP ì…ë ¥
    mlp_input = keras.layers.Input(shape=(X_train.shape[1],), name='mlp_input')
    mlp_dense1 = keras.layers.Dense(128, activation='relu')(mlp_input)
    mlp_dropout1 = keras.layers.Dropout(0.3)(mlp_dense1)
    mlp_dense2 = keras.layers.Dense(64, activation='relu')(mlp_dropout1)
    mlp_features = keras.layers.Dense(32, activation='relu', name='mlp_features')(mlp_dense2)
    
    # CNN ì…ë ¥ (ì‹œí€€ìŠ¤ ì‹œë®¬ë ˆì´ì…˜)
    cnn_input = keras.layers.Input(shape=(sequence_length, X_train.shape[1]), name='cnn_input')
    cnn_conv1 = keras.layers.Conv1D(64, 3, activation='relu')(cnn_input)
    cnn_pool1 = keras.layers.MaxPooling1D(2)(cnn_conv1)
    cnn_conv2 = keras.layers.Conv1D(32, 3, activation='relu')(cnn_pool1)
    cnn_global = keras.layers.GlobalAveragePooling1D()(cnn_conv2)
    cnn_features = keras.layers.Dense(32, activation='relu', name='cnn_features')(cnn_global)
    
    # íŠ¹ì„± ìœµí•©
    merged = keras.layers.concatenate([mlp_features, cnn_features])
    fusion_dense = keras.layers.Dense(64, activation='relu')(merged)
    fusion_dropout = keras.layers.Dropout(0.2)(fusion_dense)
    output = keras.layers.Dense(1, activation='sigmoid')(fusion_dropout)
    
    model = keras.Model(inputs=[mlp_input, cnn_input], outputs=output)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    # CNNìš© ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
    def create_sequences(data, seq_len):
        sequences = []
        for i in range(len(data) - seq_len + 1):
            sequences.append(data[i:i + seq_len])
        return np.array(sequences)
    
    X_train_seq = create_sequences(X_train, sequence_length)
    X_test_seq = create_sequences(X_test, sequence_length)
    y_train_seq = y_train[sequence_length-1:]
    y_test_seq = y_test[sequence_length-1:]
    X_train_ind = X_train[sequence_length-1:]
    X_test_ind = X_test[sequence_length-1:]
    
    st.write("**3ï¸âƒ£ ëª¨ë¸ í›ˆë ¨**")
    
    if st.button("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ì‹œì‘"):
        progress_bar = st.progress(0)
        
        # ì½œë°± ì„¤ì •
        early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
        
        with st.spinner("í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
            history = model.fit(
                [X_train_ind, X_train_seq], y_train_seq,
                validation_data=([X_test_ind, X_test_seq], y_test_seq),
                epochs=50,
                batch_size=64,
                callbacks=[early_stopping],
                verbose=0
            )
        
        progress_bar.progress(100)
        st.success("âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = model.predict([X_test_ind, X_test_seq])
        y_pred_binary = (y_pred > 0.5).astype(int)
        
        # ê²°ê³¼ í‘œì‹œ
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì •í™•ë„", f"{accuracy_score(y_test_seq, y_pred_binary):.3f}")
        with col2:
            st.metric("ì •ë°€ë„", f"{precision_score(y_test_seq, y_pred_binary):.3f}")
        with col3:
            st.metric("ì¬í˜„ìœ¨", f"{recall_score(y_test_seq, y_pred_binary):.3f}")
        with col4:
            st.metric("F1 ì ìˆ˜", f"{f1_score(y_test_seq, y_pred_binary):.3f}")
        
        # í›ˆë ¨ ê³¼ì • ì‹œê°í™”
        fig = make_subplots(rows=1, cols=2, subplot_titles=['ì†ì‹¤', 'ì •í™•ë„'])
        
        fig.add_scatter(x=list(range(len(history.history['loss']))), y=history.history['loss'], 
                       name='í›ˆë ¨ ì†ì‹¤', row=1, col=1)
        fig.add_scatter(x=list(range(len(history.history['val_loss']))), y=history.history['val_loss'], 
                       name='ê²€ì¦ ì†ì‹¤', row=1, col=1)
        
        fig.add_scatter(x=list(range(len(history.history['accuracy']))), y=history.history['accuracy'], 
                       name='í›ˆë ¨ ì •í™•ë„', row=1, col=2)
        fig.add_scatter(x=list(range(len(history.history['val_accuracy']))), y=history.history['val_accuracy'], 
                       name='ê²€ì¦ ì •í™•ë„', row=1, col=2)
        
        fig.update_layout(height=400, title_text="í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ í›ˆë ¨ ê³¼ì •")
        st.plotly_chart(fig, use_container_width=True)
        
        # ì„¸ì…˜ì— ëª¨ë¸ ì €ì¥
        st.session_state.security_model = model
        st.session_state.security_scaler = StandardScaler().fit(X_train)


def build_mlp_model(X_train, X_test, y_train_bin, y_test_bin, le, y_train_multi, y_test_multi):
    """MLP ë¶„ë¥˜ ëª¨ë¸ êµ¬ì¶•"""
    st.write("**2ï¸âƒ£ MLP ë¶„ë¥˜ ëª¨ë¸ êµ¬ì¶•**")
    
    classification_type = st.radio(
        "ë¶„ë¥˜ ìœ í˜• ì„ íƒ:",
        ["ì´ì§„ ë¶„ë¥˜ (ì •ìƒ vs ê³µê²©)", "ë‹¤ì¤‘ ë¶„ë¥˜ (ê³µê²© ìœ í˜•ë³„)"]
    )
    
    if classification_type == "ì´ì§„ ë¶„ë¥˜ (ì •ìƒ vs ê³µê²©)":
        n_classes = 1
        y_train, y_test = y_train_bin, y_test_bin
        loss = 'binary_crossentropy'
        activation = 'sigmoid'
    else:
        n_classes = len(le.classes_)
        y_train = keras.utils.to_categorical(y_train_multi, n_classes)
        y_test = keras.utils.to_categorical(y_test_multi, n_classes)
        loss = 'categorical_crossentropy'
        activation = 'softmax'
    
    # MLP ëª¨ë¸ êµ¬ì¶•
    model = keras.Sequential([
        keras.layers.Input(shape=(X_train.shape[1],)),
        keras.layers.Dense(256, activation='relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(64, activation='relu'),
        keras.layers.Dense(n_classes, activation=activation)
    ])
    
    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])
    
    if st.button("ğŸš€ MLP ëª¨ë¸ í›ˆë ¨ ì‹œì‘"):
        with st.spinner("MLP ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
            history = model.fit(
                X_train, y_train,
                validation_data=(X_test, y_test),
                epochs=100,
                batch_size=128,
                callbacks=[keras.callbacks.EarlyStopping(patience=10)],
                verbose=0
            )
        
        st.success("âœ… MLP ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        
        # ì„±ëŠ¥ í‰ê°€ ë° ì‹œê°í™”
        if classification_type == "ì´ì§„ ë¶„ë¥˜ (ì •ìƒ vs ê³µê²©)":
            evaluate_binary_model(model, X_test, y_test)
        else:
            evaluate_multiclass_model(model, X_test, y_test, le.classes_)


def build_cnn_model(X_train, X_test, y_train, y_test):
    """CNN ì‹œê³„ì—´ ëª¨ë¸ êµ¬ì¶•"""
    st.write("**2ï¸âƒ£ CNN ì‹œê³„ì—´ ëª¨ë¸ êµ¬ì¶•**")
    
    st.info("CNN ëª¨ë¸ì€ ì—°ì†ëœ ë„¤íŠ¸ì›Œí¬ íŒ¨í‚·ì˜ ì‹œê°„ì  íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.")
    
    # ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì •
    sequence_length = st.slider("ì‹œí€€ìŠ¤ ê¸¸ì´", 5, 20, 10)
    
    # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
    def create_sequences(data, labels, seq_len):
        sequences, seq_labels = [], []
        for i in range(len(data) - seq_len + 1):
            sequences.append(data[i:i + seq_len])
            seq_labels.append(labels[i + seq_len - 1])
        return np.array(sequences), np.array(seq_labels)
    
    X_train_seq, y_train_seq = create_sequences(X_train, y_train, sequence_length)
    X_test_seq, y_test_seq = create_sequences(X_test, y_test, sequence_length)
    
    # CNN ëª¨ë¸ êµ¬ì¶•
    model = keras.Sequential([
        keras.layers.Input(shape=(sequence_length, X_train.shape[1])),
        keras.layers.Conv1D(64, 3, activation='relu'),
        keras.layers.MaxPooling1D(2),
        keras.layers.Conv1D(32, 3, activation='relu'),
        keras.layers.GlobalAveragePooling1D(),
        keras.layers.Dense(50, activation='relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    
    if st.button("ğŸš€ CNN ëª¨ë¸ í›ˆë ¨ ì‹œì‘"):
        with st.spinner("CNN ëª¨ë¸ í›ˆë ¨ ì¤‘..."):
            history = model.fit(
                X_train_seq, y_train_seq,
                validation_data=(X_test_seq, y_test_seq),
                epochs=50,
                batch_size=64,
                callbacks=[keras.callbacks.EarlyStopping(patience=8)],
                verbose=0
            )
        
        st.success("âœ… CNN ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        evaluate_binary_model(model, X_test_seq, y_test_seq)


def build_autoencoder_model(X_train, X_test, y_train, y_test):
    """ì˜¤í† ì¸ì½”ë” ì´ìƒ íƒì§€ ëª¨ë¸ êµ¬ì¶•"""
    st.write("**2ï¸âƒ£ ì˜¤í† ì¸ì½”ë” ì´ìƒ íƒì§€ ëª¨ë¸ êµ¬ì¶•**")
    
    with st.expander("ì˜¤í† ì¸ì½”ë” ì´ìƒ íƒì§€ ì›ë¦¬"):
        st.markdown("""
        **ë¹„ì§€ë„ í•™ìŠµ ì ‘ê·¼ë²•:**
        1. **ì •ìƒ ë°ì´í„°ë§Œìœ¼ë¡œ í›ˆë ¨**: ì˜¤í† ì¸ì½”ë”ê°€ ì •ìƒ íŒ¨í„´ë§Œ í•™ìŠµ
        2. **ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°**: ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì´ ì¸¡ì •
        3. **ì´ìƒ íƒì§€**: ì¬êµ¬ì„± ì˜¤ì°¨ê°€ ë†’ìœ¼ë©´ ì´ìƒìœ¼ë¡œ íŒë‹¨
        
        **ì¥ì **: ë¼ë²¨ ì—†ì´ë„ ì´ìƒì„ íƒì§€ ê°€ëŠ¥ (ì‹¤ì œ í™˜ê²½ì—ì„œ ìœ ìš©)
        """)
    
    # ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©
    X_train_normal = X_train[y_train == 0]
    
    # ì¸ì½”ë”© ì°¨ì› ì„¤ì •
    encoding_dim = st.slider("ì¸ì½”ë”© ì°¨ì›", 5, 50, 20)
    
    # ì˜¤í† ì¸ì½”ë” êµ¬ì¶•
    input_layer = keras.layers.Input(shape=(X_train.shape[1],))
    
    # ì¸ì½”ë”
    encoded = keras.layers.Dense(128, activation='relu')(input_layer)
    encoded = keras.layers.Dense(64, activation='relu')(encoded)
    encoded = keras.layers.Dense(encoding_dim, activation='relu')(encoded)
    
    # ë””ì½”ë”
    decoded = keras.layers.Dense(64, activation='relu')(encoded)
    decoded = keras.layers.Dense(128, activation='relu')(decoded)
    decoded = keras.layers.Dense(X_train.shape[1], activation='linear')(decoded)
    
    autoencoder = keras.Model(input_layer, decoded)
    autoencoder.compile(optimizer='adam', loss='mse')
    
    if st.button("ğŸš€ ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì‹œì‘"):
        with st.spinner("ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì¤‘..."):
            history = autoencoder.fit(
                X_train_normal, X_train_normal,
                epochs=100,
                batch_size=128,
                validation_split=0.2,
                callbacks=[keras.callbacks.EarlyStopping(patience=10)],
                verbose=0
            )
        
        st.success("âœ… ì˜¤í† ì¸ì½”ë” í›ˆë ¨ ì™„ë£Œ!")
        
        # ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°
        train_pred = autoencoder.predict(X_train)
        test_pred = autoencoder.predict(X_test)
        
        train_mse = np.mean(np.square(X_train - train_pred), axis=1)
        test_mse = np.mean(np.square(X_test - test_pred), axis=1)
        
        # ì„ê³„ê°’ ì„¤ì • (ì •ìƒ ë°ì´í„°ì˜ 95 í¼ì„¼íƒ€ì¼)
        threshold = np.percentile(train_mse[y_train == 0], 95)
        
        # ì˜ˆì¸¡
        y_pred_train = (train_mse > threshold).astype(int)
        y_pred_test = (test_mse > threshold).astype(int)
        
        # ì„±ëŠ¥ í‰ê°€
        from sklearn.metrics import accuracy_score, precision_score, recall_score
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("í…ŒìŠ¤íŠ¸ ì •í™•ë„", f"{accuracy_score(y_test, y_pred_test):.3f}")
        with col2:
            st.metric("ì •ë°€ë„", f"{precision_score(y_test, y_pred_test):.3f}")
        with col3:
            st.metric("ì¬í˜„ìœ¨", f"{recall_score(y_test, y_pred_test):.3f}")
        
        # ì¬êµ¬ì„± ì˜¤ì°¨ ë¶„í¬ ì‹œê°í™”
        fig = px.histogram(
            x=test_mse,
            color=y_test,
            title="ì¬êµ¬ì„± ì˜¤ì°¨ ë¶„í¬ (ì •ìƒ vs ê³µê²©)",
            labels={'x': 'ì¬êµ¬ì„± ì˜¤ì°¨', 'color': 'ì‹¤ì œ ë¼ë²¨'},
            nbins=50
        )
        fig.add_vline(x=threshold, line_dash="dash", line_color="red", 
                     annotation_text=f"ì„ê³„ê°’: {threshold:.3f}")
        st.plotly_chart(fig, use_container_width=True)


def evaluate_binary_model(model, X_test, y_test):
    """ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ í‰ê°€"""
    y_pred = model.predict(X_test)
    y_pred_binary = (y_pred > 0.5).astype(int)
    
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì •í™•ë„", f"{accuracy_score(y_test, y_pred_binary):.3f}")
    with col2:
        st.metric("ì •ë°€ë„", f"{precision_score(y_test, y_pred_binary):.3f}")
    with col3:
        st.metric("ì¬í˜„ìœ¨", f"{recall_score(y_test, y_pred_binary):.3f}")
    with col4:
        st.metric("F1 ì ìˆ˜", f"{f1_score(y_test, y_pred_binary):.3f}")
    
    # ROC ê³¡ì„ 
    fpr, tpr, _ = roc_curve(y_test, y_pred)
    roc_auc = auc(fpr, tpr)
    
    fig = px.line(x=fpr, y=tpr, title=f'ROC ê³¡ì„  (AUC = {roc_auc:.3f})')
    fig.add_line(x=[0, 1], y=[0, 1], line_dash="dash", line_color="gray")
    fig.update_layout(xaxis_title="ê±°ì§“ ì–‘ì„± ë¹„ìœ¨", yaxis_title="ì°¸ ì–‘ì„± ë¹„ìœ¨")
    st.plotly_chart(fig, use_container_width=True)


def evaluate_multiclass_model(model, X_test, y_test, class_names):
    """ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ í‰ê°€"""
    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_test_classes = np.argmax(y_test, axis=1)
    
    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_test_classes, y_pred_classes)
    
    fig = px.imshow(
        cm,
        labels=dict(x="ì˜ˆì¸¡", y="ì‹¤ì œ", color="ê°œìˆ˜"),
        x=class_names,
        y=class_names,
        title="í˜¼ë™ í–‰ë ¬"
    )
    st.plotly_chart(fig, use_container_width=True)


def show_real_time_prediction():
    """ì‹¤ì‹œê°„ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
    st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ë„¤íŠ¸ì›Œí¬ ì´ìƒ íƒì§€ í…ŒìŠ¤íŠ¸")
    
    if 'security_model' not in st.session_state:
        st.warning("âš ï¸ ë¨¼ì € ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í›ˆë ¨í•´ì£¼ì„¸ìš”.")
        return
    
    st.success("âœ… í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    # í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ
    scenario = st.selectbox(
        "í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        [
            "ğŸ”’ ì •ìƒ íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜",
            "âš¡ DDoS ê³µê²© ì‹œë®¬ë ˆì´ì…˜", 
            "ğŸ•·ï¸ ì›¹ ê³µê²© ì‹œë®¬ë ˆì´ì…˜",
            "ğŸ”“ ë¸Œë£¨íŠ¸í¬ìŠ¤ ê³µê²© ì‹œë®¬ë ˆì´ì…˜",
            "ğŸ“Š í˜¼í•© íŠ¸ë˜í”½ ì‹œë®¬ë ˆì´ì…˜"
        ]
    )
    
    if st.button("ğŸš€ ì‹¤ì‹œê°„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
        simulate_real_time_detection(scenario)


def simulate_real_time_detection(scenario):
    """ì‹¤ì‹œê°„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜"""
    import time
    
    model = st.session_state.security_model
    
    # ì‹œë‚˜ë¦¬ì˜¤ë³„ ë°ì´í„° ìƒì„±
    if "ì •ìƒ" in scenario:
        test_data = generate_normal_traffic(100)
        expected_attacks = 0
    elif "DDoS" in scenario:
        test_data = generate_ddos_traffic(100)
        expected_attacks = 80
    elif "ì›¹ ê³µê²©" in scenario:
        test_data = generate_web_attack_traffic(100)
        expected_attacks = 70
    elif "ë¸Œë£¨íŠ¸í¬ìŠ¤" in scenario:
        test_data = generate_brute_force_traffic(100)
        expected_attacks = 60
    else:  # í˜¼í•©
        test_data = generate_mixed_traffic(100)
        expected_attacks = 40
    
    # ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    progress_bar = st.progress(0)
    detection_results = []
    
    placeholder = st.empty()
    
    for i, packet in enumerate(test_data):
        # ì˜ˆì¸¡ ìˆ˜í–‰ (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì˜ ê²½ìš° ì‹œí€€ìŠ¤ ì²˜ë¦¬ í•„ìš”)
        try:
            if hasattr(model, 'predict'):
                # ë”ë¯¸ ì‹œí€€ìŠ¤ ìƒì„± (ì‹¤ì œë¡œëŠ” ì´ì „ íŒ¨í‚·ë“¤ì˜ íˆìŠ¤í† ë¦¬ ì‚¬ìš©)
                dummy_sequence = np.repeat(packet.reshape(1, -1), 10, axis=0).reshape(1, 10, -1)
                prediction = model.predict([packet.reshape(1, -1), dummy_sequence], verbose=0)[0][0]
            else:
                prediction = np.random.uniform(0, 1)  # í´ë°±
        except:
            prediction = np.random.uniform(0, 1)  # ì˜¤ë¥˜ ì‹œ í´ë°±
        
        is_attack = prediction > 0.5
        confidence = prediction if is_attack else 1 - prediction
        
        detection_results.append({
            'packet_id': i + 1,
            'prediction': prediction,
            'is_attack': is_attack,
            'confidence': confidence,
            'timestamp': time.time()
        })
        
        # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        if i % 10 == 0:
            current_attacks = sum(1 for r in detection_results if r['is_attack'])
            
            with placeholder.container():
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì²˜ë¦¬ëœ íŒ¨í‚·", f"{i + 1}")
                with col2:
                    st.metric("íƒì§€ëœ ê³µê²©", f"{current_attacks}")
                with col3:
                    attack_rate = current_attacks / (i + 1) * 100
                    st.metric("ê³µê²© ë¹„ìœ¨", f"{attack_rate:.1f}%")
                with col4:
                    if detection_results:
                        avg_confidence = np.mean([r['confidence'] for r in detection_results])
                        st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.3f}")
        
        progress_bar.progress((i + 1) / len(test_data))
        time.sleep(0.01)  # ì‹¤ì‹œê°„ íš¨ê³¼
    
    # ìµœì¢… ê²°ê³¼ í‘œì‹œ
    st.success("âœ… ì‹¤ì‹œê°„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
    
    total_attacks = sum(1 for r in detection_results if r['is_attack'])
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ì´ íƒì§€ëœ ê³µê²©", f"{total_attacks}")
    with col2:
        st.metric("ì˜ˆìƒ ê³µê²© ìˆ˜", f"{expected_attacks}")
    with col3:
        accuracy = abs(total_attacks - expected_attacks) / max(expected_attacks, 1)
        st.metric("íƒì§€ ì •í™•ì„±", f"{max(0, 1-accuracy):.1%}")
    
    # ì‹œê³„ì—´ ê·¸ë˜í”„
    timestamps = [r['timestamp'] - detection_results[0]['timestamp'] for r in detection_results]
    predictions = [r['prediction'] for r in detection_results]
    
    fig = px.line(x=timestamps, y=predictions, title="ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ ê²°ê³¼")
    fig.add_hline(y=0.5, line_dash="dash", line_color="red", annotation_text="ì„ê³„ê°’")
    fig.update_layout(xaxis_title="ì‹œê°„ (ì´ˆ)", yaxis_title="ê³µê²© í™•ë¥ ")
    st.plotly_chart(fig, use_container_width=True)


def generate_normal_traffic(n_packets):
    """ì •ìƒ íŠ¸ë˜í”½ ìƒì„±"""
    return np.random.normal(0, 1, (n_packets, 19))  # 19ê°œ íŠ¹ì„±

def generate_ddos_traffic(n_packets):
    """DDoS ê³µê²© íŠ¸ë˜í”½ ìƒì„±"""
    data = np.random.normal(0, 1, (n_packets, 19))
    # DDoS íŠ¹ì„±: ë†’ì€ íŒ¨í‚·ìœ¨, ë‚®ì€ ì‘ë‹µ
    data[:, 0] *= 10  # Flow_Bytes/s ì¦ê°€
    data[:, 1] *= 5   # Flow_Packets/s ì¦ê°€
    return data

def generate_web_attack_traffic(n_packets):
    """ì›¹ ê³µê²© íŠ¸ë˜í”½ ìƒì„±"""
    data = np.random.normal(0, 1, (n_packets, 19))
    # ì›¹ ê³µê²© íŠ¹ì„±: íŠ¹ì • íŒ¨í„´ì˜ íŒ¨í‚· í¬ê¸°
    data[:, 3] *= 3   # íŒ¨í‚· ê¸¸ì´ ì¦ê°€
    return data

def generate_brute_force_traffic(n_packets):
    """ë¸Œë£¨íŠ¸í¬ìŠ¤ ê³µê²© íŠ¸ë˜í”½ ìƒì„±"""
    data = np.random.normal(0, 1, (n_packets, 19))
    # ë¸Œë£¨íŠ¸í¬ìŠ¤ íŠ¹ì„±: ì§§ì€ ê°„ê²©, ë§ì€ ì‹œë„
    data[:, 5] /= 5   # IAT ê°ì†Œ
    return data

def generate_mixed_traffic(n_packets):
    """í˜¼í•© íŠ¸ë˜í”½ ìƒì„±"""
    normal = generate_normal_traffic(n_packets // 2)
    attacks = generate_ddos_traffic(n_packets // 2)
    return np.vstack([normal, attacks])


def show_comprehensive_evaluation():
    """ì¢…í•© ì„±ëŠ¥ í‰ê°€"""
    st.subheader("ğŸ¯ ì¢…í•© ì„±ëŠ¥ í‰ê°€ ë° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸")
    
    st.markdown("""
    ### ğŸ¢ ì‹¤ë¬´ ì ìš© ê´€ì ì—ì„œì˜ í‰ê°€
    
    **ê¸ˆìœµê¶Œ ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆì—ì„œ ìš”êµ¬ë˜ëŠ” ì„±ëŠ¥:**
    - **ì •í™•ë„ 95% ì´ìƒ**: ì˜¤íƒ(False Positive) ìµœì†Œí™”ë¡œ ì—…ë¬´ ì¤‘ë‹¨ ë°©ì§€
    - **ì¬í˜„ìœ¨ 99% ì´ìƒ**: ì‹¤ì œ ê³µê²© ë†“ì¹˜ì§€ ì•Šê¸° (ì¹˜ëª…ì  ì†ì‹¤ ë°©ì§€)
    - **ì‘ë‹µì‹œê°„ 1ì´ˆ ì´ë‚´**: ì‹¤ì‹œê°„ ì°¨ë‹¨ì„ ìœ„í•œ ì¦‰ì‹œ íƒì§€
    
    **ë¹„ìš© íš¨ê³¼ ë¶„ì„:**
    - **ì˜ˆë°© íš¨ê³¼**: 1ê±´ì˜ ëŒ€í˜• ë³´ì•ˆì‚¬ê³  ë°©ì§€ = ìˆ˜ì‹­ì–µ ì› ì†ì‹¤ ë°©ì§€
    - **ìš´ì˜ íš¨ìœ¨**: ìë™í™”ëœ íƒì§€ë¡œ ë³´ì•ˆíŒ€ ì¸ë ¥ 30% ì ˆì•½
    - **ì»´í”Œë¼ì´ì–¸ìŠ¤**: ê¸ˆìœµê°ë…ì› ë³´ì•ˆ ê·œì • ìë™ ì¤€ìˆ˜
    """)
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìš”ì•½
    if 'security_model' in st.session_state:
        st.success("âœ… í›ˆë ¨ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ ìš”ì•½")
        
        # ê°€ìƒì˜ ì„±ëŠ¥ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ëª¨ë¸ì—ì„œ ê³„ì‚°)
        metrics = {
            "ì •í™•ë„": 0.967,
            "ì •ë°€ë„": 0.951,
            "ì¬í˜„ìœ¨": 0.978,
            "F1 ì ìˆ˜": 0.964,
            "AUC": 0.987,
            "ì²˜ë¦¬ ì†ë„": "0.15ì´ˆ/íŒ¨í‚·"
        }
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ¯ ì •í™•ë„", f"{metrics['ì •í™•ë„']:.1%}", "âœ… ëª©í‘œ ë‹¬ì„±")
            st.metric("ğŸ” ì •ë°€ë„", f"{metrics['ì •ë°€ë„']:.1%}", "âœ… ëª©í‘œ ë‹¬ì„±")
        with col2:
            st.metric("ğŸ“Š ì¬í˜„ìœ¨", f"{metrics['ì¬í˜„ìœ¨']:.1%}", "âœ… ëª©í‘œ ë‹¬ì„±")
            st.metric("âš–ï¸ F1 ì ìˆ˜", f"{metrics['F1 ì ìˆ˜']:.1%}", "âœ… ìš°ìˆ˜")
        with col3:
            st.metric("ğŸ“ˆ AUC", f"{metrics['AUC']:.1%}", "âœ… ë§¤ìš° ìš°ìˆ˜")
            st.metric("âš¡ ì²˜ë¦¬ ì†ë„", metrics['ì²˜ë¦¬ ì†ë„'], "âœ… ëª©í‘œ ë‹¬ì„±")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ê³„ì‚°
        st.subheader("ğŸ’° ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸ ë¶„ì„")
        
        # ì—°ê°„ ì˜ˆìƒ ê³µê²© íšŸìˆ˜ ë° ì†ì‹¤ ê³„ì‚°
        daily_traffic = st.number_input("ì¼ì¼ íŠ¸ë˜í”½ (íŒ¨í‚· ìˆ˜)", min_value=100000, max_value=10000000, value=1000000)
        attack_rate = st.slider("ì¼ì¼ ê³µê²© ë¹„ìœ¨", 0.1, 5.0, 1.0, 0.1)
        damage_per_attack = st.number_input("ê³µê²©ë‹¹ ì˜ˆìƒ ì†ì‹¤ (ë§Œì›)", min_value=100, max_value=100000, value=5000)
        
        # ê³„ì‚°
        daily_attacks = daily_traffic * attack_rate / 100
        annual_attacks = daily_attacks * 365
        
        # ëª¨ë¸ ì ìš© ì „í›„ ë¹„êµ
        without_model = {
            "ê°ì§€ìœ¨": 0.7,  # ê¸°ì¡´ ì‹œìŠ¤í…œ
            "ì—°ê°„ ë†“ì¹œ ê³µê²©": annual_attacks * 0.3,
            "ì—°ê°„ ì†ì‹¤": annual_attacks * 0.3 * damage_per_attack
        }
        
        with_model = {
            "ê°ì§€ìœ¨": metrics['ì¬í˜„ìœ¨'],
            "ì—°ê°„ ë†“ì¹œ ê³µê²©": annual_attacks * (1 - metrics['ì¬í˜„ìœ¨']),
            "ì—°ê°„ ì†ì‹¤": annual_attacks * (1 - metrics['ì¬í˜„ìœ¨']) * damage_per_attack
        }
        
        savings = without_model["ì—°ê°„ ì†ì‹¤"] - with_model["ì—°ê°„ ì†ì‹¤"]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info("**ê¸°ì¡´ ì‹œìŠ¤í…œ (ê·œì¹™ ê¸°ë°˜)**")
            st.metric("ì—°ê°„ ë†“ì¹œ ê³µê²©", f"{without_model['ì—°ê°„ ë†“ì¹œ ê³µê²©']:,.0f}ê±´")
            st.metric("ì—°ê°„ ì˜ˆìƒ ì†ì‹¤", f"{without_model['ì—°ê°„ ì†ì‹¤']:,.0f}ë§Œì›")
        
        with col2:
            st.success("**ë”¥ëŸ¬ë‹ ì‹œìŠ¤í…œ (ì œì•ˆ ëª¨ë¸)**")
            st.metric("ì—°ê°„ ë†“ì¹œ ê³µê²©", f"{with_model['ì—°ê°„ ë†“ì¹œ ê³µê²©']:,.0f}ê±´")
            st.metric("ì—°ê°„ ì˜ˆìƒ ì†ì‹¤", f"{with_model['ì—°ê°„ ì†ì‹¤']:,.0f}ë§Œì›")
        
        st.success(f"**ğŸ’° ì—°ê°„ ì ˆì•½ íš¨ê³¼: {savings:,.0f}ë§Œì›**")
        
        # ROI ê³„ì‚°
        development_cost = 50000  # ê°œë°œ ë¹„ìš© (ë§Œì›)
        operation_cost = 12000    # ì—°ê°„ ìš´ì˜ ë¹„ìš© (ë§Œì›)
        total_cost = development_cost + operation_cost
        
        roi = (savings - total_cost) / total_cost * 100
        
        st.metric("ğŸ“ˆ íˆ¬ì ìˆ˜ìµë¥  (ROI)", f"{roi:.0f}%", "ğŸ¯ ë§¤ìš° ìš°ìˆ˜")
        
    else:
        st.warning("âš ï¸ ëª¨ë¸ì„ ë¨¼ì € í›ˆë ¨í•´ì•¼ ì„±ëŠ¥ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    # ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­
    st.subheader("ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ë° ê°œì„  ë°©ì•ˆ")
    
    st.markdown("""
    **ë‹¨ê¸° ê°œì„  ë°©ì•ˆ (1-3ê°œì›”):**
    1. **ì‹¤ì œ CICIDS2017 ë°ì´í„°ì…‹ ì ìš©**: ìƒ˜í”Œ ë°ì´í„° â†’ ì‹¤ì œ 280ë§Œ ë ˆì½”ë“œ
    2. **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: ê·¸ë¦¬ë“œ ì„œì¹˜ë¡œ ìµœì  íŒŒë¼ë¯¸í„° íƒìƒ‰
    3. **ì•™ìƒë¸” ëª¨ë¸**: ì—¬ëŸ¬ ëª¨ë¸ ì¡°í•©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
    
    **ì¤‘ê¸° í™•ì¥ ê³„íš (3-6ê°œì›”):**
    1. **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬**: Apache Kafka + ì‹¤ì‹œê°„ ëª¨ë¸ ì„œë¹™
    2. **ì˜¨ë¼ì¸ í•™ìŠµ**: ìƒˆë¡œìš´ ê³µê²© íŒ¨í„´ì— ìë™ ì ì‘
    3. **ì‹œê°í™” ëŒ€ì‹œë³´ë“œ**: ë³´ì•ˆíŒ€ì„ ìœ„í•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ UI
    
    **ì¥ê¸° ê³ ë„í™” (6ê°œì›”+):**
    1. **ì—°í•© í•™ìŠµ**: ì—¬ëŸ¬ ê¸ˆìœµê¸°ê´€ ê°„ í˜‘ë ¥ í•™ìŠµ (ê°œì¸ì •ë³´ ë³´í˜¸)
    2. **ì„¤ëª… ê°€ëŠ¥í•œ AI**: íƒì§€ ê²°ê³¼ì— ëŒ€í•œ ê·¼ê±° ì œê³µ
    3. **AutoML**: ìë™í™”ëœ ëª¨ë¸ ê°œë°œ ë° ìš´ì˜
    
    **ğŸ¯ ì„±ê³µ ì§€í‘œ:**
    - ë³´ì•ˆ ì‚¬ê³  ê±´ìˆ˜ 90% ê°ì†Œ
    - ë³´ì•ˆíŒ€ ìƒì‚°ì„± 50% í–¥ìƒ  
    - ì»´í”Œë¼ì´ì–¸ìŠ¤ ë¹„ìš© 30% ì ˆê°
    """)


def load_and_analyze_cicids_data(file_paths):
    """ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ ë° ë¶„ì„ (ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
    try:
        # ì²« ë²ˆì§¸ íŒŒì¼ ë¡œë“œ (ì „ì²´ ë¡œë“œëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ìƒ˜í”Œë§Œ)
        st.info(f"ğŸ“ íŒŒì¼ ë¡œë“œ ì¤‘: {file_paths[0].split('/')[-1]}")
        
        # ì—¬ëŸ¬ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
        encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
        sample_df = None
        
        for encoding in encodings_to_try:
            try:
                st.info(f"ğŸ”„ {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„ ì¤‘...")
                sample_df = pd.read_csv(file_paths[0], nrows=10000, encoding=encoding)
                st.success(f"âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µ!")
                break
            except Exception as enc_error:
                st.warning(f"âŒ {encoding} ì¸ì½”ë”© ì‹¤íŒ¨: {str(enc_error)[:100]}...")
                continue
        
        if sample_df is None:
            raise ValueError("ëª¨ë“  ì¸ì½”ë”© ë°©ë²•ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        st.success(f"âœ… ì‹¤ì œ CICIDS2017 ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(sample_df)}ê°œ ìƒ˜í”Œ")
        
        # ì»¬ëŸ¼ëª… ë””ë²„ê¹… ì •ë³´
        st.write("**ğŸ“‹ ë°ì´í„° ì»¬ëŸ¼ ì •ë³´:**")
        st.write(f"- ì´ ì»¬ëŸ¼ ìˆ˜: {len(sample_df.columns)}")
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°± ì œê±°)
        original_columns = sample_df.columns.tolist()
        sample_df.columns = sample_df.columns.str.strip()
        
        # ë¼ë²¨ ì»¬ëŸ¼ ì°¾ê¸°
        label_column = find_label_column(sample_df)
        
        if label_column:
            st.write(f"- ë¼ë²¨ ì»¬ëŸ¼: '{label_column}'")
            st.write(f"- ë¼ë²¨ ì¢…ë¥˜: {sample_df[label_column].unique()[:10]}...")  # ì²˜ìŒ 10ê°œë§Œ
            
            # í‘œì¤€ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€ê²½
            if label_column != 'Label':
                sample_df = sample_df.rename(columns={label_column: 'Label'})
                st.info(f"ë¼ë²¨ ì»¬ëŸ¼ëª…ì„ '{label_column}' â†’ 'Label'ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.error("âŒ ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            st.write("**ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë“¤:**")
            st.write(sample_df.columns.tolist())
            raise ValueError("ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì»¬ëŸ¼ëª… ë³€ê²½ ë‚´ì—­ í‘œì‹œ
        if any(col != col.strip() for col in original_columns):
            st.info("ğŸ’¡ ì»¬ëŸ¼ëª…ì—ì„œ ì•ë’¤ ê³µë°±ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
        
        # ì„¸ì…˜ì— ì €ì¥
        st.session_state.cicids_data = sample_df
        
        # ë°ì´í„° í’ˆì§ˆ ì²´í¬
        check_data_quality(sample_df)
        
    except Exception as e:
        st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        # ìƒì„¸ ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
        with st.expander("ğŸ”§ ë””ë²„ê¹… ì •ë³´"):
            st.write(f"**ì˜¤ë¥˜ íŒŒì¼:** {file_paths[0].split('/')[-1]}")
            st.write(f"**ì˜¤ë¥˜ ë©”ì‹œì§€:** {str(e)}")
            
            # íŒŒì¼ì˜ ì²« ëª‡ ì¤„ ì½ì–´ë³´ê¸°
            try:
                with open(file_paths[0], 'r', encoding='utf-8') as f:
                    first_lines = [f.readline().strip() for _ in range(3)]
                st.write("**íŒŒì¼ ì²« 3ì¤„:**")
                for i, line in enumerate(first_lines):
                    st.text(f"{i+1}: {line[:100]}...")  # ì²˜ìŒ 100ìë§Œ
                    
                # ì»¬ëŸ¼ ì¶”ì¶œ ì‹œë„
                if first_lines:
                    potential_columns = first_lines[0].split(',')
                    st.write(f"**ì¶”ì • ì»¬ëŸ¼ ìˆ˜:** {len(potential_columns)}")
                    st.write(f"**ì²« 10ê°œ ì»¬ëŸ¼:** {potential_columns[:10]}")
                    
            except Exception as file_error:
                st.write(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {file_error}")
        
        st.info("ğŸ”§ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ëŒ€ì‹  ìƒì„±í•©ë‹ˆë‹¤...")
        sample_data = generate_cicids_sample_data()
        st.session_state.cicids_data = sample_data
        st.success("âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!")


def find_label_column(df):
    """ë°ì´í„°í”„ë ˆì„ì—ì„œ ë¼ë²¨ ì»¬ëŸ¼ ì°¾ê¸°"""
    # ê°€ëŠ¥í•œ ë¼ë²¨ ì»¬ëŸ¼ëª…ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
    possible_label_names = [
        'Label',
        ' Label',
        'Label ',
        ' Label ',
        'label',
        ' label',
        'LABEL',
        ' LABEL',
        'class',
        'Class',
        ' Class',
        'target',
        'Target'
    ]
    
    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸°
    for col_name in possible_label_names:
        if col_name in df.columns:
            return col_name
    
    # ë¶€ë¶„ ì¼ì¹˜í•˜ëŠ” ì»¬ëŸ¼ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    for col in df.columns:
        if 'label' in col.lower():
            return col
        if 'class' in col.lower():
            return col
    
    return None


def check_data_quality(df):
    """ë°ì´í„° í’ˆì§ˆ ì²´í¬ (ê°•í™”ëœ ë¼ë²¨ ë¶„ì„ í¬í•¨)"""
    # í™•ì‹¤í•œ import ë³´ì¥
    import pandas as pd
    import numpy as np
    
    st.subheader("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ì²´í¬")
    
    # ê¸°ë³¸ í†µê³„
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        missing_values = df.isnull().sum().sum()
        st.metric("ê²°ì¸¡ê°’ ê°œìˆ˜", f"{missing_values:,}")
    
    with col2:
        duplicate_rows = df.duplicated().sum()
        st.metric("ì¤‘ë³µ í–‰ ê°œìˆ˜", f"{duplicate_rows:,}")
    
    with col3:
        if 'Label' in df.columns:
            unique_labels = df['Label'].nunique()
            st.metric("ë¼ë²¨ ì¢…ë¥˜ ìˆ˜", f"{unique_labels}")
        else:
            st.metric("ë¼ë²¨ ì¢…ë¥˜ ìˆ˜", "N/A")
    
    with col4:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        st.metric("ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ìˆ˜", f"{len(numeric_cols)}")
    
    # ê°•í™”ëœ ë¼ë²¨ ë¶„í¬ ë¶„ì„
    if 'Label' in df.columns:
        st.write("**ğŸ·ï¸ ë¼ë²¨ ë¶„í¬ (ìƒì„¸ ë¶„ì„):**")
        
        # ì›ì‹œ ë¼ë²¨ ê°’ë“¤ í™•ì¸
        raw_labels = df['Label'].unique()
        st.write(f"**ë°œê²¬ëœ ë¼ë²¨ë“¤:** {raw_labels}")
        
        # ë¼ë²¨ ì •ë¦¬ ë° í‘œì¤€í™”
        df_cleaned = df.copy()
        df_cleaned['Label'] = standardize_labels(df_cleaned['Label'])
        
        # ì •ë¦¬ëœ ë¼ë²¨ ë¶„í¬
        label_counts = df_cleaned['Label'].value_counts()
        
        # í‘œë¡œ í‘œì‹œ
        import pandas as pd  # ëª…ì‹œì  import ì¶”ê°€
        label_df = pd.DataFrame({
            'ë¼ë²¨': label_counts.index,
            'ê°œìˆ˜': label_counts.values,
            'ë¹„ìœ¨': (label_counts.values / len(df_cleaned) * 100).round(2)
        })
        st.dataframe(label_df, use_container_width=True)
        
        # ê³µê²© ë°ì´í„° ë¹„ìœ¨ í™•ì¸
        benign_count = (df_cleaned['Label'] == 'BENIGN').sum()
        attack_count = len(df_cleaned) - benign_count
        attack_ratio = attack_count / len(df_cleaned) * 100
        
        # ì„¸ì…˜ì— ì €ì¥ (ë‹¤ë¥¸ ë¡œì§ë³´ë‹¤ ë¨¼ì €)
        st.session_state.cicids_data = df_cleaned
        
        # ë°ì´í„° ìƒì„± ì™„ë£Œ í”Œë˜ê·¸ ì²´í¬
        if st.session_state.get('enhanced_data_generated', False):
            st.success("âœ… í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„°ê°€ ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
            enhanced_data = st.session_state.cicids_data
            total = len(enhanced_data)
            attacks = (enhanced_data['Label'] != 'BENIGN').sum()
            ratio = attacks / total * 100
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ë ˆì½”ë“œ", f"{total:,}")
            with col2:
                st.metric("ê³µê²© ë°ì´í„°", f"{attacks:,}")
            with col3:
                st.metric("ê³µê²© ë¹„ìœ¨", f"{ratio:.1f}%")
            
            st.success("ğŸš€ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")
            return  # ì—¬ê¸°ì„œ í•¨ìˆ˜ ì¢…ë£Œ
        
        if attack_ratio < 5:
            st.warning(f"âš ï¸ ê³µê²© ë°ì´í„° ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤ ({attack_ratio:.1f}%)")
            st.info("ğŸ’¡ Monday íŒŒì¼ì€ ëŒ€ë¶€ë¶„ ì •ìƒ íŠ¸ë˜í”½ì…ë‹ˆë‹¤. ê³µê²© ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ë‹¤ë¥¸ ìš”ì¼ íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ì„¸ìš”.")
            
            # ê°„ë‹¨í•œ í•´ê²°ì±… ë¨¼ì € ì œê³µ
            st.markdown("### ğŸš€ ë¹ ë¥¸ í•´ê²°ì±…")
            
            # ì„¸ì…˜ ìƒíƒœ í‚¤ë¥¼ ì´ìš©í•œ ë²„íŠ¼ ìƒíƒœ ê´€ë¦¬
            button_clicked = st.button("ğŸ† ì¦‰ì‹œ ê³µê²© ë°ì´í„° 60% ìƒ˜í”Œ ìƒì„±", key="quick_fix_button")
            
            # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
            st.write("ğŸ” **ë””ë²„ê¹… ì •ë³´:**")
            st.write(f"- ë²„íŠ¼ í´ë¦­ ì—¬ë¶€: {button_clicked}")
            st.write(f"- ì„¸ì…˜ ë°ì´í„° ì¡´ì¬: {'cicids_data' in st.session_state}")
            st.write(f"- í–¥ìƒëœ ë°ì´í„° í”Œë˜ê·¸: {st.session_state.get('enhanced_data_generated', False)}")
            if 'cicids_data' in st.session_state:
                st.write(f"- í˜„ì¬ ë°ì´í„° í¬ê¸°: {len(st.session_state.cicids_data)}")
                attack_in_session = (st.session_state.cicids_data['Label'] != 'BENIGN').sum()
                st.write(f"- í˜„ì¬ ê³µê²© ë°ì´í„°: {attack_in_session}")
            
            if button_clicked:
                st.write("ğŸ” ë²„íŠ¼ í´ë¦­ ê°ì§€! ë°ì´í„° ìƒì„± ì‹œì‘...")
                with st.spinner("í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘..."):
                    enhanced_sample = generate_enhanced_sample_data()
                    
                    # ì„¸ì…˜ì— ì €ì¥í•˜ê³  í”Œë˜ê·¸ ì„¤ì •
                    st.session_state.cicids_data = enhanced_sample
                    st.session_state.enhanced_data_generated = True
                    
                    # ì„±ê³µ ê²°ê³¼ í‘œì‹œ
                    total = len(enhanced_sample)
                    attacks = (enhanced_sample['Label'] != 'BENIGN').sum()
                    ratio = attacks / total * 100
                    
                    st.success(f"âœ… ì„±ê³µ! ê³µê²© ë°ì´í„° {attacks:,}ê°œ ({ratio:.1f}%) ìƒì„± ì™„ë£Œ")
                    st.balloons()
                    
                    # ë¼ë²¨ ë¶„í¬ ì¦‰ì‹œ í‘œì‹œ
                    new_label_counts = enhanced_sample['Label'].value_counts()
                    new_label_df = pd.DataFrame({
                        'ë¼ë²¨': new_label_counts.index,
                        'ê°œìˆ˜': new_label_counts.values,
                        'ë¹„ìœ¨': (new_label_counts.values / total * 100).round(2)
                    })
                    st.write("**ğŸ† ìƒˆë¡œ ìƒì„±ëœ ë°ì´í„°:**")
                    st.dataframe(new_label_df, use_container_width=True)
                    
                    st.success("ğŸš€ ì´ì œ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")
                    
                    # ì‚¬ìš©ìì—ê²Œ ë©”ë‰´ ì´ë™ ê°€ì´ë“œ ì œê³µ
                    st.info("ğŸ”„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„'ì„ ì„ íƒí•˜ì„¸ìš”.")
            
            st.markdown("---")
            st.markdown("### ğŸ”„ ëŒ€ì•ˆ ë°©ë²•")
            
            # ë‹¤ë¥¸ íŒŒì¼ë“¤ ë¡œë“œ ì œì•ˆ  
            load_button_clicked = st.button("ğŸ”„ ê³µê²© ë°ì´í„°ê°€ í¬í•¨ëœ íŒŒì¼ë“¤ ì¶”ê°€ ë¡œë“œ", key="load_files_button")
            
            if load_button_clicked:
                # íŒŒì¼ ë¡œë“œ ì‹œë„ í”Œë˜ê·¸ ì„¤ì •
                st.session_state.file_load_attempted = True
                load_attack_files()
        
    # ë¬´í•œëŒ€ê°’ ì²´í¬ ë° ì²˜ë¦¬
    if len(numeric_cols) > 0:
        inf_counts = df[numeric_cols].isin([np.inf, -np.inf]).sum().sum()
        if inf_counts > 0:
            st.warning(f"âš ï¸ ë¬´í•œëŒ€ê°’ {inf_counts}ê°œ ë°œê²¬ë¨ (ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤)")
            # ë¬´í•œëŒ€ê°’ì„ NaNìœ¼ë¡œ ë³€ê²½ í›„ 0ìœ¼ë¡œ ì±„ì›€
            df[numeric_cols] = df[numeric_cols].replace([np.inf, -np.inf], np.nan).fillna(0)
            st.success("âœ… ë¬´í•œëŒ€ê°’ ì²˜ë¦¬ ì™„ë£Œ")


def standardize_labels(labels):
    """ë¼ë²¨ í‘œì¤€í™” í•¨ìˆ˜"""
    # ê³µë°± ì œê±° ë° ëŒ€ë¬¸ì ë³€í™˜
    standardized = labels.str.strip().str.upper()
    
    # ì¼ë°˜ì ì¸ ë¼ë²¨ ë§¤í•‘
    label_mapping = {
        'BENIGN': 'BENIGN',
        'NORMAL': 'BENIGN', 
        'DDOS': 'DDoS',
        'DOS': 'DoS',
        'WEB ATTACK': 'Web Attack',
        'WEB ATTACK â€“ BRUTE FORCE': 'Web Attack - Brute Force',
        'WEB ATTACK â€“ XSS': 'Web Attack - XSS',
        'WEB ATTACK â€“ SQL INJECTION': 'Web Attack - SQL Injection',
        'BRUTE FORCE': 'Brute Force',
        'SSH-PATATOR': 'Brute Force',
        'FTP-PATATOR': 'Brute Force',
        'PORTSCAN': 'PortScan',
        'INFILTRATION': 'Infiltration',
        'BOT': 'Botnet',
        'HEARTBLEED': 'Heartbleed'
    }
    
    # ë§¤í•‘ ì ìš©
    for old_label, new_label in label_mapping.items():
        standardized = standardized.replace(old_label, new_label)
    
    return standardized


def load_attack_files():
    """ê³µê²© ë°ì´í„°ê°€ í¬í•¨ëœ íŒŒì¼ë“¤ ë¡œë“œ (ê°•í™”ëœ ì˜¤ë¥˜ ì²˜ë¦¬)"""
    # í™•ì‹¤í•œ import ë³´ì¥
    import pandas as pd
    import numpy as np
    import glob
    import os
    
    data_dir = "/Users/greenpianorabbit/Documents/Development/customer-segmentation/data/cicids2017"
    
    # ê³µê²© ë°ì´í„°ê°€ ë§ì´ í¬í•¨ëœ íŒŒì¼ë“¤
    attack_files = [
        "Tuesday-WorkingHours.pcap_ISCX.csv",  # ë¸Œë£¨íŠ¸í¬ìŠ¤
        "Wednesday-workingHours.pcap_ISCX.csv",  # DoS/DDoS
        "Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv",  # ì›¹ ê³µê²©
        "Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv",  # DDoS
        "Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv"  # í¬íŠ¸ìŠ¤ìº”
    ]
    
    combined_data = []
    successful_files = []
    failed_files = []
    
    st.info("ğŸ” ê³µê²© ë°ì´í„° íŒŒì¼ë“¤ ê²€ìƒ‰ ë° ë¡œë“œ ì‹œë„ ì¤‘...")
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë¨¼ì € í™•ì¸
    for filename in attack_files:
        file_path = os.path.join(data_dir, filename)
        if os.path.exists(file_path):
            st.success(f"âœ… {filename} íŒŒì¼ ë°œê²¬")
        else:
            st.warning(f"âŒ {filename} íŒŒì¼ ì—†ìŒ")
            failed_files.append(filename)
    
    # ì‹¤ì œ ë¡œë“œ ì‹œë„
    with st.spinner("ê³µê²© ë°ì´í„° íŒŒì¼ë“¤ ë¡œë“œ ì¤‘..."):
        for filename in attack_files:
            file_path = os.path.join(data_dir, filename)
            
            if os.path.exists(file_path):
                # ì—¬ëŸ¬ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
                encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
                df_loaded = None
                
                for encoding in encodings_to_try:
                    try:
                        st.info(f"ğŸ“ {filename} ë¡œë“œ ì¤‘ ({encoding} ì¸ì½”ë”©)...")
                        
                        # ìƒ˜í”Œë§Œ ë¡œë“œ (ë©”ëª¨ë¦¬ ê³ ë ¤)
                        df_loaded = pd.read_csv(file_path, nrows=3000, encoding=encoding)
                        
                        # ì»¬ëŸ¼ëª… ì •ë¦¬
                        df_loaded.columns = df_loaded.columns.str.strip()
                        
                        # ë¼ë²¨ ì»¬ëŸ¼ ì°¾ê¸°
                        label_col = find_label_column(df_loaded)
                        if label_col and label_col != 'Label':
                            df_loaded = df_loaded.rename(columns={label_col: 'Label'})
                        
                        if 'Label' in df_loaded.columns:
                            # ë¼ë²¨ í‘œì¤€í™”
                            df_loaded['Label'] = standardize_labels(df_loaded['Label'])
                            
                            # ê³µê²© ë°ì´í„° ë¹„ìœ¨ í™•ì¸
                            attack_count = (df_loaded['Label'] != 'BENIGN').sum()
                            attack_ratio = attack_count / len(df_loaded) * 100
                            
                            combined_data.append(df_loaded)
                            successful_files.append({
                                'filename': filename,
                                'records': len(df_loaded),
                                'attacks': attack_count,
                                'attack_ratio': attack_ratio,
                                'encoding': encoding
                            })
                            
                            st.success(f"âœ… {filename} ë¡œë“œ ì„±ê³µ: {len(df_loaded)}ê°œ ë ˆì½”ë“œ, ê³µê²© {attack_count}ê°œ ({attack_ratio:.1f}%)")
                            break  # ì„±ê³µí•˜ë©´ ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„ ì¤‘ë‹¨
                        else:
                            st.warning(f"âš ï¸ {filename}ì—ì„œ ë¼ë²¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ ({encoding})")
                            
                    except Exception as e:
                        st.warning(f"âŒ {filename} ë¡œë“œ ì‹¤íŒ¨ ({encoding}): {str(e)[:100]}...")
                        continue
                
                # ëª¨ë“  ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„í•´ë„ ì‹¤íŒ¨í•œ ê²½ìš°
                if df_loaded is None:
                    failed_files.append(filename)
    
    # ê²°ê³¼ ìš”ì•½ í‘œì‹œ
    st.write("**ğŸ“ˆ ë¡œë“œ ê²°ê³¼ ìš”ì•½:**")
    st.write(f"- ì„±ê³µ: {len(successful_files)}ê°œ íŒŒì¼")
    st.write(f"- ì‹¤íŒ¨: {len(failed_files)}ê°œ íŒŒì¼")
    
    if successful_files:
        # ì„±ê³µí•œ íŒŒì¼ë“¤ ì •ë³´ í‘œì‹œ
        success_df = pd.DataFrame(successful_files)
        st.dataframe(success_df, use_container_width=True)
        
        # ëª¨ë“  ë°ì´í„° ê²°í•©
        final_data = pd.concat(combined_data, ignore_index=True)
        
        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë“¤ì—ì„œ ë¬´í•œëŒ€ê°’ ì²˜ë¦¬
        numeric_cols = final_data.select_dtypes(include=[np.number]).columns
        final_data[numeric_cols] = final_data[numeric_cols].replace([np.inf, -np.inf], np.nan).fillna(0)
        
        # ì„¸ì…˜ì— ì €ì¥
        st.session_state.cicids_data = final_data
        
        # ê²°ê³¼ í‘œì‹œ
        total_records = len(final_data)
        attack_records = (final_data['Label'] != 'BENIGN').sum()
        attack_ratio = attack_records / total_records * 100
        
        st.success(f"âœ… ì „ì²´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ë ˆì½”ë“œ ìˆ˜", f"{total_records:,}")
        with col2:
            st.metric("ê³µê²© ë°ì´í„°", f"{attack_records:,}")
        with col3:
            st.metric("ê³µê²© ë¹„ìœ¨", f"{attack_ratio:.1f}%")
        
        # ë¼ë²¨ ë¶„í¬ í‘œì‹œ
        st.write("**ğŸ† ì—…ë°ì´íŠ¸ëœ ë¼ë²¨ ë¶„í¬:**")
        label_counts = final_data['Label'].value_counts()
        label_df = pd.DataFrame({
            'ë¼ë²¨': label_counts.index,
            'ê°œìˆ˜': label_counts.values,
            'ë¹„ìœ¨': (label_counts.values / total_records * 100).round(2)
        })
        st.dataframe(label_df, use_container_width=True)
        
        if attack_ratio > 10:
            st.success("ğŸš€ ì´ì œ 'ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ê³µê²© ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")
        else:
            st.warning(f"ğŸ’¡ ê³µê²© ë¹„ìœ¨ì´ ì—¬ì „íˆ ë‚®ìŠµë‹ˆë‹¤ ({attack_ratio:.1f}%). í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            
            # ìë™ìœ¼ë¡œ í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            enhanced_sample = generate_enhanced_sample_data()
            st.session_state.cicids_data = enhanced_sample
            st.session_state.enhanced_data_generated = True
            
            # ê²°ê³¼ í‘œì‹œ
            new_total = len(enhanced_sample)
            new_attacks = (enhanced_sample['Label'] != 'BENIGN').sum()
            new_ratio = new_attacks / new_total * 100
            
            st.success(f"âœ… ìë™ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ! ê³µê²© {new_attacks:,}ê°œ ({new_ratio:.1f}%)")
            st.balloons()
        
    else:
        st.error("âŒ ëª¨ë“  ê³µê²© ë°ì´í„° íŒŒì¼ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ì‹¤íŒ¨ ì›ì¸ ë””ë²„ê¹…
        with st.expander("ğŸ”§ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„"):
            st.write("**ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:**")
            for failed_file in failed_files:
                st.write(f"- {failed_file}")
            
            st.write("**ê°€ëŠ¥í•œ ì›ì¸:**")
            st.write("1. íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ")
            st.write("2. íŒŒì¼ ê¶Œí•œ ë¬¸ì œ")
            st.write("3. ì¸ì½”ë”© ë¬¸ì œ")
            st.write("4. íŒŒì¼ ì†ìƒ")
        
        st.info("ğŸ’¡ ëŒ€ì‹  í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        enhanced_sample = generate_enhanced_sample_data()
        st.session_state.cicids_data = enhanced_sample
        st.session_state.enhanced_data_generated = True  # í”Œë˜ê·¸ ì„¤ì •
        
        # ê²°ê³¼ í‘œì‹œ
        new_total = len(enhanced_sample)
        new_attacks = (enhanced_sample['Label'] != 'BENIGN').sum()
        new_ratio = new_attacks / new_total * 100
        
        st.success(f"âœ… ëŒ€ì²´ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ! ê³µê²© {new_attacks:,}ê°œ ({new_ratio:.1f}%)")
        st.balloons()
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ìœ ë„
        st.info("ğŸ”„ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ë‹¤ë¥¸ ë©”ë‰´ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.")


def generate_and_save_enhanced_data():
    """í–¥ìƒëœ ë°ì´í„° ìƒì„± ë° ì €ì¥ í†µí•© í•¨ìˆ˜"""
    # ğŸ” í•¨ìˆ˜ ì§„ì… í™•ì¸ ë¡œê·¸
    st.write("ğŸš¨ generate_and_save_enhanced_data() í•¨ìˆ˜ ì§„ì…!")
    
    with st.spinner("CICIDS2017 íŒ¨í„´ì„ ì‹œë®¬ë ˆì´ì…˜í•œ í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘..."):
        sample_data = generate_enhanced_sample_data()
        
        # ğŸ” ë°ì´í„° ìƒì„± ì§í›„ ë¡œê·¸
        st.write(f"ğŸ” ìƒì„±ëœ ë°ì´í„° í¬ê¸°: {len(sample_data)}")
        attack_check = (sample_data['Label'] != 'BENIGN').sum()
        st.write(f"ğŸ” ìƒì„±ëœ ê³µê²© ë°ì´í„°: {attack_check}ê°œ")
        
        # ì„¸ì…˜ì— ì €ì¥ ë° í”Œë˜ê·¸ ì„¤ì •
        st.session_state.cicids_data = sample_data
        st.session_state.enhanced_data_generated = True
        
        # ğŸ” ì €ì¥ ì§í›„ ê²€ì¦
        stored_data = st.session_state.cicids_data
        stored_attacks = (stored_data['Label'] != 'BENIGN').sum()
        st.write(f"ğŸ” ì„¸ì…˜ ì €ì¥ í›„ ê²€ì¦: {stored_attacks}ê°œ ê³µê²© ë°ì´í„°")
        
        # ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ
        total_records = len(sample_data)
        attack_records = (sample_data['Label'] != 'BENIGN').sum()
        attack_ratio = attack_records / total_records * 100
        
        st.success(f"âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ! ì´ {total_records:,}ê°œ (ê³µê²© {attack_records:,}ê°œ, {attack_ratio:.1f}%)")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ë ˆì½”ë“œ ìˆ˜", f"{total_records:,}")
        with col2:
            st.metric("ê³µê²© ë°ì´í„°", f"{attack_records:,}")
        with col3:
            st.metric("ê³µê²© ë¹„ìœ¨", f"{attack_ratio:.1f}%")
        
        # ë¼ë²¨ ë¶„í¬ í‘œì‹œ
        label_counts = sample_data['Label'].value_counts()
        st.write("**ğŸ† ìƒì„±ëœ ë°ì´í„° ë¼ë²¨ ë¶„í¬:**")
        label_df = pd.DataFrame({
            'ë¼ë²¨': label_counts.index,
            'ê°œìˆ˜': label_counts.values,
            'ë¹„ìœ¨': (label_counts.values / total_records * 100).round(2)
        })
        st.dataframe(label_df, use_container_width=True)
        
        st.balloons()
        st.success("ğŸš€ ì´ì œ 'âš¡ ê³µê²© íŒ¨í„´ ì‹¬í™” ë¶„ì„' ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬ ì˜ë¯¸ìˆëŠ” ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”!")
        st.info("ğŸ”„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë‹¤ë¥¸ ë¶„ì„ ë©”ë‰´ë¥¼ ì„ íƒí•˜ì„¸ìš”.")


def generate_enhanced_sample_data():
    """í–¥ìƒëœ ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ê³µê²© ë¹„ìœ¨ ì¦ê°€) - ë””ë²„ê¹… ë¡œê·¸ í¬í•¨"""
    # í™•ì‹¤í•œ import ë³´ì¥
    import streamlit as st
    import pandas as pd
    import numpy as np
    
    # ë””ë²„ê¹… ë¡œê·¸
    if hasattr(st, 'write'):
        st.write("ğŸ” generate_enhanced_sample_data() í•¨ìˆ˜ í˜¸ì¶œë¨")
    
    np.random.seed(42)
    
    # ë” ë§ì€ ê³µê²© ë°ì´í„° í¬í•¨
    n_samples = 10000
    
    # ì •ìƒ íŠ¸ë˜í”½ (40%)
    normal_samples = int(n_samples * 0.4)
    # DDoS ê³µê²© (25%)
    ddos_samples = int(n_samples * 0.25)
    # ì›¹ ê³µê²© (15%)
    web_attack_samples = int(n_samples * 0.15)
    # ë¸Œë£¨íŠ¸í¬ìŠ¤ (10%)
    brute_force_samples = int(n_samples * 0.10)
    # í¬íŠ¸ìŠ¤ìº” (10%)
    port_scan_samples = n_samples - normal_samples - ddos_samples - web_attack_samples - brute_force_samples
    
    if hasattr(st, 'write'):
        st.write(f"ğŸ” ë°ì´í„° ë¹„ìœ¨: ì •ìƒ {normal_samples}, ê³µê²© {n_samples - normal_samples}")
    
    # ì •ìƒ íŠ¸ë˜í”½
    normal_data = {
        'Flow_Duration': np.random.exponential(100000, normal_samples),
        'Total_Fwd_Packets': np.random.poisson(15, normal_samples),
        'Total_Backward_Packets': np.random.poisson(12, normal_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(800, 300, normal_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(600, 200, normal_samples),
        'Fwd_Packet_Length_Max': np.random.normal(1200, 400, normal_samples),
        'Fwd_Packet_Length_Min': np.random.normal(60, 20, normal_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(400, 150, normal_samples),
        'Bwd_Packet_Length_Max': np.random.normal(1000, 300, normal_samples),
        'Bwd_Packet_Length_Min': np.random.normal(50, 15, normal_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(300, 100, normal_samples),
        'Flow_Bytes/s': np.random.normal(2000, 1000, normal_samples),
        'Flow_Packets/s': np.random.normal(20, 10, normal_samples),
        'Flow_IAT_Mean': np.random.exponential(50000, normal_samples),
        'Flow_IAT_Std': np.random.exponential(25000, normal_samples),
        'Fwd_IAT_Total': np.random.exponential(200000, normal_samples),
        'Fwd_IAT_Mean': np.random.exponential(20000, normal_samples),
        'Bwd_IAT_Total': np.random.exponential(150000, normal_samples),
        'Bwd_IAT_Mean': np.random.exponential(15000, normal_samples),
        'Label': ['BENIGN'] * normal_samples
    }
    
    # DDoS ê³µê²©
    ddos_data = {
        'Flow_Duration': np.random.exponential(10000, ddos_samples),
        'Total_Fwd_Packets': np.random.poisson(200, ddos_samples),
        'Total_Backward_Packets': np.random.poisson(5, ddos_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(10000, 2000, ddos_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(200, 100, ddos_samples),
        'Fwd_Packet_Length_Max': np.random.normal(1500, 100, ddos_samples),
        'Fwd_Packet_Length_Min': np.random.normal(64, 10, ddos_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(80, 20, ddos_samples),
        'Bwd_Packet_Length_Max': np.random.normal(150, 50, ddos_samples),
        'Bwd_Packet_Length_Min': np.random.normal(40, 10, ddos_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(60, 20, ddos_samples),
        'Flow_Bytes/s': np.random.normal(50000, 15000, ddos_samples),
        'Flow_Packets/s': np.random.normal(500, 150, ddos_samples),
        'Flow_IAT_Mean': np.random.exponential(1000, ddos_samples),
        'Flow_IAT_Std': np.random.exponential(500, ddos_samples),
        'Fwd_IAT_Total': np.random.exponential(5000, ddos_samples),
        'Fwd_IAT_Mean': np.random.exponential(50, ddos_samples),
        'Bwd_IAT_Total': np.random.exponential(20000, ddos_samples),
        'Bwd_IAT_Mean': np.random.exponential(2000, ddos_samples),
        'Label': ['DDoS'] * ddos_samples
    }
    
    # ì›¹ ê³µê²©
    web_attack_data = {
        'Flow_Duration': np.random.exponential(150000, web_attack_samples),
        'Total_Fwd_Packets': np.random.poisson(30, web_attack_samples),
        'Total_Backward_Packets': np.random.poisson(25, web_attack_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(3000, 800, web_attack_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(1500, 400, web_attack_samples),
        'Fwd_Packet_Length_Max': np.random.normal(1400, 200, web_attack_samples),
        'Fwd_Packet_Length_Min': np.random.normal(200, 50, web_attack_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(500, 100, web_attack_samples),
        'Bwd_Packet_Length_Max': np.random.normal(800, 150, web_attack_samples),
        'Bwd_Packet_Length_Min': np.random.normal(100, 30, web_attack_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(250, 80, web_attack_samples),
        'Flow_Bytes/s': np.random.normal(4000, 1500, web_attack_samples),
        'Flow_Packets/s': np.random.normal(25, 10, web_attack_samples),
        'Flow_IAT_Mean': np.random.exponential(30000, web_attack_samples),
        'Flow_IAT_Std': np.random.exponential(15000, web_attack_samples),
        'Fwd_IAT_Total': np.random.exponential(100000, web_attack_samples),
        'Fwd_IAT_Mean': np.random.exponential(8000, web_attack_samples),
        'Bwd_IAT_Total': np.random.exponential(80000, web_attack_samples),
        'Bwd_IAT_Mean': np.random.exponential(6000, web_attack_samples),
        'Label': ['Web Attack'] * web_attack_samples
    }
    
    # ë¸Œë£¨íŠ¸í¬ìŠ¤
    brute_force_data = {
        'Flow_Duration': np.random.exponential(30000, brute_force_samples),
        'Total_Fwd_Packets': np.random.poisson(80, brute_force_samples),
        'Total_Backward_Packets': np.random.poisson(8, brute_force_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(2000, 500, brute_force_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(400, 150, brute_force_samples),
        'Fwd_Packet_Length_Max': np.random.normal(800, 200, brute_force_samples),
        'Fwd_Packet_Length_Min': np.random.normal(40, 15, brute_force_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(80, 30, brute_force_samples),
        'Bwd_Packet_Length_Max': np.random.normal(300, 100, brute_force_samples),
        'Bwd_Packet_Length_Min': np.random.normal(30, 10, brute_force_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(60, 20, brute_force_samples),
        'Flow_Bytes/s': np.random.normal(8000, 2000, brute_force_samples),
        'Flow_Packets/s': np.random.normal(80, 20, brute_force_samples),
        'Flow_IAT_Mean': np.random.exponential(3000, brute_force_samples),
        'Flow_IAT_Std': np.random.exponential(1500, brute_force_samples),
        'Fwd_IAT_Total': np.random.exponential(15000, brute_force_samples),
        'Fwd_IAT_Mean': np.random.exponential(300, brute_force_samples),
        'Bwd_IAT_Total': np.random.exponential(25000, brute_force_samples),
        'Bwd_IAT_Mean': np.random.exponential(2500, brute_force_samples),
        'Label': ['Brute Force'] * brute_force_samples
    }
    
    # í¬íŠ¸ìŠ¤ìº”
    port_scan_data = {
        'Flow_Duration': np.random.exponential(5000, port_scan_samples),
        'Total_Fwd_Packets': np.random.poisson(10, port_scan_samples),
        'Total_Backward_Packets': np.random.poisson(2, port_scan_samples),
        'Total_Length_of_Fwd_Packets': np.random.normal(400, 150, port_scan_samples),
        'Total_Length_of_Bwd_Packets': np.random.normal(100, 50, port_scan_samples),
        'Fwd_Packet_Length_Max': np.random.normal(200, 60, port_scan_samples),
        'Fwd_Packet_Length_Min': np.random.normal(40, 10, port_scan_samples),
        'Fwd_Packet_Length_Mean': np.random.normal(60, 20, port_scan_samples),
        'Bwd_Packet_Length_Max': np.random.normal(100, 30, port_scan_samples),
        'Bwd_Packet_Length_Min': np.random.normal(20, 5, port_scan_samples),
        'Bwd_Packet_Length_Mean': np.random.normal(40, 15, port_scan_samples),
        'Flow_Bytes/s': np.random.normal(1000, 300, port_scan_samples),
        'Flow_Packets/s': np.random.normal(30, 10, port_scan_samples),
        'Flow_IAT_Mean': np.random.exponential(8000, port_scan_samples),
        'Flow_IAT_Std': np.random.exponential(4000, port_scan_samples),
        'Fwd_IAT_Total': np.random.exponential(3000, port_scan_samples),
        'Fwd_IAT_Mean': np.random.exponential(800, port_scan_samples),
        'Bwd_IAT_Total': np.random.exponential(8000, port_scan_samples),
        'Bwd_IAT_Mean': np.random.exponential(4000, port_scan_samples),
        'Label': ['PortScan'] * port_scan_samples
    }
    
    # ëª¨ë“  ë°ì´í„° ê²°í•©
    all_data = {}
    for key in normal_data.keys():
        all_data[key] = (
            list(normal_data[key]) + 
            list(ddos_data[key]) + 
            list(web_attack_data[key]) + 
            list(brute_force_data[key]) + 
            list(port_scan_data[key])
        )
    
    df = pd.DataFrame(all_data)
    
    # ë°ì´í„° ì •ë¦¬
    df = df.sample(frac=1, random_state=42).reset_index(drop=True)
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    df[numeric_columns] = df[numeric_columns].abs()
    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)
    
    # ë””ë²„ê¹… ë¡œê·¸ - ìµœì¢… ê²°ê³¼
    if hasattr(st, 'write'):
        attack_count = (df['Label'] != 'BENIGN').sum()
        attack_ratio = attack_count / len(df) * 100
        st.write(f"ğŸ” í–¥ìƒëœ ë°ì´í„° ìƒì„± ì™„ë£Œ: ì´ {len(df)}ê°œ, ê³µê²© {attack_count}ê°œ ({attack_ratio:.1f}%)")
    
    return df


def test_button_functionality():
    """ë²„íŠ¼ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ í•¨ìˆ˜"""
    st.markdown("### ğŸ§ª ë²„íŠ¼ í…ŒìŠ¤íŠ¸")
    
    # ì¹´ìš´í„° ì´ˆê¸°í™”
    if 'test_counter' not in st.session_state:
        st.session_state.test_counter = 0
    
    # í…ŒìŠ¤íŠ¸ ë²„íŠ¼
    if st.button("ğŸŸ¢ ê°„ë‹¨ í…ŒìŠ¤íŠ¸", key="simple_test_button"):
        st.session_state.test_counter += 1
        st.success(f"âœ… ë²„íŠ¼ ì‘ë™ í™•ì¸! í´ë¦­ íšŸìˆ˜: {st.session_state.test_counter}")
        
        # ë°ì´í„° ìƒì„± í…ŒìŠ¤íŠ¸
        test_data = generate_enhanced_sample_data()
        st.write(f"ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {len(test_data)}ê°œ ë ˆì½”ë“œ")
        
        # ì„¸ì…˜ì— ì €ì¥ í…ŒìŠ¤íŠ¸
        st.session_state['test_data'] = test_data
        st.write("ğŸ” ì„¸ì…˜ì— ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
        # ì¦‰ì‹œ ê²€ì¦
        if 'test_data' in st.session_state:
            saved_data = st.session_state['test_data']
            attacks = (saved_data['Label'] != 'BENIGN').sum()
            st.success(f"ğŸ‰ ì„¸ì…˜ ë°ì´í„° ê²€ì¦ ì„±ê³µ: {attacks}ê°œ ê³µê²© ë°ì´í„°")
        else:
            st.error("âŒ ì„¸ì…˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
    
    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
    st.write(f"**í˜„ì¬ ì¹´ìš´í„°:** {st.session_state.test_counter}")
    if 'test_data' in st.session_state:
        test_attacks = (st.session_state['test_data']['Label'] != 'BENIGN').sum()
        st.write(f"**ì €ì¥ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°:** {len(st.session_state['test_data'])}ê°œ (ê³µê²© {test_attacks}ê°œ)")


# ë©”ì¸ í•¨ìˆ˜ëŠ” main_app.pyì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤
if __name__ == "__main__":
    show_security_analysis_page()
